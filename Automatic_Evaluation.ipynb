{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ad3024ca3e04ca7a62c3e41714d747e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2abe4264e1474037a726e41b01557efd",
              "IPY_MODEL_596c14d559fd4b028531541ac0270e84",
              "IPY_MODEL_8948ec4e12c84edfadb90c22d6548d16"
            ],
            "layout": "IPY_MODEL_1bf26f8b1e8046a984aabe04731ea4e6"
          }
        },
        "2abe4264e1474037a726e41b01557efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0954f4d608543c2b757e74d1183b714",
            "placeholder": "​",
            "style": "IPY_MODEL_d9dbc57b745b432abdbaed2db6f15982",
            "value": "config.json: 100%"
          }
        },
        "596c14d559fd4b028531541ac0270e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a568f1e4ec6746cbb26f8dd2b4b794ef",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d8cc5fc152f42aab6aa6ea668cba569",
            "value": 665
          }
        },
        "8948ec4e12c84edfadb90c22d6548d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_049b3b94ab4e43798b6cdab53687970c",
            "placeholder": "​",
            "style": "IPY_MODEL_ca67ac60115a4a13a6d54b4b946c5423",
            "value": " 665/665 [00:00&lt;00:00, 73.5kB/s]"
          }
        },
        "1bf26f8b1e8046a984aabe04731ea4e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0954f4d608543c2b757e74d1183b714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9dbc57b745b432abdbaed2db6f15982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a568f1e4ec6746cbb26f8dd2b4b794ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d8cc5fc152f42aab6aa6ea668cba569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "049b3b94ab4e43798b6cdab53687970c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca67ac60115a4a13a6d54b4b946c5423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e335eb4643f4443bcd341c951071332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b22260feb0ba40b5b4ae1b6fcddd3427",
              "IPY_MODEL_b9ff13b3bf1b4262ae10d476dba077c1",
              "IPY_MODEL_50f57ad807a649d49ec7903ab8df4442"
            ],
            "layout": "IPY_MODEL_6f94c0cac47c4b6e85c02f749e630785"
          }
        },
        "b22260feb0ba40b5b4ae1b6fcddd3427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eff735d39c647d09e58ec501b8e9988",
            "placeholder": "​",
            "style": "IPY_MODEL_463849ce2b3c407185eb32447f01d1da",
            "value": "model.safetensors: 100%"
          }
        },
        "b9ff13b3bf1b4262ae10d476dba077c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7301136eef744c34af7c5dfdabbe380d",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a098912c82345f4aa6b4b7bd1a3fa55",
            "value": 548105171
          }
        },
        "50f57ad807a649d49ec7903ab8df4442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92972e31400a43e8915a0d97e9d73132",
            "placeholder": "​",
            "style": "IPY_MODEL_366dad0292af46d5af6dbbf4e4ec3130",
            "value": " 548M/548M [00:07&lt;00:00, 44.8MB/s]"
          }
        },
        "6f94c0cac47c4b6e85c02f749e630785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eff735d39c647d09e58ec501b8e9988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463849ce2b3c407185eb32447f01d1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7301136eef744c34af7c5dfdabbe380d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a098912c82345f4aa6b4b7bd1a3fa55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92972e31400a43e8915a0d97e9d73132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366dad0292af46d5af6dbbf4e4ec3130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bad7976c22f484a925c9f62a9df2f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4350c79266b4b968ca2e135e5c2617e",
              "IPY_MODEL_b4074d252f174e049604b4bc7bfd8202",
              "IPY_MODEL_8189026d00fe4b1daa954dbef83df60b"
            ],
            "layout": "IPY_MODEL_02850156ff124b9680f123c583f6bd2c"
          }
        },
        "e4350c79266b4b968ca2e135e5c2617e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a4ef4994c04a4192f35fd9789e0ecb",
            "placeholder": "​",
            "style": "IPY_MODEL_b569deb6d6f44febb17f28af843dea40",
            "value": "generation_config.json: 100%"
          }
        },
        "b4074d252f174e049604b4bc7bfd8202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b71388bba94cf5ac7f5ab5cbdc8d98",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc6f2b5d0d8e4616b2241343b8142c0c",
            "value": 124
          }
        },
        "8189026d00fe4b1daa954dbef83df60b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cded45b23cf4d8fb970538a09310866",
            "placeholder": "​",
            "style": "IPY_MODEL_936102cd06a046d2abc70ebd16cd04d2",
            "value": " 124/124 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "02850156ff124b9680f123c583f6bd2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a4ef4994c04a4192f35fd9789e0ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b569deb6d6f44febb17f28af843dea40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71b71388bba94cf5ac7f5ab5cbdc8d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6f2b5d0d8e4616b2241343b8142c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cded45b23cf4d8fb970538a09310866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936102cd06a046d2abc70ebd16cd04d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0772976612546bfae84ad45bc2f2bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcf390d3c3114f50b4bccf19e4543265",
              "IPY_MODEL_924dcd24a05947e483f8df96a6d55965",
              "IPY_MODEL_265f77967e84411196d9bd9dc69ca237"
            ],
            "layout": "IPY_MODEL_4127a9702c3b4f7589ace0d2d41092d8"
          }
        },
        "bcf390d3c3114f50b4bccf19e4543265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89578b73afc4db991cf8925b7d9c260",
            "placeholder": "​",
            "style": "IPY_MODEL_655d15b6b53d479f92d66f6ccffe3006",
            "value": "config.json: 100%"
          }
        },
        "924dcd24a05947e483f8df96a6d55965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d067662a22d9421d9ab46394d8e11f91",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cd622a0956b4bd2a9fcb3b9a0214d14",
            "value": 665
          }
        },
        "265f77967e84411196d9bd9dc69ca237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8ceec7b9f3a40998fc37fdc0bee938d",
            "placeholder": "​",
            "style": "IPY_MODEL_77a37742a2754ddf93082ea8bbf82a5e",
            "value": " 665/665 [00:00&lt;00:00, 54.6kB/s]"
          }
        },
        "4127a9702c3b4f7589ace0d2d41092d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89578b73afc4db991cf8925b7d9c260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655d15b6b53d479f92d66f6ccffe3006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d067662a22d9421d9ab46394d8e11f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd622a0956b4bd2a9fcb3b9a0214d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8ceec7b9f3a40998fc37fdc0bee938d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a37742a2754ddf93082ea8bbf82a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfab9d4687d34255b7aa1ddb4d361add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_822db7e8216a43fbb475699b29bf7b71",
              "IPY_MODEL_c13fb2d53cb04720bc468a4a1670b35a",
              "IPY_MODEL_2549b5e585d84541ba615b2812a58c2c"
            ],
            "layout": "IPY_MODEL_feada5de96b8484fb3426927af9d7627"
          }
        },
        "822db7e8216a43fbb475699b29bf7b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea7bab0aa7f64329ba8140e8db366b32",
            "placeholder": "​",
            "style": "IPY_MODEL_1c4ec52ff15e4ffea9af6b2eee691922",
            "value": "model.safetensors: 100%"
          }
        },
        "c13fb2d53cb04720bc468a4a1670b35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8053ff10bf59456486902838dadd37da",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f4b47da83344c208e74f96004d83677",
            "value": 548105171
          }
        },
        "2549b5e585d84541ba615b2812a58c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0540dac1f61401c8ab46afb5c9aa248",
            "placeholder": "​",
            "style": "IPY_MODEL_5675158a4a144f4e8dc421c81218c86a",
            "value": " 548M/548M [00:02&lt;00:00, 431MB/s]"
          }
        },
        "feada5de96b8484fb3426927af9d7627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7bab0aa7f64329ba8140e8db366b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c4ec52ff15e4ffea9af6b2eee691922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8053ff10bf59456486902838dadd37da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4b47da83344c208e74f96004d83677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0540dac1f61401c8ab46afb5c9aa248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5675158a4a144f4e8dc421c81218c86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "334fb2182f2c4c069bcc6205b8108c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3004a8cb43c6499ca29c977b9112bac4",
              "IPY_MODEL_c4cad901b35f4fb3a905d9c2770839e1",
              "IPY_MODEL_178b0b1f47eb4260b601fc8b542f20d3"
            ],
            "layout": "IPY_MODEL_1178e6ec18b94dd3b5fd617a4b72fa0b"
          }
        },
        "3004a8cb43c6499ca29c977b9112bac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8f6bffb92048f6945603edea87cfef",
            "placeholder": "​",
            "style": "IPY_MODEL_ded541cabf0c4f5f86c737c165ac49b4",
            "value": "generation_config.json: 100%"
          }
        },
        "c4cad901b35f4fb3a905d9c2770839e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9023832b9c4f4f5887f85e5a1f2b574b",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be704fec049842888f6b7250e39d0e50",
            "value": 124
          }
        },
        "178b0b1f47eb4260b601fc8b542f20d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4106ffbad8443e8bc6a78095d0b219",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c5524fb0f24f5aa85418b43cb0a56c",
            "value": " 124/124 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "1178e6ec18b94dd3b5fd617a4b72fa0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8f6bffb92048f6945603edea87cfef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded541cabf0c4f5f86c737c165ac49b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9023832b9c4f4f5887f85e5a1f2b574b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be704fec049842888f6b7250e39d0e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c4106ffbad8443e8bc6a78095d0b219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c5524fb0f24f5aa85418b43cb0a56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c17c02e527314b91911895893d0715ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f56b94324a54dcd982da097b3c87b8d",
              "IPY_MODEL_be8b327ebfde4d74b75490a8d79f92b1",
              "IPY_MODEL_2bf27bf1dd9244518972ca8f08b86a78"
            ],
            "layout": "IPY_MODEL_c109e6a101c34690a6672924f91f68d5"
          }
        },
        "1f56b94324a54dcd982da097b3c87b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4aa9e83f8841bfa4eca71b6836c84d",
            "placeholder": "​",
            "style": "IPY_MODEL_9a451796cdf34dc6b20c78669b4f3e31",
            "value": "config.json: 100%"
          }
        },
        "be8b327ebfde4d74b75490a8d79f92b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fec0bdecfeb4f8ab1e2ebbadfb9dba4",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d3ad068c0de41d69169108cc0f13629",
            "value": 665
          }
        },
        "2bf27bf1dd9244518972ca8f08b86a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9a59d538454528a8495516cdad0d43",
            "placeholder": "​",
            "style": "IPY_MODEL_87837d4e947e494296289405d6b0f963",
            "value": " 665/665 [00:00&lt;00:00, 54.0kB/s]"
          }
        },
        "c109e6a101c34690a6672924f91f68d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4aa9e83f8841bfa4eca71b6836c84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a451796cdf34dc6b20c78669b4f3e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fec0bdecfeb4f8ab1e2ebbadfb9dba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3ad068c0de41d69169108cc0f13629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a9a59d538454528a8495516cdad0d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87837d4e947e494296289405d6b0f963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b37c1198f21a4581b7106ebac92b1582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bb56f5f1ce548f2b6d9998fcbf193ab",
              "IPY_MODEL_c4ab6a7f6a4441cfaf1855d9c050eddf",
              "IPY_MODEL_f2c0f6fcecfc4050ac05d2f60845eef5"
            ],
            "layout": "IPY_MODEL_2a0fb5a53efa429fb332e30090bd819c"
          }
        },
        "2bb56f5f1ce548f2b6d9998fcbf193ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4150860e8edf4197b9edc3894562b701",
            "placeholder": "​",
            "style": "IPY_MODEL_d097579224c84f92964dfd31be36229d",
            "value": "model.safetensors: 100%"
          }
        },
        "c4ab6a7f6a4441cfaf1855d9c050eddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e8a0c6037c544348af7370fe3dde210",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_352d8ceed7564427a63c2b6f9fdf126f",
            "value": 548105171
          }
        },
        "f2c0f6fcecfc4050ac05d2f60845eef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e101f9784a42459b1d4a049bf761e0",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf8af30f4564d8d8cbff0901f82d2b9",
            "value": " 548M/548M [00:18&lt;00:00, 53.6MB/s]"
          }
        },
        "2a0fb5a53efa429fb332e30090bd819c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4150860e8edf4197b9edc3894562b701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d097579224c84f92964dfd31be36229d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e8a0c6037c544348af7370fe3dde210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352d8ceed7564427a63c2b6f9fdf126f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0e101f9784a42459b1d4a049bf761e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf8af30f4564d8d8cbff0901f82d2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a68e62158ea4a2d935797fd7c56a11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30094357ce484fcfa0234b3a0879c16e",
              "IPY_MODEL_dd1e735dd0804349b4230a9d577db457",
              "IPY_MODEL_2c6e1d35d8434907b624d58eac8bda2d"
            ],
            "layout": "IPY_MODEL_1049dc196fdb43a3bdde0eff49ca624b"
          }
        },
        "30094357ce484fcfa0234b3a0879c16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82cdcd15df2f43058c884e35f8260929",
            "placeholder": "​",
            "style": "IPY_MODEL_b1cca684038745a0a02fc82e7ccd937e",
            "value": "generation_config.json: 100%"
          }
        },
        "dd1e735dd0804349b4230a9d577db457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d9b054c75c4e0b98b0b8feb0e7346e",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc587c1973024690962d9bb6d5020724",
            "value": 124
          }
        },
        "2c6e1d35d8434907b624d58eac8bda2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1a308fc8ac4601b190e425b28a3741",
            "placeholder": "​",
            "style": "IPY_MODEL_0e5c336ffb68460dbcdec4c0a22fb0c0",
            "value": " 124/124 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "1049dc196fdb43a3bdde0eff49ca624b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cdcd15df2f43058c884e35f8260929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cca684038745a0a02fc82e7ccd937e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d9b054c75c4e0b98b0b8feb0e7346e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc587c1973024690962d9bb6d5020724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1a308fc8ac4601b190e425b28a3741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5c336ffb68460dbcdec4c0a22fb0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bbc90b011d64936b861c6738eb51f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e671951ce1214773ac266bea93932607",
              "IPY_MODEL_c05ba641de32427d8688464dcafc75fc",
              "IPY_MODEL_f2991937f56f4dd29da53dae5b02ff3e"
            ],
            "layout": "IPY_MODEL_5dacea550b344a0e986a61938789e724"
          }
        },
        "e671951ce1214773ac266bea93932607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b91cee79c084eb899cb7fa90e2417c3",
            "placeholder": "​",
            "style": "IPY_MODEL_81f50236448d4292a5f138788851bc64",
            "value": "config.json: 100%"
          }
        },
        "c05ba641de32427d8688464dcafc75fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff1f4ce692241b888f0d32adc6e1f02",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6dcce7e055641e288c87bc196b7c18a",
            "value": 665
          }
        },
        "f2991937f56f4dd29da53dae5b02ff3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745ac7abe14c46b08ca4925a92627347",
            "placeholder": "​",
            "style": "IPY_MODEL_816f522de974459b822a770d8c6d567e",
            "value": " 665/665 [00:00&lt;00:00, 70.5kB/s]"
          }
        },
        "5dacea550b344a0e986a61938789e724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b91cee79c084eb899cb7fa90e2417c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f50236448d4292a5f138788851bc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff1f4ce692241b888f0d32adc6e1f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6dcce7e055641e288c87bc196b7c18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "745ac7abe14c46b08ca4925a92627347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816f522de974459b822a770d8c6d567e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "524437d999aa488fb37f5cd2b0a9c9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb08f2d1ccee43a486984178b877bbb3",
              "IPY_MODEL_79c121513fdd4114934617db9e20660f",
              "IPY_MODEL_dc923984e80e42388157fde6fe02437c"
            ],
            "layout": "IPY_MODEL_a5c9b249059948acbf8ce17140d8ea61"
          }
        },
        "eb08f2d1ccee43a486984178b877bbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd678ef9bfca44b783b8bbcc1aa14d36",
            "placeholder": "​",
            "style": "IPY_MODEL_2c838e1ae0514f49a5497f82d81dc0ed",
            "value": "model.safetensors: 100%"
          }
        },
        "79c121513fdd4114934617db9e20660f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ace6e6a90ab4a2f83abc319504a9863",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bce69901c32449486b6f0fd01a5018d",
            "value": 548105171
          }
        },
        "dc923984e80e42388157fde6fe02437c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6660c9826f754ce98d685b0eac0560d8",
            "placeholder": "​",
            "style": "IPY_MODEL_ad3049d4392a4eba8e0713556c24b62a",
            "value": " 548M/548M [00:01&lt;00:00, 364MB/s]"
          }
        },
        "a5c9b249059948acbf8ce17140d8ea61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd678ef9bfca44b783b8bbcc1aa14d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c838e1ae0514f49a5497f82d81dc0ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ace6e6a90ab4a2f83abc319504a9863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bce69901c32449486b6f0fd01a5018d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6660c9826f754ce98d685b0eac0560d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3049d4392a4eba8e0713556c24b62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7478f0ae42bf436885d4c6b8c5ac94d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_435dc24046ba4a25a4319df15560859e",
              "IPY_MODEL_3516d37139f74f53b7f392c4b5eec522",
              "IPY_MODEL_114450ebc064436db7cef87a081a87e9"
            ],
            "layout": "IPY_MODEL_1fc1935bd4a64479a6ab62f4b618d585"
          }
        },
        "435dc24046ba4a25a4319df15560859e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac8b942004942ac8bfb259bd18f93d7",
            "placeholder": "​",
            "style": "IPY_MODEL_cea1e260ece04148a2938097525c2dde",
            "value": "generation_config.json: 100%"
          }
        },
        "3516d37139f74f53b7f392c4b5eec522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ee53941db84c318cf455785ec6305a",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_888a4e39f8904a90bb8bcbf71dcb8919",
            "value": 124
          }
        },
        "114450ebc064436db7cef87a081a87e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0540c2753f1442dfa8b99d68f0a58c80",
            "placeholder": "​",
            "style": "IPY_MODEL_62e200e0c3314200bdc34eb167c699cf",
            "value": " 124/124 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "1fc1935bd4a64479a6ab62f4b618d585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac8b942004942ac8bfb259bd18f93d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea1e260ece04148a2938097525c2dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ee53941db84c318cf455785ec6305a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888a4e39f8904a90bb8bcbf71dcb8919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0540c2753f1442dfa8b99d68f0a58c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e200e0c3314200bdc34eb167c699cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40ebd7865c11459993f16a615bc243c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc4151e041c6461b960dec4b062efba0",
              "IPY_MODEL_e392fc7af4bc44089b823b2b803233d2",
              "IPY_MODEL_f407e98abbde444f92a3403a4bcb9c51"
            ],
            "layout": "IPY_MODEL_c3037d339d1546af9c4a1224044773ad"
          }
        },
        "fc4151e041c6461b960dec4b062efba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2bea38ae474c08be410939d71d6991",
            "placeholder": "​",
            "style": "IPY_MODEL_357a8a5a02e247de8c1acf2bf07d42f2",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e392fc7af4bc44089b823b2b803233d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef02bad7caee4914bd715703d43e66b7",
            "max": 380,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dce151e6b7546b4ba12538d039471cc",
            "value": 380
          }
        },
        "f407e98abbde444f92a3403a4bcb9c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c9c6a70fd94c5fb9237bd02f27a3e0",
            "placeholder": "​",
            "style": "IPY_MODEL_947b23b3f1d448aab45f9f0be5eb114f",
            "value": " 380/380 [00:00&lt;00:00, 43.7kB/s]"
          }
        },
        "c3037d339d1546af9c4a1224044773ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d2bea38ae474c08be410939d71d6991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357a8a5a02e247de8c1acf2bf07d42f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef02bad7caee4914bd715703d43e66b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dce151e6b7546b4ba12538d039471cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c9c6a70fd94c5fb9237bd02f27a3e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "947b23b3f1d448aab45f9f0be5eb114f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2050d6ff86a4dbfb7e1a5b5eb468c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d02a7a1758754bab91c07fa5c47c84b6",
              "IPY_MODEL_a2689f6815f745fd8894cbc7895bb79c",
              "IPY_MODEL_ac00d546416d4d94b255101caff69dae"
            ],
            "layout": "IPY_MODEL_a6631e9ddb274aeb8c487a7c5d97f7df"
          }
        },
        "d02a7a1758754bab91c07fa5c47c84b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17b5009583d4d34aab5e4071822b536",
            "placeholder": "​",
            "style": "IPY_MODEL_3275b1c8fc664d7db2e95740ee82a1a8",
            "value": "vocab.json: "
          }
        },
        "a2689f6815f745fd8894cbc7895bb79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62a68f1613e40a38a756fc96a9b98f6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0e2fb855e4945c6b317e935a6c22b54",
            "value": 1
          }
        },
        "ac00d546416d4d94b255101caff69dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0d4bcafda2c44cab49801dab8018a0f",
            "placeholder": "​",
            "style": "IPY_MODEL_c16eb98ea27f40b8b7712ba3ae37b486",
            "value": " 798k/? [00:00&lt;00:00, 15.9MB/s]"
          }
        },
        "a6631e9ddb274aeb8c487a7c5d97f7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17b5009583d4d34aab5e4071822b536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3275b1c8fc664d7db2e95740ee82a1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b62a68f1613e40a38a756fc96a9b98f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c0e2fb855e4945c6b317e935a6c22b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0d4bcafda2c44cab49801dab8018a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16eb98ea27f40b8b7712ba3ae37b486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ed12aee1c7460abb6c320bcdbc208a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b424f73c6a549e0a0293a852366514b",
              "IPY_MODEL_749b447c559a41818dff382d345882a1",
              "IPY_MODEL_a78712a33a524baba749f1c7e54a6433"
            ],
            "layout": "IPY_MODEL_ff264ad7714e462f8a331a56e0010818"
          }
        },
        "5b424f73c6a549e0a0293a852366514b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc67c4561e84439ea3071b82e80c7cba",
            "placeholder": "​",
            "style": "IPY_MODEL_4ca16b35ad6b43afae0a7f4075f93453",
            "value": "merges.txt: "
          }
        },
        "749b447c559a41818dff382d345882a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92728534d8d4fbe87358caa9eeeb626",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97dc395ba1a6433f883b5b44d3ec8adf",
            "value": 1
          }
        },
        "a78712a33a524baba749f1c7e54a6433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5dc20b802f40bd9f62a657caf4b8a0",
            "placeholder": "​",
            "style": "IPY_MODEL_01c25f8598e2421e96055b12f3de5f41",
            "value": " 456k/? [00:00&lt;00:00, 32.0MB/s]"
          }
        },
        "ff264ad7714e462f8a331a56e0010818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc67c4561e84439ea3071b82e80c7cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca16b35ad6b43afae0a7f4075f93453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c92728534d8d4fbe87358caa9eeeb626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "97dc395ba1a6433f883b5b44d3ec8adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f5dc20b802f40bd9f62a657caf4b8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c25f8598e2421e96055b12f3de5f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8517666e7a4619afa4e07a25d5db18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9afc5690e260427083c908bd0e69c2bf",
              "IPY_MODEL_005ca838a88f4d0eb7d97dbb6c339bd9",
              "IPY_MODEL_3dbe9c3e7f6d429c9a5938f6e95e25c2"
            ],
            "layout": "IPY_MODEL_a2222862d224431db68301f93280bd2e"
          }
        },
        "9afc5690e260427083c908bd0e69c2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cdd7173e3347919bcff9ad6f2fd272",
            "placeholder": "​",
            "style": "IPY_MODEL_155023b29f5f4e47920b3cac4c5a811b",
            "value": "tokenizer.json: "
          }
        },
        "005ca838a88f4d0eb7d97dbb6c339bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4768fd34ef83469e888e64ac58ecbc89",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2574691fa37643689f187a56ace6e424",
            "value": 1
          }
        },
        "3dbe9c3e7f6d429c9a5938f6e95e25c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e8a97005754141a7ddbd5039b63a01",
            "placeholder": "​",
            "style": "IPY_MODEL_49f7c3dbab1447d6b87f7f4ed56e1f19",
            "value": " 2.11M/? [00:00&lt;00:00, 98.8MB/s]"
          }
        },
        "a2222862d224431db68301f93280bd2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cdd7173e3347919bcff9ad6f2fd272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155023b29f5f4e47920b3cac4c5a811b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4768fd34ef83469e888e64ac58ecbc89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2574691fa37643689f187a56ace6e424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05e8a97005754141a7ddbd5039b63a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f7c3dbab1447d6b87f7f4ed56e1f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd124a8605734bb9b2f5a8578f200aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f766f3fda444de6970b340dce4d1595",
              "IPY_MODEL_4f65a5f89936446ebfcbc62273402014",
              "IPY_MODEL_727c326635bf48b5b527beff0373961c"
            ],
            "layout": "IPY_MODEL_14bce312c2244b528f33a7a687065fea"
          }
        },
        "2f766f3fda444de6970b340dce4d1595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e75e48df19444f75b6f3aec169b2c63c",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab8d5d8dbe0425bb2ce6ea964cf657a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4f65a5f89936446ebfcbc62273402014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4984fb80953148deb2d3f22f9f084f1f",
            "max": 280,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a65f81c72dd4541836822d39b055995",
            "value": 280
          }
        },
        "727c326635bf48b5b527beff0373961c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1708670f2d448ad93c8b74b9df4da02",
            "placeholder": "​",
            "style": "IPY_MODEL_00c2b59dc6a84b5a8d295ea1cd8975ea",
            "value": " 280/280 [00:00&lt;00:00, 33.6kB/s]"
          }
        },
        "14bce312c2244b528f33a7a687065fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75e48df19444f75b6f3aec169b2c63c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab8d5d8dbe0425bb2ce6ea964cf657a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4984fb80953148deb2d3f22f9f084f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a65f81c72dd4541836822d39b055995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1708670f2d448ad93c8b74b9df4da02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c2b59dc6a84b5a8d295ea1cd8975ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f1bea78d5a40c2a8bc089069247eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71618480a0394c1e97b054e97fa0bc17",
              "IPY_MODEL_39285f7f516a488aaa0c978b266cbf1d",
              "IPY_MODEL_21d67dbf4ba94619a5ab8e8662c4e41e"
            ],
            "layout": "IPY_MODEL_370abcabb4744f7883c760bc53926d3c"
          }
        },
        "71618480a0394c1e97b054e97fa0bc17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2097ecf4894ca8bb5ff4d542bb316f",
            "placeholder": "​",
            "style": "IPY_MODEL_345c64ae42a5488c963e4cad04d50c24",
            "value": "config.json: "
          }
        },
        "39285f7f516a488aaa0c978b266cbf1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541ca562e0744d9299727513096d8638",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c6c1acdad0b4c3d9315559de4e4f420",
            "value": 1
          }
        },
        "21d67dbf4ba94619a5ab8e8662c4e41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5f7cfcf2ff4d94afd020891e2f70b0",
            "placeholder": "​",
            "style": "IPY_MODEL_621e3dbdc80849f2a77dd1e17f661623",
            "value": " 1.92k/? [00:00&lt;00:00, 213kB/s]"
          }
        },
        "370abcabb4744f7883c760bc53926d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2097ecf4894ca8bb5ff4d542bb316f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345c64ae42a5488c963e4cad04d50c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "541ca562e0744d9299727513096d8638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0c6c1acdad0b4c3d9315559de4e4f420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d5f7cfcf2ff4d94afd020891e2f70b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "621e3dbdc80849f2a77dd1e17f661623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88efadb6f2b843589ac31bea2a30b1b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b56c6a3da58c423f9961e0d918480494",
              "IPY_MODEL_48264b9cebfe4d5f862274217b55dc05",
              "IPY_MODEL_542bd6d484634636b7d52246ea4dc0a4"
            ],
            "layout": "IPY_MODEL_6883692759704b28933027bfe451c7d6"
          }
        },
        "b56c6a3da58c423f9961e0d918480494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbeff08377b741b6b137ce172254e596",
            "placeholder": "​",
            "style": "IPY_MODEL_97e5827266e84ce582c1a8c879214f31",
            "value": "model.safetensors: 100%"
          }
        },
        "48264b9cebfe4d5f862274217b55dc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2cad09459f848deae4eb1341f6fe837",
            "max": 498697004,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af4aadd5f1614b7e92d0025cea3ae597",
            "value": 498697004
          }
        },
        "542bd6d484634636b7d52246ea4dc0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_719760902d0f40898edc18f70f91ed5f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b38f263daa34fdaaf9e03f3301f248a",
            "value": " 499M/499M [00:01&lt;00:00, 482MB/s]"
          }
        },
        "6883692759704b28933027bfe451c7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeff08377b741b6b137ce172254e596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e5827266e84ce582c1a8c879214f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2cad09459f848deae4eb1341f6fe837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4aadd5f1614b7e92d0025cea3ae597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "719760902d0f40898edc18f70f91ed5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b38f263daa34fdaaf9e03f3301f248a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A2nN92o530H",
        "outputId": "38fa3905-f6a1-406e-95f6-184f5dd2f9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e4c36f1fcd769c5a49686e1cf88964698ca4deb9bb79866c58e0cc2ca5af4791\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline GPT2\n"
      ],
      "metadata": {
        "id": "ieGsKaXiYjCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Baseline Model Functions ======================\n",
        "def load_baseline_gpt2(device='cuda'):\n",
        "    \"\"\"Load vanilla GPT-2 model without custom tokenizer\"\"\"\n",
        "    print(\"Loading vanilla GPT-2 model...\")\n",
        "\n",
        "    # Load standard GPT-2 tokenizer and model\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"Vanilla GPT-2 loaded with vocab size: {len(tokenizer)}\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_emotion_classifier(device='cuda'):\n",
        "    \"\"\"Load RoBERTa emotion classifier\"\"\"\n",
        "    print(\"Loading emotion classifier...\")\n",
        "    emotion_tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
        "    emotion_model = AutoModelForSequenceClassification.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
        "    emotion_model.to(device)\n",
        "    emotion_model.eval()\n",
        "\n",
        "    return emotion_model, emotion_tokenizer\n",
        "\n",
        "def extract_user_input_for_baseline(input_text, use_full_input=False):\n",
        "    \"\"\"\n",
        "    Extract input for baseline GPT-2\n",
        "\n",
        "    Args:\n",
        "        input_text: Full structured input\n",
        "        use_full_input: If True, use full input (GPT-2 will see unknown tokens)\n",
        "                       If False, extract just user text (default)\n",
        "    \"\"\"\n",
        "    if use_full_input:\n",
        "        # Return full input\n",
        "        return input_text\n",
        "\n",
        "    # Extract just the user text (default behavior for fair comparison)\n",
        "    user_match = re.search(r'<user>(.*?)(?:<user_emotion>|<therapist>)', input_text)\n",
        "    if user_match:\n",
        "        user_text = user_match.group(1).strip()\n",
        "        return user_text\n",
        "\n",
        "    # Fallback: try to extract any text after <user>\n",
        "    user_match = re.search(r'<user>(.*)', input_text)\n",
        "    if user_match:\n",
        "        return user_match.group(1).strip()\n",
        "\n",
        "    # Last fallback: return the input as is\n",
        "    return input_text\n",
        "\n",
        "def predict_emotion_roberta(text, emotion_model, emotion_tokenizer, device='cuda'):\n",
        "    \"\"\"Predict emotion using RoBERTa model, constrained to therapy emotions\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "    # Define therapy emotions we care about\n",
        "    therapy_emotions = ['anger', 'joy', 'neutral', 'sadness', 'depression', 'disgust', 'fear']\n",
        "\n",
        "    # Tokenize and predict\n",
        "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = emotion_model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Get all emotion labels from RoBERTa model\n",
        "    emotion_labels = emotion_model.config.id2label\n",
        "\n",
        "    emotion_mapping = {\n",
        "        # Direct matches\n",
        "        'anger': 'anger',\n",
        "        'joy': 'joy',\n",
        "        'sadness': 'sadness',\n",
        "        'fear': 'fear',\n",
        "        'disgust': 'disgust',\n",
        "        'neutral': 'neutral',\n",
        "\n",
        "        # Joy-related emotions\n",
        "        'amusement': 'joy',\n",
        "        'excitement': 'joy',\n",
        "        'gratitude': 'joy',\n",
        "        'love': 'joy',\n",
        "        'optimism': 'joy',\n",
        "        'pride': 'joy',\n",
        "        'relief': 'joy',\n",
        "        'admiration': 'joy',\n",
        "\n",
        "        # Sadness-related emotions (potential depression indicators)\n",
        "        'disappointment': 'sadness',\n",
        "        'embarrassment': 'sadness',\n",
        "        'grief': 'sadness',\n",
        "        'remorse': 'sadness',\n",
        "\n",
        "        # Anger-related emotions\n",
        "        'annoyance': 'anger',\n",
        "        'disapproval': 'anger',\n",
        "\n",
        "        # Fear-related emotions\n",
        "        'nervousness': 'fear',\n",
        "\n",
        "        # Neutral-related emotions\n",
        "        'approval': 'neutral',\n",
        "        'caring': 'neutral',\n",
        "        'confusion': 'neutral',\n",
        "        'curiosity': 'neutral',\n",
        "        'desire': 'neutral',\n",
        "        'realization': 'neutral',\n",
        "        'surprise': 'neutral'\n",
        "    }\n",
        "\n",
        "    # Aggregate scores for therapy emotions\n",
        "    therapy_scores = {emotion: 0.0 for emotion in therapy_emotions}\n",
        "\n",
        "    for class_id, score in enumerate(predictions[0]):\n",
        "        go_emotion = emotion_labels[class_id]\n",
        "        therapy_emotion = emotion_mapping.get(go_emotion, 'neutral')\n",
        "        therapy_scores[therapy_emotion] += score.item()\n",
        "\n",
        "    # Find the therapy emotion with highest score\n",
        "    best_emotion = max(therapy_scores, key=therapy_scores.get)\n",
        "    best_score = therapy_scores[best_emotion]\n",
        "\n",
        "    # Enhanced depression detection based on strong indicators\n",
        "    if best_emotion == 'sadness':\n",
        "        depression_indicators = ['grief', 'remorse', 'disappointment', 'embarrassment']\n",
        "        depression_score = sum(predictions[0][class_id].item()\n",
        "                              for class_id, label in emotion_labels.items()\n",
        "                              if label in depression_indicators)\n",
        "\n",
        "        if depression_score > 0.2 or (emotion_labels.get(predictions[0].argmax().item()) in ['grief', 'remorse']):\n",
        "            best_emotion = 'depression'\n",
        "            best_score = depression_score\n",
        "\n",
        "    return best_emotion, best_score\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDataset:\n",
        "    \"\"\"Dataset class for evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt\n",
        "                    input_parts = []\n",
        "                    if problem_type:\n",
        "                        input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                    input_parts.append(f\"<user>{combined_user_text}\")\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.append(f\"<user_emotion>{last_user_emotion}\")\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \" \".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_baseline(evaluation_dataset, device='cuda', top_p=0.8, max_new_tokens=128, use_full_input=False):\n",
        "    \"\"\"\n",
        "    Evaluate vanilla GPT-2 model on therapy dataset with emotion detection\n",
        "\n",
        "    Args:\n",
        "        evaluation_dataset: TherapyEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        top_p: Top-p sampling parameter\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        use_full_input: If True, feed full structured input to GPT-2\n",
        "                       If False, extract just user text (default for fair comparison)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    # Load baseline model and emotion classifier\n",
        "    model, tokenizer = load_baseline_gpt2(device)\n",
        "    emotion_model, emotion_tokenizer = load_emotion_classifier(device)\n",
        "\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if use_full_input:\n",
        "        print(\"Evaluating vanilla GPT-2 with FULL structured input (will see unknown tokens)...\")\n",
        "    else:\n",
        "        print(\"Evaluating vanilla GPT-2 with extracted user text only...\")\n",
        "    print(f\"Evaluating model on {len(evaluation_data)} samples...\")\n",
        "\n",
        "    # Create progress bar\n",
        "    progress_bar = tqdm(evaluation_data, desc=\"Evaluating Baseline\",\n",
        "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Extract user input for baseline\n",
        "        user_input = extract_user_input_for_baseline(input_text, use_full_input)\n",
        "\n",
        "        # Tokenize input for vanilla GPT-2\n",
        "        input_ids = tokenizer.encode(user_input, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=True,\n",
        "                top_p=top_p,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        predicted_text = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "        # Predict emotion using RoBERTa\n",
        "        predicted_emotion, emotion_confidence = predict_emotion_roberta(\n",
        "            predicted_text, emotion_model, emotion_tokenizer, device\n",
        "        )\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower())\n",
        "        has_emotion = True\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "        # Update confusion matrix\n",
        "        emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "\n",
        "        # Store sample outputs for inspection\n",
        "        if i < 10:  # Store first 10 samples\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'user_input_extracted': user_input,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'emotion_confidence': emotion_confidence,\n",
        "                'full_response': predicted_text,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        if (i + 1) % 20 == 0 or i < 5:\n",
        "            sample_info = f\"Sample {i+1}: BLEU={bleu:.3f}, Emotion={'✓' if emotion_correct else '✗'}\"\n",
        "            progress_bar.set_description(f\"Evaluating Baseline - {sample_info}\")\n",
        "\n",
        "            if (i + 1) % 50 == 0 or i < 3:\n",
        "                print(f\"\\n\" + \"=\"*80)\n",
        "                print(f\"BASELINE SAMPLE {i+1}/{len(evaluation_data)}\")\n",
        "                print(\"=\"*80)\n",
        "                print(f\"Original Input: {input_text[:120]}...\")\n",
        "                print(f\"Processed Input: {user_input[:100]}...\")\n",
        "                if use_full_input:\n",
        "                    print(f\"Note: GPT-2 sees unknown tokens like <problem>, <user>, etc.\")\n",
        "                print(f\"Reference: {reference_text[:100]}...\")\n",
        "                print(f\"Generated: {predicted_text[:100]}...\")\n",
        "                print(f\"Ref Emotion: {reference_emotion} | Pred Emotion: {predicted_emotion} (conf: {emotion_confidence:.3f}) | Match: {'✓' if emotion_correct else '✗'}\")\n",
        "                print(f\"BLEU: {bleu:.4f} | ROUGE-1: {rouge['rouge1']:.4f} | METEOR: {meteor:.4f}\")\n",
        "                print(\"=\"*80)\n",
        "        else:\n",
        "            if i > 0:\n",
        "                avg_bleu = np.mean(results['bleu_scores'])\n",
        "                avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "                progress_bar.set_description(f\"Evaluating Baseline - Avg BLEU: {avg_bleu:.3f}, Emotion Acc: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    # Close progress bar\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['detected_format'] = 'roberta_emotion_detection'\n",
        "\n",
        "    # Print final progress summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"BASELINE EVALUATION COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed {len(evaluation_data)} samples\")\n",
        "    print(f\"Average BLEU: {results['summary']['avg_bleu']:.4f}\")\n",
        "    print(f\"Average ROUGE-1: {results['summary']['avg_rouge1']:.4f}\")\n",
        "    print(f\"Emotion Accuracy: {results['summary']['emotion_accuracy']:.4f}\")\n",
        "    print(f\"Emotion Tag Coverage: {results['summary']['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    results['model_type'] = 'baseline_gpt2_roberta_emotion'\n",
        "    if use_full_input:\n",
        "        results['model_type'] += '_full_input'\n",
        "    else:\n",
        "        results['model_type'] += '_user_only'\n",
        "\n",
        "    results['generation_params'] = {\n",
        "        'top_p': top_p,\n",
        "        'max_new_tokens': max_new_tokens,\n",
        "        'use_full_input': use_full_input\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BASELINE GPT-2 EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Model Type: {results.get('model_type', 'Unknown').upper()}\")\n",
        "    print(f\"Output Format: {results.get('detected_format', 'Unknown').upper()}\")\n",
        "\n",
        "    # Show generation parameters\n",
        "    gen_params = results.get('generation_params', {})\n",
        "    if gen_params:\n",
        "        print(f\"Generation Params: top_p={gen_params.get('top_p', 'N/A')}, \"\n",
        "              f\"max_tokens={gen_params.get('max_new_tokens', 'N/A')}, \"\n",
        "              f\"full_input={gen_params.get('use_full_input', 'N/A')}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction:\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Tag Coverage: {summary['emotion_tag_coverage']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Original Input: {sample['input'][:100]}...\")\n",
        "        print(f\"    Processed Input: {sample['user_input_extracted'][:80]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:80]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:80]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']} (conf: {sample['emotion_confidence']:.3f})\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load evaluation dataset\n",
        "    eval_dataset = TherapyEvaluationDataset(TEST_DATA_PATH)\n",
        "\n",
        "    print(\"\\n=== BASELINE WITH FULL STRUCTURED INPUT ===\")\n",
        "    baseline_full_results = evaluate_baseline(eval_dataset, DEVICE, use_full_input=True, top_p=0.8)\n",
        "    print_evaluation_results(baseline_full_results)\n"
      ],
      "metadata": {
        "id": "pGNE-2lwYdDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT Hyperparameters Tuning\n"
      ],
      "metadata": {
        "id": "c1jxop-EYtVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set seed at import\n",
        "set_seed(42)\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"Extract therapist text and emotion from model output\"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        # No emotion tag found, return entire response as text\n",
        "        return response, \"\", False\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDataset:\n",
        "    \"\"\"Dataset class for evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None, subset_size=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self.subset_size = subset_size\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        print(f\"Processing evaluation data (subset_size: {self.subset_size})...\")\n",
        "\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt\n",
        "                    input_parts = []\n",
        "                    if problem_type:\n",
        "                        input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                    input_parts.append(f\"<user>{combined_user_text}\")\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.append(f\"<user_emotion>{last_user_emotion}\")\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \" \".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "                    if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                        break\n",
        "\n",
        "            if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                break\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Fast Evaluation Function ======================\n",
        "def evaluate_hyperparameters(model, tokenizer, evaluation_dataset, device='cuda',\n",
        "                            max_new_tokens=128, top_p=0.8, top_k=0, temperature=1.0, do_sample=True,\n",
        "                            verbose=False):\n",
        "    \"\"\"\n",
        "    Fast evaluation for hyperparameter tuning\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: TherapyEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        top_k: Top-k sampling parameter\n",
        "        temperature: Temperature for sampling\n",
        "        do_sample: Whether to use sampling\n",
        "        verbose: Whether to print detailed progress\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Progress bar only if verbose\n",
        "    if verbose:\n",
        "        progress_bar = tqdm(evaluation_data, desc=f\"Eval p={top_p:.2f} k={top_k} T={temperature:.1f}\")\n",
        "        data_iter = progress_bar\n",
        "    else:\n",
        "        data_iter = evaluation_data\n",
        "\n",
        "    for i, sample in enumerate(data_iter):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "    if verbose and 'progress_bar' in locals():\n",
        "        progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    summary = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data),\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'temperature': temperature\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Automatically detect and load model\"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "    elif os.path.isdir(model_path):\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Hyperparameter Tuning Functions ======================\n",
        "def compute_combined_score(results, weights=None):\n",
        "    \"\"\"\n",
        "    Compute a combined score from multiple metrics\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary containing metric results\n",
        "        weights: Dictionary of weights for each metric\n",
        "\n",
        "    Returns:\n",
        "        Combined score (higher is better)\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'avg_bleu': 0.2,\n",
        "            'avg_rouge1': 0.15,\n",
        "            'avg_rouge2': 0.15,\n",
        "            'avg_rougeL': 0.15,\n",
        "            'avg_meteor': 0.2,\n",
        "            'emotion_accuracy': 0.1,\n",
        "            'emotion_tag_coverage': 0.05\n",
        "        }\n",
        "\n",
        "    score = 0.0\n",
        "    for metric, weight in weights.items():\n",
        "        if metric in results:\n",
        "            score += results[metric] * weight\n",
        "\n",
        "    return score\n",
        "\n",
        "def hyperparameter_search(model_path, tokenizer_path, test_data_path, device='cuda',\n",
        "                         top_p_values=None, top_k_values=None, temperature_values=None, subset_size=100,\n",
        "                         max_new_tokens=128, output_dir=None, weights=None):\n",
        "    \"\"\"\n",
        "    Perform grid search over top_p, top_k, and temperature values\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        test_data_path: Path to test JSON data\n",
        "        device: Device to run evaluation on\n",
        "        top_p_values: List of top_p values to test\n",
        "        top_k_values: List of top_k values to test\n",
        "        temperature_values: List of temperature values to test\n",
        "        subset_size: Number of samples to use for evaluation\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        output_dir: Directory to save results\n",
        "        weights: Weights for combining metrics\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all results and best parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Default hyperparameter values\n",
        "    if top_p_values is None:\n",
        "        top_p_values = [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "    if top_k_values is None:\n",
        "        top_k_values = [0, 5, 10, 20, 40, 50]  # 0 means no top_k filtering\n",
        "\n",
        "    if temperature_values is None:\n",
        "        temperature_values = [0.8, 1.0, 1.1, 1.2, 1.3, 1.4]\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    # Load evaluation dataset (subset)\n",
        "    print(f\"Loading evaluation data subset (size: {subset_size})...\")\n",
        "    eval_dataset = TherapyEvaluationDataset(test_data_path, tokenizer_path, subset_size=subset_size)\n",
        "\n",
        "    # Initialize results storage\n",
        "    all_results = []\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # Total combinations\n",
        "    total_combinations = len(top_p_values) * len(top_k_values) * len(temperature_values)\n",
        "    print(f\"Testing {total_combinations} hyperparameter combinations...\")\n",
        "    print(f\"top_p values: {top_p_values}\")\n",
        "    print(f\"top_k values: {top_k_values}\")\n",
        "    print(f\"temperature values: {temperature_values}\")\n",
        "    print(f\"Subset size: {subset_size} samples\")\n",
        "\n",
        "    # Grid search\n",
        "    combination_count = 0\n",
        "\n",
        "    for top_p in top_p_values:\n",
        "        for top_k in top_k_values:\n",
        "            for temperature in temperature_values:\n",
        "                combination_count += 1\n",
        "\n",
        "                print(f\"\\n[{combination_count}/{total_combinations}] Testing top_p={top_p}, top_k={top_k}, temp={temperature}\")\n",
        "\n",
        "                # Evaluate with current hyperparameters\n",
        "                results = evaluate_hyperparameters(\n",
        "                    model, tokenizer, eval_dataset, device,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    top_p=top_p, top_k=top_k, temperature=temperature,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                # Compute combined score\n",
        "                combined_score = compute_combined_score(results, weights)\n",
        "                results['combined_score'] = combined_score\n",
        "\n",
        "                # Store results\n",
        "                all_results.append(results)\n",
        "\n",
        "                # Check if this is the best so far\n",
        "                if combined_score > best_score:\n",
        "                    best_score = combined_score\n",
        "                    best_params = {'top_p': top_p, 'top_k': top_k, 'temperature': temperature}\n",
        "                    print(f\"  *** NEW BEST *** Score: {combined_score:.4f}\")\n",
        "\n",
        "                # Print current results\n",
        "                print(f\"  BLEU: {results['avg_bleu']:.4f}, \"\n",
        "                      f\"ROUGE-1: {results['avg_rouge1']:.4f}, \"\n",
        "                      f\"ROUGE-2: {results['avg_rouge2']:.4f}, \"\n",
        "                      f\"ROUGE-L: {results['avg_rougeL']:.4f}, \"\n",
        "                      f\"METEOR: {results['avg_meteor']:.4f}, \"\n",
        "                      f\"Emotion: {results['emotion_accuracy']:.4f}, \"\n",
        "                      f\"Combined: {combined_score:.4f}\")\n",
        "\n",
        "    # Compile final results\n",
        "    final_results = {\n",
        "        'best_params': best_params,\n",
        "        'best_score': best_score,\n",
        "        'all_results': all_results,\n",
        "        'model_path': model_path,\n",
        "        'model_type': model_type,\n",
        "        'subset_size': subset_size,\n",
        "        'search_space': {\n",
        "            'top_p_values': top_p_values,\n",
        "            'top_k_values': top_k_values,\n",
        "            'temperature_values': temperature_values\n",
        "        },\n",
        "        'weights': weights or {\n",
        "            'avg_bleu': 0.2,\n",
        "            'avg_rouge1': 0.15,\n",
        "            'avg_rouge2': 0.15,\n",
        "            'avg_rougeL': 0.15,\n",
        "            'avg_meteor': 0.2,\n",
        "            'emotion_accuracy': 0.1,\n",
        "            'emotion_tag_coverage': 0.05\n",
        "        },\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"HYPERPARAMETER SEARCH COMPLETED\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Best parameters: top_p={best_params['top_p']}, top_k={best_params['top_k']}, temperature={best_params['temperature']}\")\n",
        "    print(f\"Best combined score: {best_score:.4f}\")\n",
        "\n",
        "    # Find best result details\n",
        "    best_result = max(all_results, key=lambda x: x['combined_score'])\n",
        "    print(f\"\\nBest result details:\")\n",
        "    print(f\"  BLEU Score: {best_result['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1: {best_result['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2: {best_result['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L: {best_result['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR: {best_result['avg_meteor']:.4f}\")\n",
        "    print(f\"  Emotion Accuracy: {best_result['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Coverage: {best_result['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"  Combined Score: {best_result['combined_score']:.4f}\")\n",
        "\n",
        "    # Save results if output directory specified\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_file = os.path.join(output_dir, f\"hyperparameter_search_{timestamp}.pkl\")\n",
        "\n",
        "        with open(results_file, 'wb') as f:\n",
        "            pickle.dump(final_results, f)\n",
        "\n",
        "        print(f\"\\nResults saved to: {results_file}\")\n",
        "\n",
        "        # Also save a summary CSV\n",
        "        import pandas as pd\n",
        "        df_results = pd.DataFrame(all_results)\n",
        "        csv_file = os.path.join(output_dir, f\"hyperparameter_results_{timestamp}.csv\")\n",
        "        df_results.to_csv(csv_file, index=False)\n",
        "        print(f\"CSV summary saved to: {csv_file}\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def analyze_results(results_file):\n",
        "    \"\"\"Analyze hyperparameter search results\"\"\"\n",
        "    with open(results_file, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(results['all_results'])\n",
        "\n",
        "    print(f\"Hyperparameter Search Analysis\")\n",
        "    print(f\"=\" * 50)\n",
        "    print(f\"Model: {results['model_path']}\")\n",
        "    print(f\"Search completed: {results['timestamp']}\")\n",
        "    print(f\"Total combinations tested: {len(df)}\")\n",
        "\n",
        "    # Top 5 results\n",
        "    print(f\"\\nTop 5 Results:\")\n",
        "    top_5 = df.nlargest(5, 'combined_score')[['top_p', 'top_k', 'temperature', 'avg_bleu', 'avg_rouge1',\n",
        "                                              'avg_rouge2', 'avg_rougeL', 'avg_meteor',\n",
        "                                              'emotion_accuracy', 'combined_score']]\n",
        "    print(top_5.to_string(index=False))\n",
        "\n",
        "    print(f\"\\nBest parameters for each metric:\")\n",
        "    for metric in ['avg_bleu', 'avg_rouge1', 'avg_rouge2', 'avg_rougeL', 'avg_meteor', 'emotion_accuracy']:\n",
        "        best_row = df.loc[df[metric].idxmax()]\n",
        "        print(f\"  {metric}: top_p={best_row['top_p']}, top_k={best_row['top_k']}, temp={best_row['temperature']} (score: {best_row[metric]:.4f})\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\"\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/SFThyperparameter_search1\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    TOP_P_VALUES = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "    TOP_K_VALUES = [0, 5, 10, 15, 20, 25, 30, 35]\n",
        "    TEMPERATURE_VALUES = [1.0, 1.1, 1.2, 1.3]\n",
        "\n",
        "    SUBSET_SIZE = 100\n",
        "\n",
        "    CUSTOM_WEIGHTS = None\n",
        "\n",
        "    # Run hyperparameter search\n",
        "    results = hyperparameter_search(\n",
        "        model_path=MODEL_PATH,\n",
        "        tokenizer_path=TOKENIZER_PATH,\n",
        "        test_data_path=TEST_DATA_PATH,\n",
        "        device=DEVICE,\n",
        "        top_p_values=TOP_P_VALUES,\n",
        "        top_k_values=TOP_K_VALUES,\n",
        "        temperature_values=TEMPERATURE_VALUES,\n",
        "        subset_size=SUBSET_SIZE,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        weights=CUSTOM_WEIGHTS\n",
        "    )\n",
        "\n",
        "    print(f\"\\nBest hyperparameters found:\")\n",
        "    print(f\"top_p: {results['best_params']['top_p']}\")\n",
        "    print(f\"top_k: {results['best_params']['top_k']}\")\n",
        "    print(f\"temperature: {results['best_params']['temperature']}\")\n",
        "    print(f\"Score: {results['best_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3ad3024ca3e04ca7a62c3e41714d747e",
            "2abe4264e1474037a726e41b01557efd",
            "596c14d559fd4b028531541ac0270e84",
            "8948ec4e12c84edfadb90c22d6548d16",
            "1bf26f8b1e8046a984aabe04731ea4e6",
            "f0954f4d608543c2b757e74d1183b714",
            "d9dbc57b745b432abdbaed2db6f15982",
            "a568f1e4ec6746cbb26f8dd2b4b794ef",
            "2d8cc5fc152f42aab6aa6ea668cba569",
            "049b3b94ab4e43798b6cdab53687970c",
            "ca67ac60115a4a13a6d54b4b946c5423",
            "1e335eb4643f4443bcd341c951071332",
            "b22260feb0ba40b5b4ae1b6fcddd3427",
            "b9ff13b3bf1b4262ae10d476dba077c1",
            "50f57ad807a649d49ec7903ab8df4442",
            "6f94c0cac47c4b6e85c02f749e630785",
            "6eff735d39c647d09e58ec501b8e9988",
            "463849ce2b3c407185eb32447f01d1da",
            "7301136eef744c34af7c5dfdabbe380d",
            "3a098912c82345f4aa6b4b7bd1a3fa55",
            "92972e31400a43e8915a0d97e9d73132",
            "366dad0292af46d5af6dbbf4e4ec3130",
            "5bad7976c22f484a925c9f62a9df2f3f",
            "e4350c79266b4b968ca2e135e5c2617e",
            "b4074d252f174e049604b4bc7bfd8202",
            "8189026d00fe4b1daa954dbef83df60b",
            "02850156ff124b9680f123c583f6bd2c",
            "52a4ef4994c04a4192f35fd9789e0ecb",
            "b569deb6d6f44febb17f28af843dea40",
            "71b71388bba94cf5ac7f5ab5cbdc8d98",
            "bc6f2b5d0d8e4616b2241343b8142c0c",
            "0cded45b23cf4d8fb970538a09310866",
            "936102cd06a046d2abc70ebd16cd04d2"
          ]
        },
        "id": "PytEtsP9mBUh",
        "outputId": "801f2343-d5e2-42e0-c2ae-e7789dcf133f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt...\n",
            "Detected SFT checkpoint file\n",
            "Loading SFT checkpoint: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ad3024ca3e04ca7a62c3e41714d747e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e335eb4643f4443bcd341c951071332"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bad7976c22f484a925c9f62a9df2f3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SFT model successfully\n",
            "Loading evaluation data subset (size: 100)...\n",
            "Processing evaluation data (subset_size: 100)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing evaluation data:  24%|██▎       | 24/102 [00:00<00:00, 5276.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100 evaluation samples\n",
            "Testing 256 hyperparameter combinations...\n",
            "top_p values: [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
            "top_k values: [0, 5, 10, 15, 20, 25, 30, 35]\n",
            "temperature values: [1.0, 1.1, 1.2, 1.3]\n",
            "Subset size: 100 samples\n",
            "\n",
            "[1/256] Testing top_p=0.6, top_k=0, temp=1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  *** NEW BEST *** Score: 0.2035\n",
            "  BLEU: 0.0153, ROUGE-1: 0.1341, ROUGE-2: 0.0313, ROUGE-L: 0.1273, METEOR: 0.0627, Emotion: 0.9400, Combined: 0.2035\n",
            "\n",
            "[2/256] Testing top_p=0.6, top_k=0, temp=1.1\n",
            "  BLEU: 0.0148, ROUGE-1: 0.1206, ROUGE-2: 0.0162, ROUGE-L: 0.1143, METEOR: 0.0577, Emotion: 0.8900, Combined: 0.1906\n",
            "\n",
            "[3/256] Testing top_p=0.6, top_k=0, temp=1.2\n",
            "  BLEU: 0.0136, ROUGE-1: 0.1116, ROUGE-2: 0.0209, ROUGE-L: 0.1042, METEOR: 0.0576, Emotion: 0.8300, Combined: 0.1802\n",
            "\n",
            "[4/256] Testing top_p=0.6, top_k=0, temp=1.3\n",
            "  BLEU: 0.0078, ROUGE-1: 0.0800, ROUGE-2: 0.0017, ROUGE-L: 0.0761, METEOR: 0.0520, Emotion: 0.7700, Combined: 0.1571\n",
            "\n",
            "[5/256] Testing top_p=0.6, top_k=5, temp=1.0\n",
            "  BLEU: 0.0155, ROUGE-1: 0.1291, ROUGE-2: 0.0251, ROUGE-L: 0.1256, METEOR: 0.0593, Emotion: 0.9700, Combined: 0.2034\n",
            "\n",
            "[6/256] Testing top_p=0.6, top_k=5, temp=1.1\n",
            "  BLEU: 0.0130, ROUGE-1: 0.1354, ROUGE-2: 0.0187, ROUGE-L: 0.1275, METEOR: 0.0608, Emotion: 0.9300, Combined: 0.2000\n",
            "\n",
            "[7/256] Testing top_p=0.6, top_k=5, temp=1.2\n",
            "  BLEU: 0.0171, ROUGE-1: 0.1383, ROUGE-2: 0.0277, ROUGE-L: 0.1321, METEOR: 0.0630, Emotion: 0.9100, Combined: 0.2012\n",
            "\n",
            "[8/256] Testing top_p=0.6, top_k=5, temp=1.3\n",
            "  BLEU: 0.0177, ROUGE-1: 0.1374, ROUGE-2: 0.0212, ROUGE-L: 0.1304, METEOR: 0.0601, Emotion: 0.9100, Combined: 0.1999\n",
            "\n",
            "[9/256] Testing top_p=0.6, top_k=10, temp=1.0\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1103, ROUGE-2: 0.0097, ROUGE-L: 0.1011, METEOR: 0.0423, Emotion: 0.9700, Combined: 0.1906\n",
            "\n",
            "[10/256] Testing top_p=0.6, top_k=10, temp=1.1\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1172, ROUGE-2: 0.0137, ROUGE-L: 0.1127, METEOR: 0.0507, Emotion: 0.9600, Combined: 0.1948\n",
            "\n",
            "[11/256] Testing top_p=0.6, top_k=10, temp=1.2\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1068, ROUGE-2: 0.0192, ROUGE-L: 0.1027, METEOR: 0.0465, Emotion: 0.9300, Combined: 0.1884\n",
            "\n",
            "[12/256] Testing top_p=0.6, top_k=10, temp=1.3\n",
            "  BLEU: 0.0208, ROUGE-1: 0.1491, ROUGE-2: 0.0281, ROUGE-L: 0.1362, METEOR: 0.0736, Emotion: 0.8800, Combined: 0.2034\n",
            "\n",
            "[13/256] Testing top_p=0.6, top_k=15, temp=1.0\n",
            "  BLEU: 0.0149, ROUGE-1: 0.1276, ROUGE-2: 0.0241, ROUGE-L: 0.1232, METEOR: 0.0597, Emotion: 0.9100, Combined: 0.1972\n",
            "\n",
            "[14/256] Testing top_p=0.6, top_k=15, temp=1.1\n",
            "  *** NEW BEST *** Score: 0.2046\n",
            "  BLEU: 0.0214, ROUGE-1: 0.1440, ROUGE-2: 0.0306, ROUGE-L: 0.1373, METEOR: 0.0575, Emotion: 0.9200, Combined: 0.2046\n",
            "\n",
            "[15/256] Testing top_p=0.6, top_k=15, temp=1.2\n",
            "  BLEU: 0.0138, ROUGE-1: 0.1299, ROUGE-2: 0.0138, ROUGE-L: 0.1148, METEOR: 0.0618, Emotion: 0.9100, Combined: 0.1939\n",
            "\n",
            "[16/256] Testing top_p=0.6, top_k=15, temp=1.3\n",
            "  *** NEW BEST *** Score: 0.2070\n",
            "  BLEU: 0.0143, ROUGE-1: 0.1517, ROUGE-2: 0.0243, ROUGE-L: 0.1392, METEOR: 0.0745, Emotion: 0.9200, Combined: 0.2070\n",
            "\n",
            "[17/256] Testing top_p=0.6, top_k=20, temp=1.0\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1394, ROUGE-2: 0.0234, ROUGE-L: 0.1325, METEOR: 0.0520, Emotion: 0.9300, Combined: 0.1996\n",
            "\n",
            "[18/256] Testing top_p=0.6, top_k=20, temp=1.1\n",
            "  BLEU: 0.0139, ROUGE-1: 0.1537, ROUGE-2: 0.0229, ROUGE-L: 0.1405, METEOR: 0.0653, Emotion: 0.9300, Combined: 0.2064\n",
            "\n",
            "[19/256] Testing top_p=0.6, top_k=20, temp=1.2\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1058, ROUGE-2: 0.0066, ROUGE-L: 0.1024, METEOR: 0.0403, Emotion: 0.9200, Combined: 0.1843\n",
            "\n",
            "[20/256] Testing top_p=0.6, top_k=20, temp=1.3\n",
            "  BLEU: 0.0217, ROUGE-1: 0.1384, ROUGE-2: 0.0250, ROUGE-L: 0.1237, METEOR: 0.0629, Emotion: 0.8400, Combined: 0.1930\n",
            "\n",
            "[21/256] Testing top_p=0.6, top_k=25, temp=1.0\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1228, ROUGE-2: 0.0182, ROUGE-L: 0.1127, METEOR: 0.0521, Emotion: 0.9400, Combined: 0.1946\n",
            "\n",
            "[22/256] Testing top_p=0.6, top_k=25, temp=1.1\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1333, ROUGE-2: 0.0211, ROUGE-L: 0.1308, METEOR: 0.0708, Emotion: 0.8900, Combined: 0.1981\n",
            "\n",
            "[23/256] Testing top_p=0.6, top_k=25, temp=1.2\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1222, ROUGE-2: 0.0100, ROUGE-L: 0.1134, METEOR: 0.0538, Emotion: 0.9000, Combined: 0.1895\n",
            "\n",
            "[24/256] Testing top_p=0.6, top_k=25, temp=1.3\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1059, ROUGE-2: 0.0054, ROUGE-L: 0.0991, METEOR: 0.0481, Emotion: 0.9200, Combined: 0.1853\n",
            "\n",
            "[25/256] Testing top_p=0.6, top_k=30, temp=1.0\n",
            "  *** NEW BEST *** Score: 0.2222\n",
            "  BLEU: 0.0275, ROUGE-1: 0.1645, ROUGE-2: 0.0370, ROUGE-L: 0.1535, METEOR: 0.0875, Emotion: 0.9600, Combined: 0.2222\n",
            "\n",
            "[26/256] Testing top_p=0.6, top_k=30, temp=1.1\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1234, ROUGE-2: 0.0105, ROUGE-L: 0.1196, METEOR: 0.0434, Emotion: 0.9200, Combined: 0.1893\n",
            "\n",
            "[27/256] Testing top_p=0.6, top_k=30, temp=1.2\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1138, ROUGE-2: 0.0223, ROUGE-L: 0.1113, METEOR: 0.0500, Emotion: 0.8900, Combined: 0.1882\n",
            "\n",
            "[28/256] Testing top_p=0.6, top_k=30, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1212, ROUGE-2: 0.0191, ROUGE-L: 0.1160, METEOR: 0.0454, Emotion: 0.8700, Combined: 0.1858\n",
            "\n",
            "[29/256] Testing top_p=0.6, top_k=35, temp=1.0\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1211, ROUGE-2: 0.0128, ROUGE-L: 0.1155, METEOR: 0.0545, Emotion: 0.9000, Combined: 0.1903\n",
            "\n",
            "[30/256] Testing top_p=0.6, top_k=35, temp=1.1\n",
            "  BLEU: 0.0129, ROUGE-1: 0.1315, ROUGE-2: 0.0209, ROUGE-L: 0.1279, METEOR: 0.0591, Emotion: 0.9000, Combined: 0.1964\n",
            "\n",
            "[31/256] Testing top_p=0.6, top_k=35, temp=1.2\n",
            "  BLEU: 0.0312, ROUGE-1: 0.1539, ROUGE-2: 0.0416, ROUGE-L: 0.1507, METEOR: 0.0841, Emotion: 0.9000, Combined: 0.2150\n",
            "\n",
            "[32/256] Testing top_p=0.6, top_k=35, temp=1.3\n",
            "  BLEU: 0.0139, ROUGE-1: 0.1331, ROUGE-2: 0.0144, ROUGE-L: 0.1226, METEOR: 0.0648, Emotion: 0.8700, Combined: 0.1928\n",
            "\n",
            "[33/256] Testing top_p=0.65, top_k=0, temp=1.0\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1317, ROUGE-2: 0.0184, ROUGE-L: 0.1242, METEOR: 0.0506, Emotion: 0.8500, Combined: 0.1870\n",
            "\n",
            "[34/256] Testing top_p=0.65, top_k=0, temp=1.1\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1199, ROUGE-2: 0.0140, ROUGE-L: 0.1139, METEOR: 0.0524, Emotion: 0.8800, Combined: 0.1879\n",
            "\n",
            "[35/256] Testing top_p=0.65, top_k=0, temp=1.2\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1151, ROUGE-2: 0.0085, ROUGE-L: 0.1092, METEOR: 0.0549, Emotion: 0.8000, Combined: 0.1756\n",
            "\n",
            "[36/256] Testing top_p=0.65, top_k=0, temp=1.3\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0948, ROUGE-2: 0.0112, ROUGE-L: 0.0928, METEOR: 0.0558, Emotion: 0.7500, Combined: 0.1643\n",
            "\n",
            "[37/256] Testing top_p=0.65, top_k=5, temp=1.0\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1222, ROUGE-2: 0.0130, ROUGE-L: 0.1188, METEOR: 0.0611, Emotion: 0.9300, Combined: 0.1960\n",
            "\n",
            "[38/256] Testing top_p=0.65, top_k=5, temp=1.1\n",
            "  BLEU: 0.0183, ROUGE-1: 0.1522, ROUGE-2: 0.0259, ROUGE-L: 0.1440, METEOR: 0.0702, Emotion: 0.9000, Combined: 0.2060\n",
            "\n",
            "[39/256] Testing top_p=0.65, top_k=5, temp=1.2\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1407, ROUGE-2: 0.0157, ROUGE-L: 0.1241, METEOR: 0.0523, Emotion: 0.9100, Combined: 0.1948\n",
            "\n",
            "[40/256] Testing top_p=0.65, top_k=5, temp=1.3\n",
            "  BLEU: 0.0068, ROUGE-1: 0.1013, ROUGE-2: 0.0068, ROUGE-L: 0.0928, METEOR: 0.0485, Emotion: 0.8900, Combined: 0.1797\n",
            "\n",
            "[41/256] Testing top_p=0.65, top_k=10, temp=1.0\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1198, ROUGE-2: 0.0217, ROUGE-L: 0.1104, METEOR: 0.0578, Emotion: 0.9000, Combined: 0.1916\n",
            "\n",
            "[42/256] Testing top_p=0.65, top_k=10, temp=1.1\n",
            "  BLEU: 0.0156, ROUGE-1: 0.1518, ROUGE-2: 0.0285, ROUGE-L: 0.1499, METEOR: 0.0723, Emotion: 0.8500, Combined: 0.2021\n",
            "\n",
            "[43/256] Testing top_p=0.65, top_k=10, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1150, ROUGE-2: 0.0133, ROUGE-L: 0.1111, METEOR: 0.0452, Emotion: 0.9000, Combined: 0.1867\n",
            "\n",
            "[44/256] Testing top_p=0.65, top_k=10, temp=1.3\n",
            "  BLEU: 0.0221, ROUGE-1: 0.1326, ROUGE-2: 0.0350, ROUGE-L: 0.1240, METEOR: 0.0717, Emotion: 0.8500, Combined: 0.1965\n",
            "\n",
            "[45/256] Testing top_p=0.65, top_k=15, temp=1.0\n",
            "  BLEU: 0.0172, ROUGE-1: 0.1127, ROUGE-2: 0.0297, ROUGE-L: 0.1110, METEOR: 0.0465, Emotion: 0.9500, Combined: 0.1957\n",
            "\n",
            "[46/256] Testing top_p=0.65, top_k=15, temp=1.1\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1408, ROUGE-2: 0.0164, ROUGE-L: 0.1303, METEOR: 0.0656, Emotion: 0.8900, Combined: 0.1978\n",
            "\n",
            "[47/256] Testing top_p=0.65, top_k=15, temp=1.2\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1047, ROUGE-2: 0.0112, ROUGE-L: 0.1002, METEOR: 0.0453, Emotion: 0.8300, Combined: 0.1756\n",
            "\n",
            "[48/256] Testing top_p=0.65, top_k=15, temp=1.3\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1239, ROUGE-2: 0.0158, ROUGE-L: 0.1197, METEOR: 0.0518, Emotion: 0.8500, Combined: 0.1853\n",
            "\n",
            "[49/256] Testing top_p=0.65, top_k=20, temp=1.0\n",
            "  BLEU: 0.0134, ROUGE-1: 0.1453, ROUGE-2: 0.0284, ROUGE-L: 0.1391, METEOR: 0.0711, Emotion: 0.9000, Combined: 0.2033\n",
            "\n",
            "[50/256] Testing top_p=0.65, top_k=20, temp=1.1\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1281, ROUGE-2: 0.0171, ROUGE-L: 0.1229, METEOR: 0.0547, Emotion: 0.9100, Combined: 0.1946\n",
            "\n",
            "[51/256] Testing top_p=0.65, top_k=20, temp=1.2\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1233, ROUGE-2: 0.0217, ROUGE-L: 0.1175, METEOR: 0.0583, Emotion: 0.9000, Combined: 0.1925\n",
            "\n",
            "[52/256] Testing top_p=0.65, top_k=20, temp=1.3\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1200, ROUGE-2: 0.0176, ROUGE-L: 0.1080, METEOR: 0.0600, Emotion: 0.8300, Combined: 0.1823\n",
            "\n",
            "[53/256] Testing top_p=0.65, top_k=25, temp=1.0\n",
            "  BLEU: 0.0190, ROUGE-1: 0.1362, ROUGE-2: 0.0270, ROUGE-L: 0.1317, METEOR: 0.0741, Emotion: 0.9300, Combined: 0.2059\n",
            "\n",
            "[54/256] Testing top_p=0.65, top_k=25, temp=1.1\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1274, ROUGE-2: 0.0133, ROUGE-L: 0.1187, METEOR: 0.0474, Emotion: 0.9400, Combined: 0.1944\n",
            "\n",
            "[55/256] Testing top_p=0.65, top_k=25, temp=1.2\n",
            "  BLEU: 0.0187, ROUGE-1: 0.1602, ROUGE-2: 0.0315, ROUGE-L: 0.1494, METEOR: 0.0708, Emotion: 0.8700, Combined: 0.2056\n",
            "\n",
            "[56/256] Testing top_p=0.65, top_k=25, temp=1.3\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1080, ROUGE-2: 0.0187, ROUGE-L: 0.1004, METEOR: 0.0573, Emotion: 0.8600, Combined: 0.1828\n",
            "\n",
            "[57/256] Testing top_p=0.65, top_k=30, temp=1.0\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1242, ROUGE-2: 0.0104, ROUGE-L: 0.1223, METEOR: 0.0487, Emotion: 0.9700, Combined: 0.1973\n",
            "\n",
            "[58/256] Testing top_p=0.65, top_k=30, temp=1.1\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1193, ROUGE-2: 0.0175, ROUGE-L: 0.1115, METEOR: 0.0466, Emotion: 0.8700, Combined: 0.1857\n",
            "\n",
            "[59/256] Testing top_p=0.65, top_k=30, temp=1.2\n",
            "  BLEU: 0.0156, ROUGE-1: 0.1289, ROUGE-2: 0.0192, ROUGE-L: 0.1208, METEOR: 0.0539, Emotion: 0.8100, Combined: 0.1842\n",
            "\n",
            "[60/256] Testing top_p=0.65, top_k=30, temp=1.3\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1225, ROUGE-2: 0.0095, ROUGE-L: 0.1122, METEOR: 0.0549, Emotion: 0.8600, Combined: 0.1842\n",
            "\n",
            "[61/256] Testing top_p=0.65, top_k=35, temp=1.0\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1300, ROUGE-2: 0.0205, ROUGE-L: 0.1229, METEOR: 0.0625, Emotion: 0.9200, Combined: 0.1977\n",
            "\n",
            "[62/256] Testing top_p=0.65, top_k=35, temp=1.1\n",
            "  BLEU: 0.0138, ROUGE-1: 0.1323, ROUGE-2: 0.0167, ROUGE-L: 0.1224, METEOR: 0.0675, Emotion: 0.8700, Combined: 0.1940\n",
            "\n",
            "[63/256] Testing top_p=0.65, top_k=35, temp=1.2\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1166, ROUGE-2: 0.0038, ROUGE-L: 0.1135, METEOR: 0.0501, Emotion: 0.8200, Combined: 0.1782\n",
            "\n",
            "[64/256] Testing top_p=0.65, top_k=35, temp=1.3\n",
            "  BLEU: 0.0152, ROUGE-1: 0.1240, ROUGE-2: 0.0130, ROUGE-L: 0.1162, METEOR: 0.0649, Emotion: 0.8600, Combined: 0.1890\n",
            "\n",
            "[65/256] Testing top_p=0.7, top_k=0, temp=1.0\n",
            "  BLEU: 0.0135, ROUGE-1: 0.1394, ROUGE-2: 0.0268, ROUGE-L: 0.1306, METEOR: 0.0628, Emotion: 0.8800, Combined: 0.1973\n",
            "\n",
            "[66/256] Testing top_p=0.7, top_k=0, temp=1.1\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1008, ROUGE-2: 0.0069, ROUGE-L: 0.0875, METEOR: 0.0437, Emotion: 0.8400, Combined: 0.1724\n",
            "\n",
            "[67/256] Testing top_p=0.7, top_k=0, temp=1.2\n",
            "  BLEU: 0.0070, ROUGE-1: 0.0919, ROUGE-2: 0.0048, ROUGE-L: 0.0873, METEOR: 0.0373, Emotion: 0.7900, Combined: 0.1615\n",
            "\n",
            "[68/256] Testing top_p=0.7, top_k=0, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.0928, ROUGE-2: 0.0070, ROUGE-L: 0.0885, METEOR: 0.0498, Emotion: 0.8400, Combined: 0.1711\n",
            "\n",
            "[69/256] Testing top_p=0.7, top_k=5, temp=1.0\n",
            "  BLEU: 0.0214, ROUGE-1: 0.1356, ROUGE-2: 0.0275, ROUGE-L: 0.1268, METEOR: 0.0731, Emotion: 0.9400, Combined: 0.2064\n",
            "\n",
            "[70/256] Testing top_p=0.7, top_k=5, temp=1.1\n",
            "  BLEU: 0.0129, ROUGE-1: 0.1239, ROUGE-2: 0.0146, ROUGE-L: 0.1191, METEOR: 0.0576, Emotion: 0.9100, Combined: 0.1932\n",
            "\n",
            "[71/256] Testing top_p=0.7, top_k=5, temp=1.2\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1296, ROUGE-2: 0.0176, ROUGE-L: 0.1209, METEOR: 0.0579, Emotion: 0.8800, Combined: 0.1922\n",
            "\n",
            "[72/256] Testing top_p=0.7, top_k=5, temp=1.3\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1263, ROUGE-2: 0.0149, ROUGE-L: 0.1188, METEOR: 0.0536, Emotion: 0.9400, Combined: 0.1959\n",
            "\n",
            "[73/256] Testing top_p=0.7, top_k=10, temp=1.0\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1409, ROUGE-2: 0.0177, ROUGE-L: 0.1308, METEOR: 0.0499, Emotion: 0.9000, Combined: 0.1956\n",
            "\n",
            "[74/256] Testing top_p=0.7, top_k=10, temp=1.1\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1311, ROUGE-2: 0.0150, ROUGE-L: 0.1259, METEOR: 0.0564, Emotion: 0.8500, Combined: 0.1889\n",
            "\n",
            "[75/256] Testing top_p=0.7, top_k=10, temp=1.2\n",
            "  BLEU: 0.0074, ROUGE-1: 0.0890, ROUGE-2: 0.0025, ROUGE-L: 0.0832, METEOR: 0.0339, Emotion: 0.8900, Combined: 0.1735\n",
            "\n",
            "[76/256] Testing top_p=0.7, top_k=10, temp=1.3\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1292, ROUGE-2: 0.0113, ROUGE-L: 0.1152, METEOR: 0.0489, Emotion: 0.8900, Combined: 0.1888\n",
            "\n",
            "[77/256] Testing top_p=0.7, top_k=15, temp=1.0\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1317, ROUGE-2: 0.0254, ROUGE-L: 0.1282, METEOR: 0.0639, Emotion: 0.9200, Combined: 0.2000\n",
            "\n",
            "[78/256] Testing top_p=0.7, top_k=15, temp=1.1\n",
            "  BLEU: 0.0167, ROUGE-1: 0.1223, ROUGE-2: 0.0164, ROUGE-L: 0.1102, METEOR: 0.0483, Emotion: 0.9100, Combined: 0.1913\n",
            "\n",
            "[79/256] Testing top_p=0.7, top_k=15, temp=1.2\n",
            "  BLEU: 0.0138, ROUGE-1: 0.1401, ROUGE-2: 0.0214, ROUGE-L: 0.1268, METEOR: 0.0591, Emotion: 0.8000, Combined: 0.1873\n",
            "\n",
            "[80/256] Testing top_p=0.7, top_k=15, temp=1.3\n",
            "  BLEU: 0.0165, ROUGE-1: 0.1245, ROUGE-2: 0.0208, ROUGE-L: 0.1209, METEOR: 0.0595, Emotion: 0.8500, Combined: 0.1876\n",
            "\n",
            "[81/256] Testing top_p=0.7, top_k=20, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1188, ROUGE-2: 0.0108, ROUGE-L: 0.1118, METEOR: 0.0539, Emotion: 0.8600, Combined: 0.1850\n",
            "\n",
            "[82/256] Testing top_p=0.7, top_k=20, temp=1.1\n",
            "  BLEU: 0.0137, ROUGE-1: 0.1266, ROUGE-2: 0.0168, ROUGE-L: 0.1179, METEOR: 0.0616, Emotion: 0.8700, Combined: 0.1907\n",
            "\n",
            "[83/256] Testing top_p=0.7, top_k=20, temp=1.2\n",
            "  BLEU: 0.0142, ROUGE-1: 0.1371, ROUGE-2: 0.0169, ROUGE-L: 0.1303, METEOR: 0.0660, Emotion: 0.8300, Combined: 0.1912\n",
            "\n",
            "[84/256] Testing top_p=0.7, top_k=20, temp=1.3\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1184, ROUGE-2: 0.0099, ROUGE-L: 0.1109, METEOR: 0.0629, Emotion: 0.8200, Combined: 0.1821\n",
            "\n",
            "[85/256] Testing top_p=0.7, top_k=25, temp=1.0\n",
            "  BLEU: 0.0185, ROUGE-1: 0.1349, ROUGE-2: 0.0214, ROUGE-L: 0.1264, METEOR: 0.0549, Emotion: 0.9800, Combined: 0.2051\n",
            "\n",
            "[86/256] Testing top_p=0.7, top_k=25, temp=1.1\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1390, ROUGE-2: 0.0162, ROUGE-L: 0.1339, METEOR: 0.0663, Emotion: 0.9000, Combined: 0.1991\n",
            "\n",
            "[87/256] Testing top_p=0.7, top_k=25, temp=1.2\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1152, ROUGE-2: 0.0137, ROUGE-L: 0.1037, METEOR: 0.0649, Emotion: 0.8700, Combined: 0.1860\n",
            "\n",
            "[88/256] Testing top_p=0.7, top_k=25, temp=1.3\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1154, ROUGE-2: 0.0082, ROUGE-L: 0.1109, METEOR: 0.0525, Emotion: 0.8100, Combined: 0.1772\n",
            "\n",
            "[89/256] Testing top_p=0.7, top_k=30, temp=1.0\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1211, ROUGE-2: 0.0127, ROUGE-L: 0.1151, METEOR: 0.0550, Emotion: 0.8700, Combined: 0.1877\n",
            "\n",
            "[90/256] Testing top_p=0.7, top_k=30, temp=1.1\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1271, ROUGE-2: 0.0127, ROUGE-L: 0.1190, METEOR: 0.0482, Emotion: 0.9600, Combined: 0.1968\n",
            "\n",
            "[91/256] Testing top_p=0.7, top_k=30, temp=1.2\n",
            "  BLEU: 0.0070, ROUGE-1: 0.0978, ROUGE-2: 0.0013, ROUGE-L: 0.0936, METEOR: 0.0341, Emotion: 0.7900, Combined: 0.1641\n",
            "\n",
            "[92/256] Testing top_p=0.7, top_k=30, temp=1.3\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1227, ROUGE-2: 0.0159, ROUGE-L: 0.1199, METEOR: 0.0545, Emotion: 0.8300, Combined: 0.1823\n",
            "\n",
            "[93/256] Testing top_p=0.7, top_k=35, temp=1.0\n",
            "  BLEU: 0.0148, ROUGE-1: 0.1289, ROUGE-2: 0.0316, ROUGE-L: 0.1227, METEOR: 0.0667, Emotion: 0.8700, Combined: 0.1958\n",
            "\n",
            "[94/256] Testing top_p=0.7, top_k=35, temp=1.1\n",
            "  BLEU: 0.0139, ROUGE-1: 0.1249, ROUGE-2: 0.0150, ROUGE-L: 0.1204, METEOR: 0.0554, Emotion: 0.8500, Combined: 0.1879\n",
            "\n",
            "[95/256] Testing top_p=0.7, top_k=35, temp=1.2\n",
            "  BLEU: 0.0138, ROUGE-1: 0.1148, ROUGE-2: 0.0237, ROUGE-L: 0.1061, METEOR: 0.0558, Emotion: 0.8000, Combined: 0.1801\n",
            "\n",
            "[96/256] Testing top_p=0.7, top_k=35, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1002, ROUGE-2: 0.0086, ROUGE-L: 0.0944, METEOR: 0.0535, Emotion: 0.7800, Combined: 0.1690\n",
            "\n",
            "[97/256] Testing top_p=0.75, top_k=0, temp=1.0\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1199, ROUGE-2: 0.0057, ROUGE-L: 0.1174, METEOR: 0.0544, Emotion: 0.8500, Combined: 0.1841\n",
            "\n",
            "[98/256] Testing top_p=0.75, top_k=0, temp=1.1\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1085, ROUGE-2: 0.0171, ROUGE-L: 0.1047, METEOR: 0.0545, Emotion: 0.8000, Combined: 0.1756\n",
            "\n",
            "[99/256] Testing top_p=0.75, top_k=0, temp=1.2\n",
            "  BLEU: 0.0083, ROUGE-1: 0.0929, ROUGE-2: 0.0054, ROUGE-L: 0.0859, METEOR: 0.0421, Emotion: 0.7200, Combined: 0.1567\n",
            "\n",
            "[100/256] Testing top_p=0.75, top_k=0, temp=1.3\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1001, ROUGE-2: 0.0017, ROUGE-L: 0.0962, METEOR: 0.0528, Emotion: 0.7300, Combined: 0.1616\n",
            "\n",
            "[101/256] Testing top_p=0.75, top_k=5, temp=1.0\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1154, ROUGE-2: 0.0136, ROUGE-L: 0.1142, METEOR: 0.0466, Emotion: 0.9400, Combined: 0.1916\n",
            "\n",
            "[102/256] Testing top_p=0.75, top_k=5, temp=1.1\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1300, ROUGE-2: 0.0095, ROUGE-L: 0.1172, METEOR: 0.0528, Emotion: 0.8600, Combined: 0.1862\n",
            "\n",
            "[103/256] Testing top_p=0.75, top_k=5, temp=1.2\n",
            "  BLEU: 0.0158, ROUGE-1: 0.1411, ROUGE-2: 0.0158, ROUGE-L: 0.1341, METEOR: 0.0658, Emotion: 0.7900, Combined: 0.1875\n",
            "\n",
            "[104/256] Testing top_p=0.75, top_k=5, temp=1.3\n",
            "  BLEU: 0.0090, ROUGE-1: 0.1305, ROUGE-2: 0.0158, ROUGE-L: 0.1200, METEOR: 0.0491, Emotion: 0.7600, Combined: 0.1761\n",
            "\n",
            "[105/256] Testing top_p=0.75, top_k=10, temp=1.0\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1161, ROUGE-2: 0.0165, ROUGE-L: 0.1128, METEOR: 0.0525, Emotion: 0.8900, Combined: 0.1881\n",
            "\n",
            "[106/256] Testing top_p=0.75, top_k=10, temp=1.1\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1241, ROUGE-2: 0.0074, ROUGE-L: 0.1174, METEOR: 0.0533, Emotion: 0.9100, Combined: 0.1909\n",
            "\n",
            "[107/256] Testing top_p=0.75, top_k=10, temp=1.2\n",
            "  BLEU: 0.0189, ROUGE-1: 0.1287, ROUGE-2: 0.0225, ROUGE-L: 0.1212, METEOR: 0.0615, Emotion: 0.8900, Combined: 0.1954\n",
            "\n",
            "[108/256] Testing top_p=0.75, top_k=10, temp=1.3\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1215, ROUGE-2: 0.0139, ROUGE-L: 0.1089, METEOR: 0.0610, Emotion: 0.8500, Combined: 0.1856\n",
            "\n",
            "[109/256] Testing top_p=0.75, top_k=15, temp=1.0\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1230, ROUGE-2: 0.0152, ROUGE-L: 0.1177, METEOR: 0.0578, Emotion: 0.8800, Combined: 0.1903\n",
            "\n",
            "[110/256] Testing top_p=0.75, top_k=15, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1318, ROUGE-2: 0.0076, ROUGE-L: 0.1168, METEOR: 0.0469, Emotion: 0.8900, Combined: 0.1888\n",
            "\n",
            "[111/256] Testing top_p=0.75, top_k=15, temp=1.2\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1127, ROUGE-2: 0.0127, ROUGE-L: 0.1061, METEOR: 0.0488, Emotion: 0.8200, Combined: 0.1776\n",
            "\n",
            "[112/256] Testing top_p=0.75, top_k=15, temp=1.3\n",
            "  BLEU: 0.0152, ROUGE-1: 0.1266, ROUGE-2: 0.0215, ROUGE-L: 0.1225, METEOR: 0.0514, Emotion: 0.8400, Combined: 0.1869\n",
            "\n",
            "[113/256] Testing top_p=0.75, top_k=20, temp=1.0\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1146, ROUGE-2: 0.0186, ROUGE-L: 0.1096, METEOR: 0.0592, Emotion: 0.9000, Combined: 0.1906\n",
            "\n",
            "[114/256] Testing top_p=0.75, top_k=20, temp=1.1\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1023, ROUGE-2: 0.0086, ROUGE-L: 0.0934, METEOR: 0.0441, Emotion: 0.8600, Combined: 0.1771\n",
            "\n",
            "[115/256] Testing top_p=0.75, top_k=20, temp=1.2\n",
            "  BLEU: 0.0136, ROUGE-1: 0.1107, ROUGE-2: 0.0182, ROUGE-L: 0.1061, METEOR: 0.0527, Emotion: 0.7600, Combined: 0.1735\n",
            "\n",
            "[116/256] Testing top_p=0.75, top_k=20, temp=1.3\n",
            "  BLEU: 0.0134, ROUGE-1: 0.1150, ROUGE-2: 0.0180, ROUGE-L: 0.1067, METEOR: 0.0617, Emotion: 0.8200, Combined: 0.1815\n",
            "\n",
            "[117/256] Testing top_p=0.75, top_k=25, temp=1.0\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1115, ROUGE-2: 0.0201, ROUGE-L: 0.1057, METEOR: 0.0521, Emotion: 0.8600, Combined: 0.1841\n",
            "\n",
            "[118/256] Testing top_p=0.75, top_k=25, temp=1.1\n",
            "  BLEU: 0.0162, ROUGE-1: 0.1527, ROUGE-2: 0.0242, ROUGE-L: 0.1468, METEOR: 0.0726, Emotion: 0.8700, Combined: 0.2023\n",
            "\n",
            "[119/256] Testing top_p=0.75, top_k=25, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1215, ROUGE-2: 0.0186, ROUGE-L: 0.1102, METEOR: 0.0630, Emotion: 0.8600, Combined: 0.1875\n",
            "\n",
            "[120/256] Testing top_p=0.75, top_k=25, temp=1.3\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1077, ROUGE-2: 0.0145, ROUGE-L: 0.0999, METEOR: 0.0489, Emotion: 0.8000, Combined: 0.1740\n",
            "\n",
            "[121/256] Testing top_p=0.75, top_k=30, temp=1.0\n",
            "  BLEU: 0.0117, ROUGE-1: 0.1145, ROUGE-2: 0.0223, ROUGE-L: 0.1117, METEOR: 0.0543, Emotion: 0.8700, Combined: 0.1875\n",
            "\n",
            "[122/256] Testing top_p=0.75, top_k=30, temp=1.1\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0970, ROUGE-2: 0.0065, ROUGE-L: 0.0899, METEOR: 0.0461, Emotion: 0.8500, Combined: 0.1741\n",
            "\n",
            "[123/256] Testing top_p=0.75, top_k=30, temp=1.2\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1170, ROUGE-2: 0.0131, ROUGE-L: 0.1066, METEOR: 0.0530, Emotion: 0.8400, Combined: 0.1819\n",
            "\n",
            "[124/256] Testing top_p=0.75, top_k=30, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1033, ROUGE-2: 0.0105, ROUGE-L: 0.0956, METEOR: 0.0542, Emotion: 0.8500, Combined: 0.1776\n",
            "\n",
            "[125/256] Testing top_p=0.75, top_k=35, temp=1.0\n",
            "  BLEU: 0.0204, ROUGE-1: 0.1271, ROUGE-2: 0.0328, ROUGE-L: 0.1191, METEOR: 0.0639, Emotion: 0.8600, Combined: 0.1937\n",
            "\n",
            "[126/256] Testing top_p=0.75, top_k=35, temp=1.1\n",
            "  BLEU: 0.0154, ROUGE-1: 0.1296, ROUGE-2: 0.0279, ROUGE-L: 0.1215, METEOR: 0.0618, Emotion: 0.8300, Combined: 0.1898\n",
            "\n",
            "[127/256] Testing top_p=0.75, top_k=35, temp=1.2\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1174, ROUGE-2: 0.0125, ROUGE-L: 0.1103, METEOR: 0.0607, Emotion: 0.8200, Combined: 0.1812\n",
            "\n",
            "[128/256] Testing top_p=0.75, top_k=35, temp=1.3\n",
            "  BLEU: 0.0073, ROUGE-1: 0.1032, ROUGE-2: 0.0059, ROUGE-L: 0.0961, METEOR: 0.0463, Emotion: 0.7800, Combined: 0.1660\n",
            "\n",
            "[129/256] Testing top_p=0.8, top_k=0, temp=1.0\n",
            "  BLEU: 0.0140, ROUGE-1: 0.1260, ROUGE-2: 0.0146, ROUGE-L: 0.1154, METEOR: 0.0486, Emotion: 0.7800, Combined: 0.1759\n",
            "\n",
            "[130/256] Testing top_p=0.8, top_k=0, temp=1.1\n",
            "  BLEU: 0.0106, ROUGE-1: 0.0963, ROUGE-2: 0.0134, ROUGE-L: 0.0917, METEOR: 0.0485, Emotion: 0.8300, Combined: 0.1725\n",
            "\n",
            "[131/256] Testing top_p=0.8, top_k=0, temp=1.2\n",
            "  BLEU: 0.0076, ROUGE-1: 0.0775, ROUGE-2: 0.0072, ROUGE-L: 0.0716, METEOR: 0.0368, Emotion: 0.6700, Combined: 0.1458\n",
            "\n",
            "[132/256] Testing top_p=0.8, top_k=0, temp=1.3\n",
            "  BLEU: 0.0083, ROUGE-1: 0.0861, ROUGE-2: 0.0047, ROUGE-L: 0.0805, METEOR: 0.0466, Emotion: 0.7300, Combined: 0.1537\n",
            "\n",
            "[133/256] Testing top_p=0.8, top_k=5, temp=1.0\n",
            "  BLEU: 0.0281, ROUGE-1: 0.1497, ROUGE-2: 0.0373, ROUGE-L: 0.1416, METEOR: 0.0765, Emotion: 0.8700, Combined: 0.2067\n",
            "\n",
            "[134/256] Testing top_p=0.8, top_k=5, temp=1.1\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1377, ROUGE-2: 0.0088, ROUGE-L: 0.1288, METEOR: 0.0458, Emotion: 0.8500, Combined: 0.1868\n",
            "\n",
            "[135/256] Testing top_p=0.8, top_k=5, temp=1.2\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1182, ROUGE-2: 0.0175, ROUGE-L: 0.1079, METEOR: 0.0480, Emotion: 0.8800, Combined: 0.1864\n",
            "\n",
            "[136/256] Testing top_p=0.8, top_k=5, temp=1.3\n",
            "  BLEU: 0.0176, ROUGE-1: 0.1412, ROUGE-2: 0.0239, ROUGE-L: 0.1336, METEOR: 0.0610, Emotion: 0.8300, Combined: 0.1925\n",
            "\n",
            "[137/256] Testing top_p=0.8, top_k=10, temp=1.0\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1258, ROUGE-2: 0.0175, ROUGE-L: 0.1204, METEOR: 0.0686, Emotion: 0.9100, Combined: 0.1964\n",
            "\n",
            "[138/256] Testing top_p=0.8, top_k=10, temp=1.1\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1149, ROUGE-2: 0.0148, ROUGE-L: 0.1106, METEOR: 0.0489, Emotion: 0.8400, Combined: 0.1818\n",
            "\n",
            "[139/256] Testing top_p=0.8, top_k=10, temp=1.2\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1228, ROUGE-2: 0.0075, ROUGE-L: 0.1214, METEOR: 0.0436, Emotion: 0.8500, Combined: 0.1824\n",
            "\n",
            "[140/256] Testing top_p=0.8, top_k=10, temp=1.3\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1028, ROUGE-2: 0.0052, ROUGE-L: 0.0948, METEOR: 0.0374, Emotion: 0.8300, Combined: 0.1702\n",
            "\n",
            "[141/256] Testing top_p=0.8, top_k=15, temp=1.0\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1000, ROUGE-2: 0.0088, ROUGE-L: 0.0905, METEOR: 0.0429, Emotion: 0.8900, Combined: 0.1783\n",
            "\n",
            "[142/256] Testing top_p=0.8, top_k=15, temp=1.1\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1245, ROUGE-2: 0.0107, ROUGE-L: 0.1220, METEOR: 0.0444, Emotion: 0.8600, Combined: 0.1847\n",
            "\n",
            "[143/256] Testing top_p=0.8, top_k=15, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1249, ROUGE-2: 0.0118, ROUGE-L: 0.1208, METEOR: 0.0571, Emotion: 0.8500, Combined: 0.1849\n",
            "\n",
            "[144/256] Testing top_p=0.8, top_k=15, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1003, ROUGE-2: 0.0073, ROUGE-L: 0.0946, METEOR: 0.0472, Emotion: 0.7800, Combined: 0.1661\n",
            "\n",
            "[145/256] Testing top_p=0.8, top_k=20, temp=1.0\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1247, ROUGE-2: 0.0188, ROUGE-L: 0.1190, METEOR: 0.0579, Emotion: 0.9100, Combined: 0.1944\n",
            "\n",
            "[146/256] Testing top_p=0.8, top_k=20, temp=1.1\n",
            "  BLEU: 0.0067, ROUGE-1: 0.1165, ROUGE-2: 0.0118, ROUGE-L: 0.1083, METEOR: 0.0443, Emotion: 0.8600, Combined: 0.1807\n",
            "\n",
            "[147/256] Testing top_p=0.8, top_k=20, temp=1.2\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1103, ROUGE-2: 0.0105, ROUGE-L: 0.1015, METEOR: 0.0589, Emotion: 0.7600, Combined: 0.1711\n",
            "\n",
            "[148/256] Testing top_p=0.8, top_k=20, temp=1.3\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1166, ROUGE-2: 0.0199, ROUGE-L: 0.1090, METEOR: 0.0531, Emotion: 0.8000, Combined: 0.1764\n",
            "\n",
            "[149/256] Testing top_p=0.8, top_k=25, temp=1.0\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1212, ROUGE-2: 0.0116, ROUGE-L: 0.1177, METEOR: 0.0547, Emotion: 0.8600, Combined: 0.1863\n",
            "\n",
            "[150/256] Testing top_p=0.8, top_k=25, temp=1.1\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1116, ROUGE-2: 0.0275, ROUGE-L: 0.1058, METEOR: 0.0468, Emotion: 0.8100, Combined: 0.1791\n",
            "\n",
            "[151/256] Testing top_p=0.8, top_k=25, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1238, ROUGE-2: 0.0071, ROUGE-L: 0.1115, METEOR: 0.0515, Emotion: 0.7500, Combined: 0.1711\n",
            "\n",
            "[152/256] Testing top_p=0.8, top_k=25, temp=1.3\n",
            "  BLEU: 0.0195, ROUGE-1: 0.1096, ROUGE-2: 0.0196, ROUGE-L: 0.0987, METEOR: 0.0541, Emotion: 0.7400, Combined: 0.1699\n",
            "\n",
            "[153/256] Testing top_p=0.8, top_k=30, temp=1.0\n",
            "  BLEU: 0.0150, ROUGE-1: 0.1272, ROUGE-2: 0.0124, ROUGE-L: 0.1164, METEOR: 0.0640, Emotion: 0.8300, Combined: 0.1867\n",
            "\n",
            "[154/256] Testing top_p=0.8, top_k=30, temp=1.1\n",
            "  BLEU: 0.0165, ROUGE-1: 0.1303, ROUGE-2: 0.0262, ROUGE-L: 0.1225, METEOR: 0.0682, Emotion: 0.8500, Combined: 0.1918\n",
            "\n",
            "[155/256] Testing top_p=0.8, top_k=30, temp=1.2\n",
            "  BLEU: 0.0056, ROUGE-1: 0.0907, ROUGE-2: 0.0081, ROUGE-L: 0.0791, METEOR: 0.0344, Emotion: 0.7600, Combined: 0.1572\n",
            "\n",
            "[156/256] Testing top_p=0.8, top_k=30, temp=1.3\n",
            "  BLEU: 0.0062, ROUGE-1: 0.0943, ROUGE-2: 0.0043, ROUGE-L: 0.0902, METEOR: 0.0399, Emotion: 0.6900, Combined: 0.1485\n",
            "\n",
            "[157/256] Testing top_p=0.8, top_k=35, temp=1.0\n",
            "  BLEU: 0.0149, ROUGE-1: 0.1302, ROUGE-2: 0.0089, ROUGE-L: 0.1186, METEOR: 0.0588, Emotion: 0.9000, Combined: 0.1929\n",
            "\n",
            "[158/256] Testing top_p=0.8, top_k=35, temp=1.1\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1209, ROUGE-2: 0.0133, ROUGE-L: 0.1105, METEOR: 0.0505, Emotion: 0.8100, Combined: 0.1789\n",
            "\n",
            "[159/256] Testing top_p=0.8, top_k=35, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1000, ROUGE-2: 0.0082, ROUGE-L: 0.0923, METEOR: 0.0447, Emotion: 0.7800, Combined: 0.1668\n",
            "\n",
            "[160/256] Testing top_p=0.8, top_k=35, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1115, ROUGE-2: 0.0029, ROUGE-L: 0.0982, METEOR: 0.0487, Emotion: 0.8000, Combined: 0.1690\n",
            "\n",
            "[161/256] Testing top_p=0.85, top_k=0, temp=1.0\n",
            "  BLEU: 0.0076, ROUGE-1: 0.1027, ROUGE-2: 0.0073, ROUGE-L: 0.0904, METEOR: 0.0361, Emotion: 0.8000, Combined: 0.1663\n",
            "\n",
            "[162/256] Testing top_p=0.85, top_k=0, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.0950, ROUGE-2: 0.0078, ROUGE-L: 0.0899, METEOR: 0.0462, Emotion: 0.7800, Combined: 0.1646\n",
            "\n",
            "[163/256] Testing top_p=0.85, top_k=0, temp=1.2\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0846, ROUGE-2: 0.0072, ROUGE-L: 0.0812, METEOR: 0.0412, Emotion: 0.6700, Combined: 0.1462\n",
            "\n",
            "[164/256] Testing top_p=0.85, top_k=0, temp=1.3\n",
            "  BLEU: 0.0056, ROUGE-1: 0.0807, ROUGE-2: 0.0064, ROUGE-L: 0.0719, METEOR: 0.0424, Emotion: 0.6700, Combined: 0.1440\n",
            "\n",
            "[165/256] Testing top_p=0.85, top_k=5, temp=1.0\n",
            "  BLEU: 0.0172, ROUGE-1: 0.1536, ROUGE-2: 0.0339, ROUGE-L: 0.1477, METEOR: 0.0765, Emotion: 0.8600, Combined: 0.2030\n",
            "\n",
            "[166/256] Testing top_p=0.85, top_k=5, temp=1.1\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1277, ROUGE-2: 0.0261, ROUGE-L: 0.1227, METEOR: 0.0658, Emotion: 0.9100, Combined: 0.1972\n",
            "\n",
            "[167/256] Testing top_p=0.85, top_k=5, temp=1.2\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1334, ROUGE-2: 0.0185, ROUGE-L: 0.1248, METEOR: 0.0579, Emotion: 0.8500, Combined: 0.1885\n",
            "\n",
            "[168/256] Testing top_p=0.85, top_k=5, temp=1.3\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1205, ROUGE-2: 0.0148, ROUGE-L: 0.1074, METEOR: 0.0527, Emotion: 0.8300, Combined: 0.1791\n",
            "\n",
            "[169/256] Testing top_p=0.85, top_k=10, temp=1.0\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1194, ROUGE-2: 0.0202, ROUGE-L: 0.1141, METEOR: 0.0539, Emotion: 0.8500, Combined: 0.1849\n",
            "\n",
            "[170/256] Testing top_p=0.85, top_k=10, temp=1.1\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1275, ROUGE-2: 0.0145, ROUGE-L: 0.1201, METEOR: 0.0542, Emotion: 0.8500, Combined: 0.1863\n",
            "\n",
            "[171/256] Testing top_p=0.85, top_k=10, temp=1.2\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1281, ROUGE-2: 0.0182, ROUGE-L: 0.1164, METEOR: 0.0541, Emotion: 0.7400, Combined: 0.1734\n",
            "\n",
            "[172/256] Testing top_p=0.85, top_k=10, temp=1.3\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1088, ROUGE-2: 0.0112, ROUGE-L: 0.1035, METEOR: 0.0535, Emotion: 0.7400, Combined: 0.1653\n",
            "\n",
            "[173/256] Testing top_p=0.85, top_k=15, temp=1.0\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1118, ROUGE-2: 0.0132, ROUGE-L: 0.1067, METEOR: 0.0492, Emotion: 0.8400, Combined: 0.1790\n",
            "\n",
            "[174/256] Testing top_p=0.85, top_k=15, temp=1.1\n",
            "  BLEU: 0.0131, ROUGE-1: 0.1244, ROUGE-2: 0.0152, ROUGE-L: 0.1194, METEOR: 0.0657, Emotion: 0.8400, Combined: 0.1871\n",
            "\n",
            "[175/256] Testing top_p=0.85, top_k=15, temp=1.2\n",
            "  BLEU: 0.0145, ROUGE-1: 0.1207, ROUGE-2: 0.0184, ROUGE-L: 0.1184, METEOR: 0.0561, Emotion: 0.7800, Combined: 0.1762\n",
            "\n",
            "[176/256] Testing top_p=0.85, top_k=15, temp=1.3\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1100, ROUGE-2: 0.0066, ROUGE-L: 0.1006, METEOR: 0.0527, Emotion: 0.8000, Combined: 0.1726\n",
            "\n",
            "[177/256] Testing top_p=0.85, top_k=20, temp=1.0\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1237, ROUGE-2: 0.0095, ROUGE-L: 0.1200, METEOR: 0.0569, Emotion: 0.9200, Combined: 0.1932\n",
            "\n",
            "[178/256] Testing top_p=0.85, top_k=20, temp=1.1\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1386, ROUGE-2: 0.0129, ROUGE-L: 0.1309, METEOR: 0.0607, Emotion: 0.8100, Combined: 0.1870\n",
            "\n",
            "[179/256] Testing top_p=0.85, top_k=20, temp=1.2\n",
            "  BLEU: 0.0156, ROUGE-1: 0.1245, ROUGE-2: 0.0273, ROUGE-L: 0.1227, METEOR: 0.0737, Emotion: 0.8200, Combined: 0.1895\n",
            "\n",
            "[180/256] Testing top_p=0.85, top_k=20, temp=1.3\n",
            "  BLEU: 0.0096, ROUGE-1: 0.0934, ROUGE-2: 0.0110, ROUGE-L: 0.0852, METEOR: 0.0534, Emotion: 0.7200, Combined: 0.1586\n",
            "\n",
            "[181/256] Testing top_p=0.85, top_k=25, temp=1.0\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1123, ROUGE-2: 0.0238, ROUGE-L: 0.1038, METEOR: 0.0570, Emotion: 0.8400, Combined: 0.1831\n",
            "\n",
            "[182/256] Testing top_p=0.85, top_k=25, temp=1.1\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1239, ROUGE-2: 0.0109, ROUGE-L: 0.1149, METEOR: 0.0539, Emotion: 0.7400, Combined: 0.1696\n",
            "\n",
            "[183/256] Testing top_p=0.85, top_k=25, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0941, ROUGE-2: 0.0144, ROUGE-L: 0.0853, METEOR: 0.0479, Emotion: 0.7500, Combined: 0.1611\n",
            "\n",
            "[184/256] Testing top_p=0.85, top_k=25, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.0926, ROUGE-2: 0.0056, ROUGE-L: 0.0898, METEOR: 0.0510, Emotion: 0.7700, Combined: 0.1632\n",
            "\n",
            "[185/256] Testing top_p=0.85, top_k=30, temp=1.0\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1052, ROUGE-2: 0.0066, ROUGE-L: 0.0929, METEOR: 0.0435, Emotion: 0.7800, Combined: 0.1691\n",
            "\n",
            "[186/256] Testing top_p=0.85, top_k=30, temp=1.1\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1052, ROUGE-2: 0.0135, ROUGE-L: 0.1042, METEOR: 0.0504, Emotion: 0.8300, Combined: 0.1765\n",
            "\n",
            "[187/256] Testing top_p=0.85, top_k=30, temp=1.2\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1012, ROUGE-2: 0.0095, ROUGE-L: 0.0933, METEOR: 0.0519, Emotion: 0.7100, Combined: 0.1603\n",
            "\n",
            "[188/256] Testing top_p=0.85, top_k=30, temp=1.3\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1109, ROUGE-2: 0.0129, ROUGE-L: 0.1020, METEOR: 0.0500, Emotion: 0.7600, Combined: 0.1673\n",
            "\n",
            "[189/256] Testing top_p=0.85, top_k=35, temp=1.0\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1263, ROUGE-2: 0.0138, ROUGE-L: 0.1178, METEOR: 0.0601, Emotion: 0.8900, Combined: 0.1916\n",
            "\n",
            "[190/256] Testing top_p=0.85, top_k=35, temp=1.1\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1131, ROUGE-2: 0.0065, ROUGE-L: 0.1073, METEOR: 0.0530, Emotion: 0.8500, Combined: 0.1803\n",
            "\n",
            "[191/256] Testing top_p=0.85, top_k=35, temp=1.2\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1161, ROUGE-2: 0.0098, ROUGE-L: 0.1121, METEOR: 0.0510, Emotion: 0.7100, Combined: 0.1654\n",
            "\n",
            "[192/256] Testing top_p=0.85, top_k=35, temp=1.3\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1037, ROUGE-2: 0.0080, ROUGE-L: 0.0961, METEOR: 0.0515, Emotion: 0.7100, Combined: 0.1606\n",
            "\n",
            "[193/256] Testing top_p=0.9, top_k=0, temp=1.0\n",
            "  BLEU: 0.0071, ROUGE-1: 0.1047, ROUGE-2: 0.0066, ROUGE-L: 0.0969, METEOR: 0.0447, Emotion: 0.7400, Combined: 0.1631\n",
            "\n",
            "[194/256] Testing top_p=0.9, top_k=0, temp=1.1\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0915, ROUGE-2: 0.0078, ROUGE-L: 0.0821, METEOR: 0.0404, Emotion: 0.8000, Combined: 0.1623\n",
            "\n",
            "[195/256] Testing top_p=0.9, top_k=0, temp=1.2\n",
            "  BLEU: 0.0057, ROUGE-1: 0.0699, ROUGE-2: 0.0051, ROUGE-L: 0.0639, METEOR: 0.0323, Emotion: 0.7800, Combined: 0.1529\n",
            "\n",
            "[196/256] Testing top_p=0.9, top_k=0, temp=1.3\n",
            "  BLEU: 0.0060, ROUGE-1: 0.0653, ROUGE-2: 0.0023, ROUGE-L: 0.0607, METEOR: 0.0360, Emotion: 0.7400, Combined: 0.1467\n",
            "\n",
            "[197/256] Testing top_p=0.9, top_k=5, temp=1.0\n",
            "  BLEU: 0.0163, ROUGE-1: 0.1192, ROUGE-2: 0.0198, ROUGE-L: 0.1109, METEOR: 0.0500, Emotion: 0.8500, Combined: 0.1838\n",
            "\n",
            "[198/256] Testing top_p=0.9, top_k=5, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1098, ROUGE-2: 0.0167, ROUGE-L: 0.0989, METEOR: 0.0528, Emotion: 0.8100, Combined: 0.1768\n",
            "\n",
            "[199/256] Testing top_p=0.9, top_k=5, temp=1.2\n",
            "  BLEU: 0.0154, ROUGE-1: 0.1521, ROUGE-2: 0.0330, ROUGE-L: 0.1423, METEOR: 0.0777, Emotion: 0.8300, Combined: 0.2002\n",
            "\n",
            "[200/256] Testing top_p=0.9, top_k=5, temp=1.3\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1078, ROUGE-2: 0.0221, ROUGE-L: 0.1024, METEOR: 0.0606, Emotion: 0.8100, Combined: 0.1776\n",
            "\n",
            "[201/256] Testing top_p=0.9, top_k=10, temp=1.0\n",
            "  BLEU: 0.0202, ROUGE-1: 0.1429, ROUGE-2: 0.0255, ROUGE-L: 0.1373, METEOR: 0.0706, Emotion: 0.8700, Combined: 0.1990\n",
            "\n",
            "[202/256] Testing top_p=0.9, top_k=10, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1061, ROUGE-2: 0.0214, ROUGE-L: 0.0992, METEOR: 0.0586, Emotion: 0.7500, Combined: 0.1697\n",
            "\n",
            "[203/256] Testing top_p=0.9, top_k=10, temp=1.2\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1137, ROUGE-2: 0.0098, ROUGE-L: 0.1065, METEOR: 0.0517, Emotion: 0.7900, Combined: 0.1736\n",
            "\n",
            "[204/256] Testing top_p=0.9, top_k=10, temp=1.3\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1282, ROUGE-2: 0.0094, ROUGE-L: 0.1216, METEOR: 0.0459, Emotion: 0.7500, Combined: 0.1712\n",
            "\n",
            "[205/256] Testing top_p=0.9, top_k=15, temp=1.0\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1233, ROUGE-2: 0.0132, ROUGE-L: 0.1088, METEOR: 0.0552, Emotion: 0.8300, Combined: 0.1804\n",
            "\n",
            "[206/256] Testing top_p=0.9, top_k=15, temp=1.1\n",
            "  BLEU: 0.0143, ROUGE-1: 0.1360, ROUGE-2: 0.0079, ROUGE-L: 0.1181, METEOR: 0.0535, Emotion: 0.7900, Combined: 0.1809\n",
            "\n",
            "[207/256] Testing top_p=0.9, top_k=15, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1194, ROUGE-2: 0.0154, ROUGE-L: 0.1096, METEOR: 0.0413, Emotion: 0.7500, Combined: 0.1664\n",
            "\n",
            "[208/256] Testing top_p=0.9, top_k=15, temp=1.3\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1111, ROUGE-2: 0.0125, ROUGE-L: 0.1064, METEOR: 0.0525, Emotion: 0.7800, Combined: 0.1720\n",
            "\n",
            "[209/256] Testing top_p=0.9, top_k=20, temp=1.0\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1297, ROUGE-2: 0.0124, ROUGE-L: 0.1183, METEOR: 0.0543, Emotion: 0.7600, Combined: 0.1765\n",
            "\n",
            "[210/256] Testing top_p=0.9, top_k=20, temp=1.1\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1303, ROUGE-2: 0.0100, ROUGE-L: 0.1189, METEOR: 0.0542, Emotion: 0.8100, Combined: 0.1804\n",
            "\n",
            "[211/256] Testing top_p=0.9, top_k=20, temp=1.2\n",
            "  BLEU: 0.0159, ROUGE-1: 0.1145, ROUGE-2: 0.0193, ROUGE-L: 0.1100, METEOR: 0.0598, Emotion: 0.7200, Combined: 0.1682\n",
            "\n",
            "[212/256] Testing top_p=0.9, top_k=20, temp=1.3\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1052, ROUGE-2: 0.0136, ROUGE-L: 0.0929, METEOR: 0.0577, Emotion: 0.7400, Combined: 0.1628\n",
            "\n",
            "[213/256] Testing top_p=0.9, top_k=25, temp=1.0\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1031, ROUGE-2: 0.0095, ROUGE-L: 0.0937, METEOR: 0.0463, Emotion: 0.8500, Combined: 0.1772\n",
            "\n",
            "[214/256] Testing top_p=0.9, top_k=25, temp=1.1\n",
            "  BLEU: 0.0135, ROUGE-1: 0.1028, ROUGE-2: 0.0168, ROUGE-L: 0.0979, METEOR: 0.0553, Emotion: 0.7800, Combined: 0.1719\n",
            "\n",
            "[215/256] Testing top_p=0.9, top_k=25, temp=1.2\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1141, ROUGE-2: 0.0173, ROUGE-L: 0.1080, METEOR: 0.0576, Emotion: 0.8000, Combined: 0.1754\n",
            "\n",
            "[216/256] Testing top_p=0.9, top_k=25, temp=1.3\n",
            "  BLEU: 0.0152, ROUGE-1: 0.1360, ROUGE-2: 0.0228, ROUGE-L: 0.1292, METEOR: 0.0790, Emotion: 0.7000, Combined: 0.1741\n",
            "\n",
            "[217/256] Testing top_p=0.9, top_k=30, temp=1.0\n",
            "  BLEU: 0.0080, ROUGE-1: 0.1075, ROUGE-2: 0.0139, ROUGE-L: 0.1019, METEOR: 0.0496, Emotion: 0.8700, Combined: 0.1810\n",
            "\n",
            "[218/256] Testing top_p=0.9, top_k=30, temp=1.1\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1117, ROUGE-2: 0.0155, ROUGE-L: 0.1066, METEOR: 0.0629, Emotion: 0.8000, Combined: 0.1767\n",
            "\n",
            "[219/256] Testing top_p=0.9, top_k=30, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0909, ROUGE-2: 0.0068, ROUGE-L: 0.0870, METEOR: 0.0346, Emotion: 0.6900, Combined: 0.1486\n",
            "\n",
            "[220/256] Testing top_p=0.9, top_k=30, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.0992, ROUGE-2: 0.0100, ROUGE-L: 0.0952, METEOR: 0.0499, Emotion: 0.7300, Combined: 0.1625\n",
            "\n",
            "[221/256] Testing top_p=0.9, top_k=35, temp=1.0\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1122, ROUGE-2: 0.0100, ROUGE-L: 0.1008, METEOR: 0.0509, Emotion: 0.8900, Combined: 0.1833\n",
            "\n",
            "[222/256] Testing top_p=0.9, top_k=35, temp=1.1\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0887, ROUGE-2: 0.0115, ROUGE-L: 0.0815, METEOR: 0.0451, Emotion: 0.7300, Combined: 0.1583\n",
            "\n",
            "[223/256] Testing top_p=0.9, top_k=35, temp=1.2\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0941, ROUGE-2: 0.0110, ROUGE-L: 0.0898, METEOR: 0.0454, Emotion: 0.7400, Combined: 0.1614\n",
            "\n",
            "[224/256] Testing top_p=0.9, top_k=35, temp=1.3\n",
            "  BLEU: 0.0109, ROUGE-1: 0.0995, ROUGE-2: 0.0044, ROUGE-L: 0.0972, METEOR: 0.0507, Emotion: 0.7300, Combined: 0.1590\n",
            "\n",
            "[225/256] Testing top_p=0.95, top_k=0, temp=1.0\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1031, ROUGE-2: 0.0146, ROUGE-L: 0.1015, METEOR: 0.0573, Emotion: 0.7900, Combined: 0.1733\n",
            "\n",
            "[226/256] Testing top_p=0.95, top_k=0, temp=1.1\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0734, ROUGE-2: 0.0044, ROUGE-L: 0.0675, METEOR: 0.0310, Emotion: 0.8000, Combined: 0.1572\n",
            "\n",
            "[227/256] Testing top_p=0.95, top_k=0, temp=1.2\n",
            "  BLEU: 0.0088, ROUGE-1: 0.0860, ROUGE-2: 0.0107, ROUGE-L: 0.0808, METEOR: 0.0486, Emotion: 0.7500, Combined: 0.1591\n",
            "\n",
            "[228/256] Testing top_p=0.95, top_k=0, temp=1.3\n",
            "  BLEU: 0.0067, ROUGE-1: 0.0754, ROUGE-2: 0.0000, ROUGE-L: 0.0664, METEOR: 0.0375, Emotion: 0.6800, Combined: 0.1451\n",
            "\n",
            "[229/256] Testing top_p=0.95, top_k=5, temp=1.0\n",
            "  BLEU: 0.0205, ROUGE-1: 0.1392, ROUGE-2: 0.0244, ROUGE-L: 0.1313, METEOR: 0.0615, Emotion: 0.7400, Combined: 0.1821\n",
            "\n",
            "[230/256] Testing top_p=0.95, top_k=5, temp=1.1\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1265, ROUGE-2: 0.0167, ROUGE-L: 0.1212, METEOR: 0.0580, Emotion: 0.7700, Combined: 0.1769\n",
            "\n",
            "[231/256] Testing top_p=0.95, top_k=5, temp=1.2\n",
            "  BLEU: 0.0194, ROUGE-1: 0.1680, ROUGE-2: 0.0304, ROUGE-L: 0.1614, METEOR: 0.0792, Emotion: 0.7600, Combined: 0.1957\n",
            "\n",
            "[232/256] Testing top_p=0.95, top_k=5, temp=1.3\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1168, ROUGE-2: 0.0139, ROUGE-L: 0.1098, METEOR: 0.0579, Emotion: 0.7600, Combined: 0.1724\n",
            "\n",
            "[233/256] Testing top_p=0.95, top_k=10, temp=1.0\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1360, ROUGE-2: 0.0161, ROUGE-L: 0.1281, METEOR: 0.0590, Emotion: 0.8000, Combined: 0.1850\n",
            "\n",
            "[234/256] Testing top_p=0.95, top_k=10, temp=1.1\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1219, ROUGE-2: 0.0174, ROUGE-L: 0.1174, METEOR: 0.0490, Emotion: 0.7700, Combined: 0.1731\n",
            "\n",
            "[235/256] Testing top_p=0.95, top_k=10, temp=1.2\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1112, ROUGE-2: 0.0149, ROUGE-L: 0.1033, METEOR: 0.0686, Emotion: 0.7100, Combined: 0.1658\n",
            "\n",
            "[236/256] Testing top_p=0.95, top_k=10, temp=1.3\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1009, ROUGE-2: 0.0114, ROUGE-L: 0.0991, METEOR: 0.0428, Emotion: 0.7900, Combined: 0.1655\n",
            "\n",
            "[237/256] Testing top_p=0.95, top_k=15, temp=1.0\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1152, ROUGE-2: 0.0181, ROUGE-L: 0.1105, METEOR: 0.0500, Emotion: 0.8100, Combined: 0.1788\n",
            "\n",
            "[238/256] Testing top_p=0.95, top_k=15, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.0948, ROUGE-2: 0.0106, ROUGE-L: 0.0879, METEOR: 0.0469, Emotion: 0.8800, Combined: 0.1763\n",
            "\n",
            "[239/256] Testing top_p=0.95, top_k=15, temp=1.2\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1095, ROUGE-2: 0.0071, ROUGE-L: 0.1046, METEOR: 0.0529, Emotion: 0.7400, Combined: 0.1647\n",
            "\n",
            "[240/256] Testing top_p=0.95, top_k=15, temp=1.3\n",
            "  BLEU: 0.0154, ROUGE-1: 0.1339, ROUGE-2: 0.0251, ROUGE-L: 0.1233, METEOR: 0.0719, Emotion: 0.7500, Combined: 0.1818\n",
            "\n",
            "[241/256] Testing top_p=0.95, top_k=20, temp=1.0\n",
            "  BLEU: 0.0130, ROUGE-1: 0.1077, ROUGE-2: 0.0186, ROUGE-L: 0.0952, METEOR: 0.0568, Emotion: 0.7900, Combined: 0.1737\n",
            "\n",
            "[242/256] Testing top_p=0.95, top_k=20, temp=1.1\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1019, ROUGE-2: 0.0033, ROUGE-L: 0.0967, METEOR: 0.0397, Emotion: 0.7300, Combined: 0.1606\n",
            "\n",
            "[243/256] Testing top_p=0.95, top_k=20, temp=1.2\n",
            "  BLEU: 0.0081, ROUGE-1: 0.0948, ROUGE-2: 0.0066, ROUGE-L: 0.0872, METEOR: 0.0458, Emotion: 0.7100, Combined: 0.1571\n",
            "\n",
            "[244/256] Testing top_p=0.95, top_k=20, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.0939, ROUGE-2: 0.0061, ROUGE-L: 0.0845, METEOR: 0.0478, Emotion: 0.6800, Combined: 0.1519\n",
            "\n",
            "[245/256] Testing top_p=0.95, top_k=25, temp=1.0\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1070, ROUGE-2: 0.0194, ROUGE-L: 0.1049, METEOR: 0.0547, Emotion: 0.8300, Combined: 0.1799\n",
            "\n",
            "[246/256] Testing top_p=0.95, top_k=25, temp=1.1\n",
            "  BLEU: 0.0109, ROUGE-1: 0.0961, ROUGE-2: 0.0093, ROUGE-L: 0.0925, METEOR: 0.0494, Emotion: 0.7300, Combined: 0.1602\n",
            "\n",
            "[247/256] Testing top_p=0.95, top_k=25, temp=1.2\n",
            "  BLEU: 0.0079, ROUGE-1: 0.0935, ROUGE-2: 0.0049, ROUGE-L: 0.0891, METEOR: 0.0409, Emotion: 0.8200, Combined: 0.1669\n",
            "\n",
            "[248/256] Testing top_p=0.95, top_k=25, temp=1.3\n",
            "  BLEU: 0.0179, ROUGE-1: 0.1270, ROUGE-2: 0.0166, ROUGE-L: 0.1199, METEOR: 0.0678, Emotion: 0.6500, Combined: 0.1652\n",
            "\n",
            "[249/256] Testing top_p=0.95, top_k=30, temp=1.0\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1109, ROUGE-2: 0.0142, ROUGE-L: 0.1035, METEOR: 0.0522, Emotion: 0.8300, Combined: 0.1775\n",
            "\n",
            "[250/256] Testing top_p=0.95, top_k=30, temp=1.1\n",
            "  BLEU: 0.0085, ROUGE-1: 0.1043, ROUGE-2: 0.0057, ROUGE-L: 0.0985, METEOR: 0.0464, Emotion: 0.6700, Combined: 0.1537\n",
            "\n",
            "[251/256] Testing top_p=0.95, top_k=30, temp=1.2\n",
            "  BLEU: 0.0108, ROUGE-1: 0.0968, ROUGE-2: 0.0158, ROUGE-L: 0.0937, METEOR: 0.0521, Emotion: 0.7600, Combined: 0.1640\n",
            "\n",
            "[252/256] Testing top_p=0.95, top_k=30, temp=1.3\n",
            "  BLEU: 0.0080, ROUGE-1: 0.0956, ROUGE-2: 0.0041, ROUGE-L: 0.0866, METEOR: 0.0423, Emotion: 0.7200, Combined: 0.1540\n",
            "\n",
            "[253/256] Testing top_p=0.95, top_k=35, temp=1.0\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1172, ROUGE-2: 0.0130, ROUGE-L: 0.1145, METEOR: 0.0511, Emotion: 0.7100, Combined: 0.1651\n",
            "\n",
            "[254/256] Testing top_p=0.95, top_k=35, temp=1.1\n",
            "  BLEU: 0.0156, ROUGE-1: 0.1203, ROUGE-2: 0.0176, ROUGE-L: 0.1151, METEOR: 0.0652, Emotion: 0.7700, Combined: 0.1786\n",
            "\n",
            "[255/256] Testing top_p=0.95, top_k=35, temp=1.2\n",
            "  BLEU: 0.0083, ROUGE-1: 0.0992, ROUGE-2: 0.0067, ROUGE-L: 0.0967, METEOR: 0.0446, Emotion: 0.6200, Combined: 0.1470\n",
            "\n",
            "[256/256] Testing top_p=0.95, top_k=35, temp=1.3\n",
            "  BLEU: 0.0076, ROUGE-1: 0.1052, ROUGE-2: 0.0059, ROUGE-L: 0.0991, METEOR: 0.0444, Emotion: 0.7300, Combined: 0.1619\n",
            "\n",
            "============================================================\n",
            "HYPERPARAMETER SEARCH COMPLETED\n",
            "============================================================\n",
            "Best parameters: top_p=0.6, top_k=30, temperature=1.0\n",
            "Best combined score: 0.2222\n",
            "\n",
            "Best result details:\n",
            "  BLEU Score: 0.0275\n",
            "  ROUGE-1: 0.1645\n",
            "  ROUGE-2: 0.0370\n",
            "  ROUGE-L: 0.1535\n",
            "  METEOR: 0.0875\n",
            "  Emotion Accuracy: 0.9600\n",
            "  Emotion Coverage: 1.0000\n",
            "  Combined Score: 0.2222\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/SFThyperparameter_search1/hyperparameter_search_20250824_191204.pkl\n",
            "CSV summary saved to: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/SFThyperparameter_search1/hyperparameter_results_20250824_191204.csv\n",
            "\n",
            "Best hyperparameters found:\n",
            "top_p: 0.6\n",
            "top_k: 30\n",
            "temperature: 1.0\n",
            "Score: 0.2222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT Evaluation"
      ],
      "metadata": {
        "id": "pff_w8LkYyBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Format Detection ======================\n",
        "def detect_model_format(model, tokenizer, device='cuda', test_inputs=None):\n",
        "    \"\"\"\n",
        "    Test model output format (should be consistent since both SFT and RL use same format)\n",
        "\n",
        "    Args:\n",
        "        model: The model to test\n",
        "        tokenizer: Model tokenizer\n",
        "        device: Device to run test on\n",
        "        test_inputs: List of test input strings, uses defaults if None\n",
        "\n",
        "    Returns:\n",
        "        str: 'standard' if using <therapist_emotion> format, 'unknown' otherwise\n",
        "    \"\"\"\n",
        "    if test_inputs is None:\n",
        "        test_inputs = [\n",
        "            \"<problem>anxiety <user>I'm worried about work <user_emotion>anxiety <therapist>\",\n",
        "            \"<problem>depression <user>I feel very sad <user_emotion>sadness <therapist>\",\n",
        "            \"<problem>relationship <user>My partner doesn't understand me <user_emotion>anger <therapist>\"\n",
        "        ]\n",
        "\n",
        "    emotion_tag_count = 0\n",
        "    total_tests = len(test_inputs)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_input in test_inputs:\n",
        "            # Tokenize and generate\n",
        "            input_ids = tokenizer.encode(test_input, return_tensors='pt').to(device)\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decode response\n",
        "            new_tokens = outputs[0][len(input_ids[0]):]\n",
        "            response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "            # Check for emotion tag\n",
        "            if '<therapist_emotion>' in response:\n",
        "                emotion_tag_count += 1\n",
        "\n",
        "    if emotion_tag_count >= total_tests * 0.5:\n",
        "        return 'standard'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"\n",
        "    Extract therapist text and emotion from model output.\n",
        "    Both SFT and RL models use format: 'text <therapist_emotion> emotion<eos>'\n",
        "\n",
        "    Returns:\n",
        "        therapist_text (str): Text before <therapist_emotion>\n",
        "        emotion (str): Emotion word after <therapist_emotion>\n",
        "        has_emotion_tag (bool): Whether emotion tag was found\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        # No emotion tag found, return entire response as text\n",
        "        return response, \"\", False\n",
        "\n",
        "def extract_emotion_only(response):\n",
        "    \"\"\"Extract only emotion from response (for compatibility with existing code)\"\"\"\n",
        "    _, emotion, has_emotion = extract_model_output(response)\n",
        "    return emotion if has_emotion else None\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDataset:\n",
        "    \"\"\"Dataset class for evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            # Use default tokenizer if path not provided\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt\n",
        "                    input_parts = []\n",
        "                    if problem_type:\n",
        "                        input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                    input_parts.append(f\"<user>{combined_user_text}\")\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.append(f\"<user_emotion>{last_user_emotion}\")\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \" \".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_model(model, tokenizer, evaluation_dataset, device='cuda', max_new_tokens=128,\n",
        "                  top_p=0.6, top_k=30, temperature=1.0, do_sample=True):\n",
        "    \"\"\"\n",
        "    Evaluate model on therapy dataset\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: TherapyEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        do_sample: Whether to use sampling\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Detect model output format\n",
        "    detected_format = detect_model_format(model, tokenizer, device)\n",
        "    print(f\"Output format check: {detected_format.upper()}\")\n",
        "\n",
        "    print(f\"Evaluating model on {len(evaluation_data)} samples...\")\n",
        "\n",
        "    progress_bar = tqdm(evaluation_data, desc=\"Evaluating\",\n",
        "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "        if has_emotion:\n",
        "            emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "        else:\n",
        "            emotion_confusion[reference_emotion.lower()]['no_prediction'] += 1\n",
        "\n",
        "        if i < 10:\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'full_response': response,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        if (i + 1) % 20 == 0 or i < 5:\n",
        "            sample_info = f\"Sample {i+1}: BLEU={bleu:.3f}, Emotion={'✓' if emotion_correct else '✗'}\"\n",
        "            progress_bar.set_description(f\"Evaluating - {sample_info}\")\n",
        "\n",
        "            if (i + 1) % 50 == 0 or i < 3:\n",
        "                print(f\"\\n\" + \"=\"*80)\n",
        "                print(f\"LIVE SAMPLE {i+1}/{len(evaluation_data)}\")\n",
        "                print(\"=\"*80)\n",
        "                print(f\"Input: {input_text[:120]}...\")\n",
        "                print(f\"Reference: {reference_text[:100]}...\")\n",
        "                print(f\"Generated: {predicted_text[:100]}...\")\n",
        "                print(f\"Full Response: {response[:150]}...\")\n",
        "                print(f\"Ref Emotion: {reference_emotion} | Pred Emotion: {predicted_emotion} | Match: {'✓' if emotion_correct else '✗'}\")\n",
        "                print(f\"BLEU: {bleu:.4f} | ROUGE-1: {rouge['rouge1']:.4f} | METEOR: {meteor:.4f}\")\n",
        "                print(\"=\"*80)\n",
        "        else:\n",
        "            if i > 0:\n",
        "                avg_bleu = np.mean(results['bleu_scores'])\n",
        "                avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "                progress_bar.set_description(f\"Evaluating - Avg BLEU: {avg_bleu:.3f}, Emotion Acc: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['detected_format'] = detected_format\n",
        "\n",
        "    # Print final progress summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUATION COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed {len(evaluation_data)} samples\")\n",
        "    print(f\"Average BLEU: {results['summary']['avg_bleu']:.4f}\")\n",
        "    print(f\"Average ROUGE-1: {results['summary']['avg_rouge1']:.4f}\")\n",
        "    print(f\"Emotion Accuracy: {results['summary']['emotion_accuracy']:.4f}\")\n",
        "    print(f\"Emotion Tag Coverage: {results['summary']['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"THERAPY MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Model Type: {results.get('model_type', 'Unknown').upper()}\")\n",
        "    print(f\"Output Format: {results.get('detected_format', 'Unknown').upper()}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction:\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Tag Coverage: {summary['emotion_tag_coverage']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Input: {sample['input'][:100]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:80]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:80]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']}\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"Checkpoint info: Epoch {checkpoint['epoch']}, Loss {checkpoint.get('valid_loss', 'N/A')}\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Automatically detect and load model (SFT checkpoint or RL directory)\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        device: Device to load model on\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, model_type)\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "\n",
        "    elif os.path.isdir(model_path):\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Main Evaluation Function ======================\n",
        "def run_evaluation(model_path, tokenizer_path, test_data_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Run complete evaluation pipeline\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        test_data_path: Path to test JSON data\n",
        "        device: Device to run evaluation on\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model and tokenizer (auto-detect type)\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    # Load evaluation dataset\n",
        "    print(f\"Loading evaluation data from {test_data_path}...\")\n",
        "    eval_dataset = TherapyEvaluationDataset(test_data_path, tokenizer_path)\n",
        "\n",
        "    # Run evaluation\n",
        "    results = evaluate_model(model, tokenizer, eval_dataset, device=device)\n",
        "    results['model_type'] = model_type\n",
        "\n",
        "    print_evaluation_results(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\"  # Will auto-detect type\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    results = run_evaluation(MODEL_PATH, TOKENIZER_PATH, TEST_DATA_PATH, DEVICE)\n",
        "\n",
        "    import pickle\n",
        "    with open('/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/0.6SFT_evaluation_results.pkl', 'wb') as f:\n",
        "      pickle.dump(results, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0772976612546bfae84ad45bc2f2bf6",
            "bcf390d3c3114f50b4bccf19e4543265",
            "924dcd24a05947e483f8df96a6d55965",
            "265f77967e84411196d9bd9dc69ca237",
            "4127a9702c3b4f7589ace0d2d41092d8",
            "e89578b73afc4db991cf8925b7d9c260",
            "655d15b6b53d479f92d66f6ccffe3006",
            "d067662a22d9421d9ab46394d8e11f91",
            "3cd622a0956b4bd2a9fcb3b9a0214d14",
            "c8ceec7b9f3a40998fc37fdc0bee938d",
            "77a37742a2754ddf93082ea8bbf82a5e",
            "cfab9d4687d34255b7aa1ddb4d361add",
            "822db7e8216a43fbb475699b29bf7b71",
            "c13fb2d53cb04720bc468a4a1670b35a",
            "2549b5e585d84541ba615b2812a58c2c",
            "feada5de96b8484fb3426927af9d7627",
            "ea7bab0aa7f64329ba8140e8db366b32",
            "1c4ec52ff15e4ffea9af6b2eee691922",
            "8053ff10bf59456486902838dadd37da",
            "4f4b47da83344c208e74f96004d83677",
            "e0540dac1f61401c8ab46afb5c9aa248",
            "5675158a4a144f4e8dc421c81218c86a",
            "334fb2182f2c4c069bcc6205b8108c63",
            "3004a8cb43c6499ca29c977b9112bac4",
            "c4cad901b35f4fb3a905d9c2770839e1",
            "178b0b1f47eb4260b601fc8b542f20d3",
            "1178e6ec18b94dd3b5fd617a4b72fa0b",
            "2c8f6bffb92048f6945603edea87cfef",
            "ded541cabf0c4f5f86c737c165ac49b4",
            "9023832b9c4f4f5887f85e5a1f2b574b",
            "be704fec049842888f6b7250e39d0e50",
            "2c4106ffbad8443e8bc6a78095d0b219",
            "d1c5524fb0f24f5aa85418b43cb0a56c"
          ]
        },
        "id": "xKAFb_-NmX7P",
        "outputId": "0bb98040-8295-4b7a-cbd3-1a8bf99fb2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt...\n",
            "Detected SFT checkpoint file\n",
            "Loading SFT checkpoint: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0772976612546bfae84ad45bc2f2bf6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfab9d4687d34255b7aa1ddb4d361add"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "334fb2182f2c4c069bcc6205b8108c63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint info: Epoch 7, Loss 2.237253785133362\n",
            "Loaded SFT model successfully\n",
            "Loading evaluation data from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing evaluation data: 100%|██████████| 102/102 [00:00<00:00, 6576.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 454 evaluation samples\n",
            "Output format check: STANDARD\n",
            "Evaluating model on 454 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Sample 1: BLEU=0.000, Emotion=✓:   0%|          | 1/454 [00:02<21:26,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 1/454\n",
            "================================================================================\n",
            "Input: <problem>Breakups or Divorce <user>I mean, shit, don't you know that men are the new women? Obsessed with weddings and c...\n",
            "Reference: But I thought you said...\n",
            "Generated: What is it?...\n",
            "Full Response: What is it? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Sample 4: BLEU=0.000, Emotion=✓:   1%|          | 4/454 [00:03<04:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 2/454\n",
            "================================================================================\n",
            "Input: <problem>Breakups or Divorce <user>Well, we were watching tv.But before that we were having dinner and he had this look ...\n",
            "Reference: So you were the one who came up with it....\n",
            "Generated: Well, maybe that's the way it's going to go....\n",
            "Full Response: Well, maybe that's the way it's going to go. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0215 | ROUGE-1: 0.1905 | METEOR: 0.0505\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 3/454\n",
            "================================================================================\n",
            "Input: <problem>Breakups or Divorce <user>With what? <user_emotion>neutral <therapist>...\n",
            "Reference: The ultimatum....\n",
            "Generated: Well,...\n",
            "Full Response: Well, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Avg BLEU: 0.011, Emotion Acc: 0.922:  22%|██▏       | 102/454 [00:14<00:38,  9.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 100/454\n",
            "================================================================================\n",
            "Input: <problem>Self-Assessment or Assessment of Others <user>I don't know. <user_emotion>depression <therapist>...\n",
            "Reference: You know We have these two sides to our personalities,...\n",
            "Generated: I think it's important to know that you're not alone....\n",
            "Full Response: I think it's important to know that you're not alone. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0251 | ROUGE-1: 0.2727 | METEOR: 0.1000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Avg BLEU: 0.011, Emotion Acc: 0.945:  44%|████▍     | 201/454 [00:26<00:29,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 200/454\n",
            "================================================================================\n",
            "Input: <problem>Emotional Transference or Infidelity <user>Yeah, I guess you don't really follow that world. I don't really fol...\n",
            "Reference: I remember last week that you mentioned she was wealthy....\n",
            "Generated: And what about you?...\n",
            "Full Response: And what about you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1429 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Avg BLEU: 0.012, Emotion Acc: 0.954:  66%|██████▋   | 301/454 [00:38<00:15,  9.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 300/454\n",
            "================================================================================\n",
            "Input: <problem>Self-punishment and disgust <user>I wanted Natalie up in the air, as far away from this as possible. Connie was...\n",
            "Reference: I think I heard my father use that expression....\n",
            "Generated: I don't know....\n",
            "Full Response: I don't know. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0154 | ROUGE-1: 0.1538 | METEOR: 0.0595\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Avg BLEU: 0.011, Emotion Acc: 0.950:  88%|████████▊ | 400/454 [00:50<00:07,  7.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LIVE SAMPLE 400/454\n",
            "================================================================================\n",
            "Input: <problem>The relationship with friends and family <user>But you know what could be helpful, actually? If you could just ...\n",
            "Reference: Isn't this what you used to do with Russell?...\n",
            "Generated: Would you like me to write something about you?...\n",
            "Full Response: Would you like me to write something about you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: neutral | Pred Emotion: neutral | Match: ✓\n",
            "BLEU: 0.0285 | ROUGE-1: 0.2105 | METEOR: 0.1111\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating - Avg BLEU: 0.011, Emotion Acc: 0.954: 100%|██████████| 454/454 [00:56<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION COMPLETED!\n",
            "============================================================\n",
            "Processed 454 samples\n",
            "Average BLEU: 0.0108\n",
            "Average ROUGE-1: 0.1164\n",
            "Emotion Accuracy: 0.9537\n",
            "Emotion Tag Coverage: 1.0000\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "THERAPY MODEL EVALUATION RESULTS\n",
            "============================================================\n",
            "Model Type: SFT\n",
            "Output Format: STANDARD\n",
            "\n",
            "Text Generation Metrics:\n",
            "  BLEU Score:     0.0108\n",
            "  ROUGE-1:        0.1164\n",
            "  ROUGE-2:        0.0175\n",
            "  ROUGE-L:        0.1076\n",
            "  METEOR:         0.0485\n",
            "\n",
            "Emotion Prediction:\n",
            "  Emotion Accuracy:    0.9537\n",
            "  Emotion Tag Coverage: 1.0000\n",
            "\n",
            "Dataset Info:\n",
            "  Total Samples:  454\n",
            "\n",
            "Sample Outputs:\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <problem>Breakups or Divorce <user>I mean, shit, don't you know that men are the new women? Obsessed...\n",
            "    Reference: But I thought you said...\n",
            "    Predicted: What is it?...\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.000, ROUGE-1: 0.000\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <problem>Breakups or Divorce <user>Well, we were watching tv.But before that we were having dinner a...\n",
            "    Reference: So you were the one who came up with it....\n",
            "    Predicted: Well, maybe that's the way it's going to go....\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.021, ROUGE-1: 0.190\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <problem>Breakups or Divorce <user>With what? <user_emotion>neutral <therapist>...\n",
            "    Reference: The ultimatum....\n",
            "    Predicted: Well,...\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.000, ROUGE-1: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL Hyperparameters\n"
      ],
      "metadata": {
        "id": "QJmNsbzoY3fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"Extract therapist text and emotion from model output\"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        # No emotion tag found, return entire response as text\n",
        "        return response, \"\", False\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDataset:\n",
        "    \"\"\"Dataset class for evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None, subset_size=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self.subset_size = subset_size\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        print(f\"Processing evaluation data (subset_size: {self.subset_size})...\")\n",
        "\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt\n",
        "                    input_parts = []\n",
        "                    if problem_type:\n",
        "                        input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                    input_parts.append(f\"<user>{combined_user_text}\")\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.append(f\"<user_emotion>{last_user_emotion}\")\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \" \".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "                    # Early stopping if subset size is reached\n",
        "                    if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                        break\n",
        "\n",
        "            # Early stopping if subset size is reached\n",
        "            if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                break\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ======================  Evaluation Function ======================\n",
        "def evaluate_hyperparameters(model, tokenizer, evaluation_dataset, device='cuda',\n",
        "                            max_new_tokens=128, top_p=0.8, top_k=0, temperature=1.0, do_sample=True,\n",
        "                            verbose=False):\n",
        "    \"\"\"\n",
        "    Fast evaluation for hyperparameter tuning\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: TherapyEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        top_k: Top-k sampling parameter\n",
        "        temperature: Temperature for sampling\n",
        "        do_sample: Whether to use sampling\n",
        "        verbose: Whether to print detailed progress\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Progress bar only if verbose\n",
        "    if verbose:\n",
        "        progress_bar = tqdm(evaluation_data, desc=f\"Eval p={top_p:.2f} k={top_k} T={temperature:.1f}\")\n",
        "        data_iter = progress_bar\n",
        "    else:\n",
        "        data_iter = evaluation_data\n",
        "\n",
        "    for i, sample in enumerate(data_iter):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "    if verbose and 'progress_bar' in locals():\n",
        "        progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    summary = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data),\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'temperature': temperature\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load model from directory\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Automatically detect and load model\"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "    elif os.path.isdir(model_path):\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Hyperparameter Tuning Functions ======================\n",
        "def compute_combined_score(results, weights=None):\n",
        "    \"\"\"\n",
        "    Compute a combined score from multiple metrics\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary containing metric results\n",
        "        weights: Dictionary of weights for each metric\n",
        "\n",
        "    Returns:\n",
        "        Combined score (higher is better)\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        # Default weights - adjust based on importance\n",
        "        weights = {\n",
        "            'avg_bleu': 0.2,\n",
        "            'avg_rouge1': 0.15,\n",
        "            'avg_rouge2': 0.15,\n",
        "            'avg_rougeL': 0.15,\n",
        "            'avg_meteor': 0.2,\n",
        "            'emotion_accuracy': 0.1,\n",
        "            'emotion_tag_coverage': 0.05\n",
        "        }\n",
        "\n",
        "    score = 0.0\n",
        "    for metric, weight in weights.items():\n",
        "        if metric in results:\n",
        "            score += results[metric] * weight\n",
        "\n",
        "    return score\n",
        "\n",
        "def hyperparameter_search(model_path, tokenizer_path, test_data_path, device='cuda',\n",
        "                         top_p_values=None, top_k_values=None, temperature_values=None, subset_size=100,\n",
        "                         max_new_tokens=128, output_dir=None, weights=None):\n",
        "    \"\"\"\n",
        "    Perform grid search over top_p, top_k, and temperature values\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        test_data_path: Path to test JSON data\n",
        "        device: Device to run evaluation on\n",
        "        top_p_values: List of top_p values to test\n",
        "        top_k_values: List of top_k values to test\n",
        "        temperature_values: List of temperature values to test\n",
        "        subset_size: Number of samples to use for evaluation\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        output_dir: Directory to save results\n",
        "        weights: Weights for combining metrics\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all results and best parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Default hyperparameter values\n",
        "    if top_p_values is None:\n",
        "        top_p_values = [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "    if top_k_values is None:\n",
        "        top_k_values = [0, 5, 10, 20, 40, 50]  # 0 means no top_k filtering\n",
        "\n",
        "    if temperature_values is None:\n",
        "        temperature_values = [0.8, 1.0, 1.1, 1.2, 1.3, 1.4]\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    # Load evaluation dataset (subset)\n",
        "    print(f\"Loading evaluation data subset (size: {subset_size})...\")\n",
        "    eval_dataset = TherapyEvaluationDataset(test_data_path, tokenizer_path, subset_size=subset_size)\n",
        "\n",
        "    # Initialize results storage\n",
        "    all_results = []\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # Total combinations\n",
        "    total_combinations = len(top_p_values) * len(top_k_values) * len(temperature_values)\n",
        "    print(f\"Testing {total_combinations} hyperparameter combinations...\")\n",
        "    print(f\"top_p values: {top_p_values}\")\n",
        "    print(f\"top_k values: {top_k_values}\")\n",
        "    print(f\"temperature values: {temperature_values}\")\n",
        "    print(f\"Subset size: {subset_size} samples\")\n",
        "\n",
        "    # Grid search\n",
        "    combination_count = 0\n",
        "\n",
        "    for top_p in top_p_values:\n",
        "        for top_k in top_k_values:\n",
        "            for temperature in temperature_values:\n",
        "                combination_count += 1\n",
        "\n",
        "                print(f\"\\n[{combination_count}/{total_combinations}] Testing top_p={top_p}, top_k={top_k}, temp={temperature}\")\n",
        "\n",
        "                # Evaluate with current hyperparameters\n",
        "                results = evaluate_hyperparameters(\n",
        "                    model, tokenizer, eval_dataset, device,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    top_p=top_p, top_k=top_k, temperature=temperature,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                # Compute combined score\n",
        "                combined_score = compute_combined_score(results, weights)\n",
        "                results['combined_score'] = combined_score\n",
        "\n",
        "                # Store results\n",
        "                all_results.append(results)\n",
        "\n",
        "                # Check if this is the best so far\n",
        "                if combined_score > best_score:\n",
        "                    best_score = combined_score\n",
        "                    best_params = {'top_p': top_p, 'top_k': top_k, 'temperature': temperature}\n",
        "                    print(f\"  *** NEW BEST *** Score: {combined_score:.4f}\")\n",
        "\n",
        "                # Print current results\n",
        "                print(f\"  BLEU: {results['avg_bleu']:.4f}, \"\n",
        "                      f\"ROUGE-1: {results['avg_rouge1']:.4f}, \"\n",
        "                      f\"ROUGE-2: {results['avg_rouge2']:.4f}, \"\n",
        "                      f\"ROUGE-L: {results['avg_rougeL']:.4f}, \"\n",
        "                      f\"METEOR: {results['avg_meteor']:.4f}, \"\n",
        "                      f\"Emotion: {results['emotion_accuracy']:.4f}, \"\n",
        "                      f\"Combined: {combined_score:.4f}\")\n",
        "\n",
        "    # Compile final results\n",
        "    final_results = {\n",
        "        'best_params': best_params,\n",
        "        'best_score': best_score,\n",
        "        'all_results': all_results,\n",
        "        'model_path': model_path,\n",
        "        'model_type': model_type,\n",
        "        'subset_size': subset_size,\n",
        "        'search_space': {\n",
        "            'top_p_values': top_p_values,\n",
        "            'top_k_values': top_k_values,\n",
        "            'temperature_values': temperature_values\n",
        "        },\n",
        "        'weights': weights or {\n",
        "            'avg_bleu': 0.2,\n",
        "            'avg_rouge1': 0.15,\n",
        "            'avg_rouge2': 0.15,\n",
        "            'avg_rougeL': 0.15,\n",
        "            'avg_meteor': 0.2,\n",
        "            'emotion_accuracy': 0.1,\n",
        "            'emotion_tag_coverage': 0.05\n",
        "        },\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"HYPERPARAMETER SEARCH COMPLETED\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Best parameters: top_p={best_params['top_p']}, top_k={best_params['top_k']}, temperature={best_params['temperature']}\")\n",
        "    print(f\"Best combined score: {best_score:.4f}\")\n",
        "\n",
        "    # Find best result details\n",
        "    best_result = max(all_results, key=lambda x: x['combined_score'])\n",
        "    print(f\"\\nBest result details:\")\n",
        "    print(f\"  BLEU Score: {best_result['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1: {best_result['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2: {best_result['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L: {best_result['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR: {best_result['avg_meteor']:.4f}\")\n",
        "    print(f\"  Emotion Accuracy: {best_result['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Coverage: {best_result['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"  Combined Score: {best_result['combined_score']:.4f}\")\n",
        "\n",
        "    # Save results if output directory specified\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_file = os.path.join(output_dir, f\"hyperparameter_search_{timestamp}.pkl\")\n",
        "\n",
        "        with open(results_file, 'wb') as f:\n",
        "            pickle.dump(final_results, f)\n",
        "\n",
        "        print(f\"\\nResults saved to: {results_file}\")\n",
        "\n",
        "        # Also save a summary CSV\n",
        "        import pandas as pd\n",
        "        df_results = pd.DataFrame(all_results)\n",
        "        csv_file = os.path.join(output_dir, f\"hyperparameter_results_{timestamp}.csv\")\n",
        "        df_results.to_csv(csv_file, index=False)\n",
        "        print(f\"CSV summary saved to: {csv_file}\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def analyze_results(results_file):\n",
        "    \"\"\"Analyze hyperparameter search results\"\"\"\n",
        "    with open(results_file, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(results['all_results'])\n",
        "\n",
        "    print(f\"Hyperparameter Search Analysis\")\n",
        "    print(f\"=\" * 50)\n",
        "    print(f\"Model: {results['model_path']}\")\n",
        "    print(f\"Search completed: {results['timestamp']}\")\n",
        "    print(f\"Total combinations tested: {len(df)}\")\n",
        "\n",
        "    # Top 5 results\n",
        "    print(f\"\\nTop 5 Results:\")\n",
        "    top_5 = df.nlargest(5, 'combined_score')[['top_p', 'top_k', 'temperature', 'avg_bleu', 'avg_rouge1',\n",
        "                                              'avg_rouge2', 'avg_rougeL', 'avg_meteor',\n",
        "                                              'emotion_accuracy', 'combined_score']]\n",
        "    print(top_5.to_string(index=False))\n",
        "\n",
        "    # Best for each metric\n",
        "    print(f\"\\nBest parameters for each metric:\")\n",
        "    for metric in ['avg_bleu', 'avg_rouge1', 'avg_rouge2', 'avg_rougeL', 'avg_meteor', 'emotion_accuracy']:\n",
        "        best_row = df.loc[df[metric].idxmax()]\n",
        "        print(f\"  {metric}: top_p={best_row['top_p']}, top_k={best_row['top_k']}, temp={best_row['temperature']} (score: {best_row[metric]:.4f})\")\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4\"\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/RLhyperparameter_search1\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    TOP_P_VALUES = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.00]\n",
        "    TOP_K_VALUES = [0, 5, 10, 15, 20, 25, 30, 35]\n",
        "    TEMPERATURE_VALUES = [1.0, 1.1, 1.2, 1.3]\n",
        "\n",
        "    SUBSET_SIZE = 100\n",
        "\n",
        "    CUSTOM_WEIGHTS = None\n",
        "\n",
        "    results = hyperparameter_search(\n",
        "        model_path=MODEL_PATH,\n",
        "        tokenizer_path=TOKENIZER_PATH,\n",
        "        test_data_path=TEST_DATA_PATH,\n",
        "        device=DEVICE,\n",
        "        top_p_values=TOP_P_VALUES,\n",
        "        top_k_values=TOP_K_VALUES,\n",
        "        temperature_values=TEMPERATURE_VALUES,\n",
        "        subset_size=SUBSET_SIZE,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        weights=CUSTOM_WEIGHTS\n",
        "    )\n",
        "\n",
        "    print(f\"\\nBest hyperparameters found:\")\n",
        "    print(f\"top_p: {results['best_params']['top_p']}\")\n",
        "    print(f\"top_k: {results['best_params']['top_k']}\")\n",
        "    print(f\"temperature: {results['best_params']['temperature']}\")\n",
        "    print(f\"Score: {results['best_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idWZNVtnE7Ed",
        "outputId": "db2f46e6-a20a-4b40-a194-333ba6b745a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4...\n",
            "Detected RL model directory\n",
            "Loading RL model from directory: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4 were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded RL model successfully\n",
            "Loading evaluation data subset (size: 100)...\n",
            "Processing evaluation data (subset_size: 100)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing evaluation data:  24%|██▎       | 24/102 [00:00<00:00, 6780.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100 evaluation samples\n",
            "Testing 288 hyperparameter combinations...\n",
            "top_p values: [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
            "top_k values: [0, 5, 10, 15, 20, 25, 30, 35]\n",
            "temperature values: [1.0, 1.1, 1.2, 1.3]\n",
            "Subset size: 100 samples\n",
            "\n",
            "[1/288] Testing top_p=0.6, top_k=0, temp=1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  *** NEW BEST *** Score: 0.1965\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1265, ROUGE-2: 0.0166, ROUGE-L: 0.1221, METEOR: 0.0401, Emotion: 0.9700, Combined: 0.1965\n",
            "\n",
            "[2/288] Testing top_p=0.6, top_k=0, temp=1.1\n",
            "  *** NEW BEST *** Score: 0.1976\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1289, ROUGE-2: 0.0121, ROUGE-L: 0.1224, METEOR: 0.0429, Emotion: 0.9800, Combined: 0.1976\n",
            "\n",
            "[3/288] Testing top_p=0.6, top_k=0, temp=1.2\n",
            "  *** NEW BEST *** Score: 0.2052\n",
            "  BLEU: 0.0144, ROUGE-1: 0.1344, ROUGE-2: 0.0189, ROUGE-L: 0.1256, METEOR: 0.0622, Emotion: 0.9800, Combined: 0.2052\n",
            "\n",
            "[4/288] Testing top_p=0.6, top_k=0, temp=1.3\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1326, ROUGE-2: 0.0148, ROUGE-L: 0.1269, METEOR: 0.0570, Emotion: 0.9600, Combined: 0.2009\n",
            "\n",
            "[5/288] Testing top_p=0.6, top_k=5, temp=1.0\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1402, ROUGE-2: 0.0211, ROUGE-L: 0.1321, METEOR: 0.0502, Emotion: 0.9700, Combined: 0.2023\n",
            "\n",
            "[6/288] Testing top_p=0.6, top_k=5, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1227, ROUGE-2: 0.0119, ROUGE-L: 0.1176, METEOR: 0.0378, Emotion: 0.9800, Combined: 0.1948\n",
            "\n",
            "[7/288] Testing top_p=0.6, top_k=5, temp=1.2\n",
            "  BLEU: 0.0076, ROUGE-1: 0.1274, ROUGE-2: 0.0184, ROUGE-L: 0.1255, METEOR: 0.0402, Emotion: 0.9900, Combined: 0.1993\n",
            "\n",
            "[8/288] Testing top_p=0.6, top_k=5, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1204, ROUGE-2: 0.0186, ROUGE-L: 0.1153, METEOR: 0.0442, Emotion: 0.9900, Combined: 0.1979\n",
            "\n",
            "[9/288] Testing top_p=0.6, top_k=10, temp=1.0\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1242, ROUGE-2: 0.0080, ROUGE-L: 0.1198, METEOR: 0.0332, Emotion: 0.9900, Combined: 0.1952\n",
            "\n",
            "[10/288] Testing top_p=0.6, top_k=10, temp=1.1\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1344, ROUGE-2: 0.0228, ROUGE-L: 0.1312, METEOR: 0.0495, Emotion: 0.9900, Combined: 0.2041\n",
            "\n",
            "[11/288] Testing top_p=0.6, top_k=10, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1250, ROUGE-2: 0.0179, ROUGE-L: 0.1212, METEOR: 0.0412, Emotion: 0.9800, Combined: 0.1978\n",
            "\n",
            "[12/288] Testing top_p=0.6, top_k=10, temp=1.3\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1352, ROUGE-2: 0.0136, ROUGE-L: 0.1273, METEOR: 0.0473, Emotion: 0.9900, Combined: 0.2020\n",
            "\n",
            "[13/288] Testing top_p=0.6, top_k=15, temp=1.0\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1308, ROUGE-2: 0.0238, ROUGE-L: 0.1244, METEOR: 0.0508, Emotion: 0.9800, Combined: 0.2020\n",
            "\n",
            "[14/288] Testing top_p=0.6, top_k=15, temp=1.1\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1290, ROUGE-2: 0.0142, ROUGE-L: 0.1248, METEOR: 0.0500, Emotion: 0.9900, Combined: 0.2016\n",
            "\n",
            "[15/288] Testing top_p=0.6, top_k=15, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1354, ROUGE-2: 0.0197, ROUGE-L: 0.1295, METEOR: 0.0481, Emotion: 0.9900, Combined: 0.2032\n",
            "\n",
            "[16/288] Testing top_p=0.6, top_k=15, temp=1.3\n",
            "  BLEU: 0.0072, ROUGE-1: 0.1218, ROUGE-2: 0.0114, ROUGE-L: 0.1138, METEOR: 0.0395, Emotion: 0.9900, Combined: 0.1954\n",
            "\n",
            "[17/288] Testing top_p=0.6, top_k=20, temp=1.0\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1259, ROUGE-2: 0.0173, ROUGE-L: 0.1229, METEOR: 0.0417, Emotion: 0.9900, Combined: 0.1988\n",
            "\n",
            "[18/288] Testing top_p=0.6, top_k=20, temp=1.1\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1223, ROUGE-2: 0.0136, ROUGE-L: 0.1144, METEOR: 0.0470, Emotion: 0.9800, Combined: 0.1962\n",
            "\n",
            "[19/288] Testing top_p=0.6, top_k=20, temp=1.2\n",
            "  *** NEW BEST *** Score: 0.2103\n",
            "  BLEU: 0.0174, ROUGE-1: 0.1377, ROUGE-2: 0.0283, ROUGE-L: 0.1335, METEOR: 0.0644, Emotion: 0.9900, Combined: 0.2103\n",
            "\n",
            "[20/288] Testing top_p=0.6, top_k=20, temp=1.3\n",
            "  BLEU: 0.0132, ROUGE-1: 0.1350, ROUGE-2: 0.0270, ROUGE-L: 0.1269, METEOR: 0.0487, Emotion: 0.9900, Combined: 0.2047\n",
            "\n",
            "[21/288] Testing top_p=0.6, top_k=25, temp=1.0\n",
            "  BLEU: 0.0139, ROUGE-1: 0.1394, ROUGE-2: 0.0299, ROUGE-L: 0.1340, METEOR: 0.0548, Emotion: 0.9900, Combined: 0.2082\n",
            "\n",
            "[22/288] Testing top_p=0.6, top_k=25, temp=1.1\n",
            "  BLEU: 0.0068, ROUGE-1: 0.1229, ROUGE-2: 0.0160, ROUGE-L: 0.1214, METEOR: 0.0352, Emotion: 0.9800, Combined: 0.1949\n",
            "\n",
            "[23/288] Testing top_p=0.6, top_k=25, temp=1.2\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1352, ROUGE-2: 0.0112, ROUGE-L: 0.1307, METEOR: 0.0392, Emotion: 0.9800, Combined: 0.1990\n",
            "\n",
            "[24/288] Testing top_p=0.6, top_k=25, temp=1.3\n",
            "  BLEU: 0.0117, ROUGE-1: 0.1448, ROUGE-2: 0.0264, ROUGE-L: 0.1388, METEOR: 0.0573, Emotion: 0.9900, Combined: 0.2093\n",
            "\n",
            "[25/288] Testing top_p=0.6, top_k=30, temp=1.0\n",
            "  BLEU: 0.0077, ROUGE-1: 0.1334, ROUGE-2: 0.0166, ROUGE-L: 0.1298, METEOR: 0.0386, Emotion: 0.9900, Combined: 0.2002\n",
            "\n",
            "[26/288] Testing top_p=0.6, top_k=30, temp=1.1\n",
            "  BLEU: 0.0128, ROUGE-1: 0.1281, ROUGE-2: 0.0299, ROUGE-L: 0.1212, METEOR: 0.0592, Emotion: 0.9900, Combined: 0.2053\n",
            "\n",
            "[27/288] Testing top_p=0.6, top_k=30, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1160, ROUGE-2: 0.0178, ROUGE-L: 0.1095, METEOR: 0.0462, Emotion: 0.9800, Combined: 0.1953\n",
            "\n",
            "[28/288] Testing top_p=0.6, top_k=30, temp=1.3\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1228, ROUGE-2: 0.0100, ROUGE-L: 0.1171, METEOR: 0.0308, Emotion: 0.9700, Combined: 0.1921\n",
            "\n",
            "[29/288] Testing top_p=0.6, top_k=35, temp=1.0\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1385, ROUGE-2: 0.0256, ROUGE-L: 0.1325, METEOR: 0.0561, Emotion: 0.9900, Combined: 0.2071\n",
            "\n",
            "[30/288] Testing top_p=0.6, top_k=35, temp=1.1\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1151, ROUGE-2: 0.0191, ROUGE-L: 0.1086, METEOR: 0.0485, Emotion: 0.9900, Combined: 0.1974\n",
            "\n",
            "[31/288] Testing top_p=0.6, top_k=35, temp=1.2\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1302, ROUGE-2: 0.0238, ROUGE-L: 0.1282, METEOR: 0.0566, Emotion: 0.9800, Combined: 0.2043\n",
            "\n",
            "[32/288] Testing top_p=0.6, top_k=35, temp=1.3\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1334, ROUGE-2: 0.0214, ROUGE-L: 0.1270, METEOR: 0.0499, Emotion: 0.9800, Combined: 0.2028\n",
            "\n",
            "[33/288] Testing top_p=0.65, top_k=0, temp=1.0\n",
            "  BLEU: 0.0131, ROUGE-1: 0.1397, ROUGE-2: 0.0302, ROUGE-L: 0.1327, METEOR: 0.0547, Emotion: 0.9900, Combined: 0.2079\n",
            "\n",
            "[34/288] Testing top_p=0.65, top_k=0, temp=1.1\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1399, ROUGE-2: 0.0218, ROUGE-L: 0.1343, METEOR: 0.0546, Emotion: 0.9900, Combined: 0.2068\n",
            "\n",
            "[35/288] Testing top_p=0.65, top_k=0, temp=1.2\n",
            "  BLEU: 0.0126, ROUGE-1: 0.1289, ROUGE-2: 0.0195, ROUGE-L: 0.1206, METEOR: 0.0637, Emotion: 0.9700, Combined: 0.2026\n",
            "\n",
            "[36/288] Testing top_p=0.65, top_k=0, temp=1.3\n",
            "  BLEU: 0.0073, ROUGE-1: 0.1156, ROUGE-2: 0.0089, ROUGE-L: 0.1061, METEOR: 0.0425, Emotion: 0.9700, Combined: 0.1905\n",
            "\n",
            "[37/288] Testing top_p=0.65, top_k=5, temp=1.0\n",
            "  BLEU: 0.0129, ROUGE-1: 0.1456, ROUGE-2: 0.0241, ROUGE-L: 0.1424, METEOR: 0.0528, Emotion: 0.9900, Combined: 0.2089\n",
            "\n",
            "[38/288] Testing top_p=0.65, top_k=5, temp=1.1\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1165, ROUGE-2: 0.0128, ROUGE-L: 0.1127, METEOR: 0.0308, Emotion: 0.9700, Combined: 0.1898\n",
            "\n",
            "[39/288] Testing top_p=0.65, top_k=5, temp=1.2\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1386, ROUGE-2: 0.0145, ROUGE-L: 0.1343, METEOR: 0.0393, Emotion: 0.9800, Combined: 0.2003\n",
            "\n",
            "[40/288] Testing top_p=0.65, top_k=5, temp=1.3\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1412, ROUGE-2: 0.0237, ROUGE-L: 0.1339, METEOR: 0.0442, Emotion: 0.9800, Combined: 0.2030\n",
            "\n",
            "[41/288] Testing top_p=0.65, top_k=10, temp=1.0\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1233, ROUGE-2: 0.0177, ROUGE-L: 0.1133, METEOR: 0.0339, Emotion: 0.9800, Combined: 0.1941\n",
            "\n",
            "[42/288] Testing top_p=0.65, top_k=10, temp=1.1\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1209, ROUGE-2: 0.0161, ROUGE-L: 0.1195, METEOR: 0.0489, Emotion: 0.9900, Combined: 0.1989\n",
            "\n",
            "[43/288] Testing top_p=0.65, top_k=10, temp=1.2\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1367, ROUGE-2: 0.0234, ROUGE-L: 0.1357, METEOR: 0.0503, Emotion: 0.9900, Combined: 0.2058\n",
            "\n",
            "[44/288] Testing top_p=0.65, top_k=10, temp=1.3\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1372, ROUGE-2: 0.0240, ROUGE-L: 0.1353, METEOR: 0.0517, Emotion: 0.9800, Combined: 0.2053\n",
            "\n",
            "[45/288] Testing top_p=0.65, top_k=15, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1303, ROUGE-2: 0.0226, ROUGE-L: 0.1277, METEOR: 0.0475, Emotion: 0.9900, Combined: 0.2026\n",
            "\n",
            "[46/288] Testing top_p=0.65, top_k=15, temp=1.1\n",
            "  BLEU: 0.0066, ROUGE-1: 0.1341, ROUGE-2: 0.0093, ROUGE-L: 0.1290, METEOR: 0.0388, Emotion: 0.9900, Combined: 0.1989\n",
            "\n",
            "[47/288] Testing top_p=0.65, top_k=15, temp=1.2\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1232, ROUGE-2: 0.0170, ROUGE-L: 0.1202, METEOR: 0.0413, Emotion: 0.9900, Combined: 0.1985\n",
            "\n",
            "[48/288] Testing top_p=0.65, top_k=15, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1406, ROUGE-2: 0.0111, ROUGE-L: 0.1296, METEOR: 0.0531, Emotion: 0.9900, Combined: 0.2037\n",
            "\n",
            "[49/288] Testing top_p=0.65, top_k=20, temp=1.0\n",
            "  BLEU: 0.0057, ROUGE-1: 0.1299, ROUGE-2: 0.0116, ROUGE-L: 0.1217, METEOR: 0.0316, Emotion: 0.9800, Combined: 0.1949\n",
            "\n",
            "[50/288] Testing top_p=0.65, top_k=20, temp=1.1\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1283, ROUGE-2: 0.0197, ROUGE-L: 0.1219, METEOR: 0.0392, Emotion: 0.9800, Combined: 0.1985\n",
            "\n",
            "[51/288] Testing top_p=0.65, top_k=20, temp=1.2\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1258, ROUGE-2: 0.0233, ROUGE-L: 0.1241, METEOR: 0.0527, Emotion: 0.9800, Combined: 0.2014\n",
            "\n",
            "[52/288] Testing top_p=0.65, top_k=20, temp=1.3\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1490, ROUGE-2: 0.0138, ROUGE-L: 0.1397, METEOR: 0.0524, Emotion: 0.9800, Combined: 0.2058\n",
            "\n",
            "[53/288] Testing top_p=0.65, top_k=25, temp=1.0\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1349, ROUGE-2: 0.0231, ROUGE-L: 0.1315, METEOR: 0.0464, Emotion: 0.9900, Combined: 0.2038\n",
            "\n",
            "[54/288] Testing top_p=0.65, top_k=25, temp=1.1\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1388, ROUGE-2: 0.0139, ROUGE-L: 0.1342, METEOR: 0.0434, Emotion: 0.9800, Combined: 0.2011\n",
            "\n",
            "[55/288] Testing top_p=0.65, top_k=25, temp=1.2\n",
            "  BLEU: 0.0140, ROUGE-1: 0.1431, ROUGE-2: 0.0297, ROUGE-L: 0.1397, METEOR: 0.0575, Emotion: 0.9900, Combined: 0.2102\n",
            "\n",
            "[56/288] Testing top_p=0.65, top_k=25, temp=1.3\n",
            "  BLEU: 0.0190, ROUGE-1: 0.1110, ROUGE-2: 0.0201, ROUGE-L: 0.1061, METEOR: 0.0574, Emotion: 0.9900, Combined: 0.1999\n",
            "\n",
            "[57/288] Testing top_p=0.65, top_k=30, temp=1.0\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1310, ROUGE-2: 0.0164, ROUGE-L: 0.1228, METEOR: 0.0414, Emotion: 0.9800, Combined: 0.1989\n",
            "\n",
            "[58/288] Testing top_p=0.65, top_k=30, temp=1.1\n",
            "  BLEU: 0.0132, ROUGE-1: 0.1381, ROUGE-2: 0.0232, ROUGE-L: 0.1309, METEOR: 0.0576, Emotion: 0.9800, Combined: 0.2060\n",
            "\n",
            "[59/288] Testing top_p=0.65, top_k=30, temp=1.2\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1396, ROUGE-2: 0.0176, ROUGE-L: 0.1286, METEOR: 0.0527, Emotion: 0.9900, Combined: 0.2049\n",
            "\n",
            "[60/288] Testing top_p=0.65, top_k=30, temp=1.3\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1279, ROUGE-2: 0.0169, ROUGE-L: 0.1246, METEOR: 0.0523, Emotion: 0.9900, Combined: 0.2021\n",
            "\n",
            "[61/288] Testing top_p=0.65, top_k=35, temp=1.0\n",
            "  BLEU: 0.0149, ROUGE-1: 0.1336, ROUGE-2: 0.0244, ROUGE-L: 0.1302, METEOR: 0.0504, Emotion: 0.9900, Combined: 0.2053\n",
            "\n",
            "[62/288] Testing top_p=0.65, top_k=35, temp=1.1\n",
            "  BLEU: 0.0077, ROUGE-1: 0.1327, ROUGE-2: 0.0164, ROUGE-L: 0.1281, METEOR: 0.0410, Emotion: 0.9900, Combined: 0.2003\n",
            "\n",
            "[63/288] Testing top_p=0.65, top_k=35, temp=1.2\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1283, ROUGE-2: 0.0176, ROUGE-L: 0.1229, METEOR: 0.0496, Emotion: 0.9700, Combined: 0.1989\n",
            "\n",
            "[64/288] Testing top_p=0.65, top_k=35, temp=1.3\n",
            "  BLEU: 0.0126, ROUGE-1: 0.1279, ROUGE-2: 0.0181, ROUGE-L: 0.1240, METEOR: 0.0548, Emotion: 0.9900, Combined: 0.2030\n",
            "\n",
            "[65/288] Testing top_p=0.7, top_k=0, temp=1.0\n",
            "  BLEU: 0.0163, ROUGE-1: 0.1378, ROUGE-2: 0.0264, ROUGE-L: 0.1348, METEOR: 0.0490, Emotion: 0.9900, Combined: 0.2069\n",
            "\n",
            "[66/288] Testing top_p=0.7, top_k=0, temp=1.1\n",
            "  BLEU: 0.0065, ROUGE-1: 0.1084, ROUGE-2: 0.0110, ROUGE-L: 0.1050, METEOR: 0.0323, Emotion: 0.9800, Combined: 0.1889\n",
            "\n",
            "[67/288] Testing top_p=0.7, top_k=0, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1095, ROUGE-2: 0.0133, ROUGE-L: 0.1069, METEOR: 0.0433, Emotion: 0.9700, Combined: 0.1920\n",
            "\n",
            "[68/288] Testing top_p=0.7, top_k=0, temp=1.3\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1152, ROUGE-2: 0.0133, ROUGE-L: 0.1089, METEOR: 0.0620, Emotion: 0.9600, Combined: 0.1958\n",
            "\n",
            "[69/288] Testing top_p=0.7, top_k=5, temp=1.0\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1179, ROUGE-2: 0.0176, ROUGE-L: 0.1167, METEOR: 0.0343, Emotion: 0.9800, Combined: 0.1942\n",
            "\n",
            "[70/288] Testing top_p=0.7, top_k=5, temp=1.1\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1401, ROUGE-2: 0.0160, ROUGE-L: 0.1340, METEOR: 0.0454, Emotion: 0.9900, Combined: 0.2032\n",
            "\n",
            "[71/288] Testing top_p=0.7, top_k=5, temp=1.2\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1325, ROUGE-2: 0.0223, ROUGE-L: 0.1272, METEOR: 0.0349, Emotion: 0.9700, Combined: 0.1977\n",
            "\n",
            "[72/288] Testing top_p=0.7, top_k=5, temp=1.3\n",
            "  BLEU: 0.0143, ROUGE-1: 0.1360, ROUGE-2: 0.0333, ROUGE-L: 0.1305, METEOR: 0.0653, Emotion: 0.9900, Combined: 0.2099\n",
            "\n",
            "[73/288] Testing top_p=0.7, top_k=10, temp=1.0\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1312, ROUGE-2: 0.0152, ROUGE-L: 0.1288, METEOR: 0.0460, Emotion: 0.9900, Combined: 0.2015\n",
            "\n",
            "[74/288] Testing top_p=0.7, top_k=10, temp=1.1\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1325, ROUGE-2: 0.0177, ROUGE-L: 0.1251, METEOR: 0.0431, Emotion: 0.9800, Combined: 0.2000\n",
            "\n",
            "[75/288] Testing top_p=0.7, top_k=10, temp=1.2\n",
            "  *** NEW BEST *** Score: 0.2139\n",
            "  BLEU: 0.0229, ROUGE-1: 0.1433, ROUGE-2: 0.0294, ROUGE-L: 0.1380, METEOR: 0.0685, Emotion: 0.9900, Combined: 0.2139\n",
            "\n",
            "[76/288] Testing top_p=0.7, top_k=10, temp=1.3\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1255, ROUGE-2: 0.0061, ROUGE-L: 0.1177, METEOR: 0.0405, Emotion: 0.9800, Combined: 0.1955\n",
            "\n",
            "[77/288] Testing top_p=0.7, top_k=15, temp=1.0\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1296, ROUGE-2: 0.0179, ROUGE-L: 0.1225, METEOR: 0.0363, Emotion: 0.9800, Combined: 0.1973\n",
            "\n",
            "[78/288] Testing top_p=0.7, top_k=15, temp=1.1\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1295, ROUGE-2: 0.0210, ROUGE-L: 0.1235, METEOR: 0.0447, Emotion: 0.9800, Combined: 0.2001\n",
            "\n",
            "[79/288] Testing top_p=0.7, top_k=15, temp=1.2\n",
            "  BLEU: 0.0077, ROUGE-1: 0.1174, ROUGE-2: 0.0111, ROUGE-L: 0.1146, METEOR: 0.0351, Emotion: 0.9800, Combined: 0.1930\n",
            "\n",
            "[80/288] Testing top_p=0.7, top_k=15, temp=1.3\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1220, ROUGE-2: 0.0137, ROUGE-L: 0.1140, METEOR: 0.0439, Emotion: 0.9900, Combined: 0.1977\n",
            "\n",
            "[81/288] Testing top_p=0.7, top_k=20, temp=1.0\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1164, ROUGE-2: 0.0164, ROUGE-L: 0.1138, METEOR: 0.0392, Emotion: 0.9900, Combined: 0.1959\n",
            "\n",
            "[82/288] Testing top_p=0.7, top_k=20, temp=1.1\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1257, ROUGE-2: 0.0147, ROUGE-L: 0.1208, METEOR: 0.0393, Emotion: 0.9700, Combined: 0.1953\n",
            "\n",
            "[83/288] Testing top_p=0.7, top_k=20, temp=1.2\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1268, ROUGE-2: 0.0177, ROUGE-L: 0.1221, METEOR: 0.0529, Emotion: 0.9900, Combined: 0.2015\n",
            "\n",
            "[84/288] Testing top_p=0.7, top_k=20, temp=1.3\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1306, ROUGE-2: 0.0133, ROUGE-L: 0.1244, METEOR: 0.0482, Emotion: 0.9800, Combined: 0.1999\n",
            "\n",
            "[85/288] Testing top_p=0.7, top_k=25, temp=1.0\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1287, ROUGE-2: 0.0117, ROUGE-L: 0.1248, METEOR: 0.0438, Emotion: 0.9900, Combined: 0.1995\n",
            "\n",
            "[86/288] Testing top_p=0.7, top_k=25, temp=1.1\n",
            "  BLEU: 0.0137, ROUGE-1: 0.1400, ROUGE-2: 0.0263, ROUGE-L: 0.1343, METEOR: 0.0539, Emotion: 0.9900, Combined: 0.2076\n",
            "\n",
            "[87/288] Testing top_p=0.7, top_k=25, temp=1.2\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1216, ROUGE-2: 0.0130, ROUGE-L: 0.1165, METEOR: 0.0466, Emotion: 0.9800, Combined: 0.1968\n",
            "\n",
            "[88/288] Testing top_p=0.7, top_k=25, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1328, ROUGE-2: 0.0172, ROUGE-L: 0.1256, METEOR: 0.0472, Emotion: 0.9800, Combined: 0.2004\n",
            "\n",
            "[89/288] Testing top_p=0.7, top_k=30, temp=1.0\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1238, ROUGE-2: 0.0161, ROUGE-L: 0.1213, METEOR: 0.0442, Emotion: 0.9900, Combined: 0.1989\n",
            "\n",
            "[90/288] Testing top_p=0.7, top_k=30, temp=1.1\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1054, ROUGE-2: 0.0111, ROUGE-L: 0.0986, METEOR: 0.0429, Emotion: 0.9900, Combined: 0.1922\n",
            "\n",
            "[91/288] Testing top_p=0.7, top_k=30, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1201, ROUGE-2: 0.0128, ROUGE-L: 0.1136, METEOR: 0.0330, Emotion: 0.9900, Combined: 0.1940\n",
            "\n",
            "[92/288] Testing top_p=0.7, top_k=30, temp=1.3\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1334, ROUGE-2: 0.0208, ROUGE-L: 0.1218, METEOR: 0.0553, Emotion: 0.9800, Combined: 0.2027\n",
            "\n",
            "[93/288] Testing top_p=0.7, top_k=35, temp=1.0\n",
            "  BLEU: 0.0145, ROUGE-1: 0.1380, ROUGE-2: 0.0218, ROUGE-L: 0.1341, METEOR: 0.0581, Emotion: 0.9800, Combined: 0.2066\n",
            "\n",
            "[94/288] Testing top_p=0.7, top_k=35, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1295, ROUGE-2: 0.0106, ROUGE-L: 0.1252, METEOR: 0.0520, Emotion: 0.9800, Combined: 0.2002\n",
            "\n",
            "[95/288] Testing top_p=0.7, top_k=35, temp=1.2\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1403, ROUGE-2: 0.0144, ROUGE-L: 0.1328, METEOR: 0.0470, Emotion: 0.9900, Combined: 0.2037\n",
            "\n",
            "[96/288] Testing top_p=0.7, top_k=35, temp=1.3\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1295, ROUGE-2: 0.0089, ROUGE-L: 0.1210, METEOR: 0.0626, Emotion: 0.9900, Combined: 0.2029\n",
            "\n",
            "[97/288] Testing top_p=0.75, top_k=0, temp=1.0\n",
            "  BLEU: 0.0130, ROUGE-1: 0.1368, ROUGE-2: 0.0275, ROUGE-L: 0.1355, METEOR: 0.0694, Emotion: 0.9800, Combined: 0.2094\n",
            "\n",
            "[98/288] Testing top_p=0.75, top_k=0, temp=1.1\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1249, ROUGE-2: 0.0179, ROUGE-L: 0.1172, METEOR: 0.0480, Emotion: 0.9800, Combined: 0.1984\n",
            "\n",
            "[99/288] Testing top_p=0.75, top_k=0, temp=1.2\n",
            "  BLEU: 0.0169, ROUGE-1: 0.1353, ROUGE-2: 0.0251, ROUGE-L: 0.1300, METEOR: 0.0535, Emotion: 0.9800, Combined: 0.2057\n",
            "\n",
            "[100/288] Testing top_p=0.75, top_k=0, temp=1.3\n",
            "  BLEU: 0.0145, ROUGE-1: 0.1169, ROUGE-2: 0.0154, ROUGE-L: 0.1096, METEOR: 0.0656, Emotion: 0.9200, Combined: 0.1933\n",
            "\n",
            "[101/288] Testing top_p=0.75, top_k=5, temp=1.0\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1264, ROUGE-2: 0.0097, ROUGE-L: 0.1204, METEOR: 0.0414, Emotion: 0.9800, Combined: 0.1965\n",
            "\n",
            "[102/288] Testing top_p=0.75, top_k=5, temp=1.1\n",
            "  BLEU: 0.0206, ROUGE-1: 0.1336, ROUGE-2: 0.0218, ROUGE-L: 0.1262, METEOR: 0.0558, Emotion: 0.9900, Combined: 0.2065\n",
            "\n",
            "[103/288] Testing top_p=0.75, top_k=5, temp=1.2\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1292, ROUGE-2: 0.0232, ROUGE-L: 0.1258, METEOR: 0.0471, Emotion: 0.9900, Combined: 0.2022\n",
            "\n",
            "[104/288] Testing top_p=0.75, top_k=5, temp=1.3\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1236, ROUGE-2: 0.0149, ROUGE-L: 0.1200, METEOR: 0.0441, Emotion: 0.9800, Combined: 0.1974\n",
            "\n",
            "[105/288] Testing top_p=0.75, top_k=10, temp=1.0\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1265, ROUGE-2: 0.0171, ROUGE-L: 0.1193, METEOR: 0.0547, Emotion: 0.9900, Combined: 0.2016\n",
            "\n",
            "[106/288] Testing top_p=0.75, top_k=10, temp=1.1\n",
            "  BLEU: 0.0085, ROUGE-1: 0.1240, ROUGE-2: 0.0045, ROUGE-L: 0.1205, METEOR: 0.0380, Emotion: 0.9900, Combined: 0.1956\n",
            "\n",
            "[107/288] Testing top_p=0.75, top_k=10, temp=1.2\n",
            "  BLEU: 0.0061, ROUGE-1: 0.1117, ROUGE-2: 0.0098, ROUGE-L: 0.1060, METEOR: 0.0356, Emotion: 0.9800, Combined: 0.1905\n",
            "\n",
            "[108/288] Testing top_p=0.75, top_k=10, temp=1.3\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1305, ROUGE-2: 0.0144, ROUGE-L: 0.1264, METEOR: 0.0517, Emotion: 0.9900, Combined: 0.2019\n",
            "\n",
            "[109/288] Testing top_p=0.75, top_k=15, temp=1.0\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1213, ROUGE-2: 0.0149, ROUGE-L: 0.1156, METEOR: 0.0393, Emotion: 0.9900, Combined: 0.1963\n",
            "\n",
            "[110/288] Testing top_p=0.75, top_k=15, temp=1.1\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1178, ROUGE-2: 0.0069, ROUGE-L: 0.1046, METEOR: 0.0378, Emotion: 0.9800, Combined: 0.1915\n",
            "\n",
            "[111/288] Testing top_p=0.75, top_k=15, temp=1.2\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1293, ROUGE-2: 0.0097, ROUGE-L: 0.1218, METEOR: 0.0455, Emotion: 0.9800, Combined: 0.1985\n",
            "\n",
            "[112/288] Testing top_p=0.75, top_k=15, temp=1.3\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1294, ROUGE-2: 0.0128, ROUGE-L: 0.1272, METEOR: 0.0561, Emotion: 0.9800, Combined: 0.2020\n",
            "\n",
            "[113/288] Testing top_p=0.75, top_k=20, temp=1.0\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1301, ROUGE-2: 0.0165, ROUGE-L: 0.1250, METEOR: 0.0391, Emotion: 0.9900, Combined: 0.1994\n",
            "\n",
            "[114/288] Testing top_p=0.75, top_k=20, temp=1.1\n",
            "  BLEU: 0.0081, ROUGE-1: 0.1185, ROUGE-2: 0.0134, ROUGE-L: 0.1107, METEOR: 0.0408, Emotion: 0.9900, Combined: 0.1952\n",
            "\n",
            "[115/288] Testing top_p=0.75, top_k=20, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1302, ROUGE-2: 0.0261, ROUGE-L: 0.1261, METEOR: 0.0569, Emotion: 0.9900, Combined: 0.2051\n",
            "\n",
            "[116/288] Testing top_p=0.75, top_k=20, temp=1.3\n",
            "  BLEU: 0.0131, ROUGE-1: 0.1395, ROUGE-2: 0.0251, ROUGE-L: 0.1322, METEOR: 0.0644, Emotion: 0.9900, Combined: 0.2090\n",
            "\n",
            "[117/288] Testing top_p=0.75, top_k=25, temp=1.0\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1350, ROUGE-2: 0.0177, ROUGE-L: 0.1278, METEOR: 0.0482, Emotion: 0.9900, Combined: 0.2027\n",
            "\n",
            "[118/288] Testing top_p=0.75, top_k=25, temp=1.1\n",
            "  BLEU: 0.0125, ROUGE-1: 0.1293, ROUGE-2: 0.0128, ROUGE-L: 0.1258, METEOR: 0.0533, Emotion: 0.9800, Combined: 0.2013\n",
            "\n",
            "[119/288] Testing top_p=0.75, top_k=25, temp=1.2\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1165, ROUGE-2: 0.0175, ROUGE-L: 0.1086, METEOR: 0.0520, Emotion: 0.9900, Combined: 0.1978\n",
            "\n",
            "[120/288] Testing top_p=0.75, top_k=25, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1159, ROUGE-2: 0.0148, ROUGE-L: 0.1096, METEOR: 0.0445, Emotion: 0.9800, Combined: 0.1946\n",
            "\n",
            "[121/288] Testing top_p=0.75, top_k=30, temp=1.0\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1304, ROUGE-2: 0.0205, ROUGE-L: 0.1257, METEOR: 0.0430, Emotion: 0.9700, Combined: 0.1992\n",
            "\n",
            "[122/288] Testing top_p=0.75, top_k=30, temp=1.1\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1272, ROUGE-2: 0.0068, ROUGE-L: 0.1217, METEOR: 0.0409, Emotion: 0.9700, Combined: 0.1949\n",
            "\n",
            "[123/288] Testing top_p=0.75, top_k=30, temp=1.2\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1319, ROUGE-2: 0.0235, ROUGE-L: 0.1280, METEOR: 0.0516, Emotion: 0.9800, Combined: 0.2034\n",
            "\n",
            "[124/288] Testing top_p=0.75, top_k=30, temp=1.3\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1252, ROUGE-2: 0.0101, ROUGE-L: 0.1234, METEOR: 0.0570, Emotion: 0.9900, Combined: 0.2014\n",
            "\n",
            "[125/288] Testing top_p=0.75, top_k=35, temp=1.0\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1386, ROUGE-2: 0.0128, ROUGE-L: 0.1312, METEOR: 0.0509, Emotion: 0.9800, Combined: 0.2019\n",
            "\n",
            "[126/288] Testing top_p=0.75, top_k=35, temp=1.1\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1369, ROUGE-2: 0.0155, ROUGE-L: 0.1302, METEOR: 0.0549, Emotion: 0.9900, Combined: 0.2047\n",
            "\n",
            "[127/288] Testing top_p=0.75, top_k=35, temp=1.2\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1357, ROUGE-2: 0.0193, ROUGE-L: 0.1223, METEOR: 0.0516, Emotion: 0.9700, Combined: 0.2012\n",
            "\n",
            "[128/288] Testing top_p=0.75, top_k=35, temp=1.3\n",
            "  BLEU: 0.0138, ROUGE-1: 0.1334, ROUGE-2: 0.0085, ROUGE-L: 0.1235, METEOR: 0.0489, Emotion: 0.9800, Combined: 0.2003\n",
            "\n",
            "[129/288] Testing top_p=0.8, top_k=0, temp=1.0\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1319, ROUGE-2: 0.0180, ROUGE-L: 0.1249, METEOR: 0.0449, Emotion: 0.9900, Combined: 0.2012\n",
            "\n",
            "[130/288] Testing top_p=0.8, top_k=0, temp=1.1\n",
            "  BLEU: 0.0181, ROUGE-1: 0.1139, ROUGE-2: 0.0158, ROUGE-L: 0.1073, METEOR: 0.0481, Emotion: 0.9900, Combined: 0.1978\n",
            "\n",
            "[131/288] Testing top_p=0.8, top_k=0, temp=1.2\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1093, ROUGE-2: 0.0064, ROUGE-L: 0.0973, METEOR: 0.0408, Emotion: 0.9500, Combined: 0.1867\n",
            "\n",
            "[132/288] Testing top_p=0.8, top_k=0, temp=1.3\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1038, ROUGE-2: 0.0115, ROUGE-L: 0.0932, METEOR: 0.0604, Emotion: 0.9000, Combined: 0.1837\n",
            "\n",
            "[133/288] Testing top_p=0.8, top_k=5, temp=1.0\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1285, ROUGE-2: 0.0158, ROUGE-L: 0.1285, METEOR: 0.0453, Emotion: 0.9900, Combined: 0.2012\n",
            "\n",
            "[134/288] Testing top_p=0.8, top_k=5, temp=1.1\n",
            "  BLEU: 0.0148, ROUGE-1: 0.1416, ROUGE-2: 0.0253, ROUGE-L: 0.1368, METEOR: 0.0529, Emotion: 0.9900, Combined: 0.2081\n",
            "\n",
            "[135/288] Testing top_p=0.8, top_k=5, temp=1.2\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1298, ROUGE-2: 0.0250, ROUGE-L: 0.1246, METEOR: 0.0516, Emotion: 0.9900, Combined: 0.2036\n",
            "\n",
            "[136/288] Testing top_p=0.8, top_k=5, temp=1.3\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1416, ROUGE-2: 0.0220, ROUGE-L: 0.1356, METEOR: 0.0507, Emotion: 0.9800, Combined: 0.2051\n",
            "\n",
            "[137/288] Testing top_p=0.8, top_k=10, temp=1.0\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1436, ROUGE-2: 0.0187, ROUGE-L: 0.1405, METEOR: 0.0550, Emotion: 0.9800, Combined: 0.2061\n",
            "\n",
            "[138/288] Testing top_p=0.8, top_k=10, temp=1.1\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1291, ROUGE-2: 0.0200, ROUGE-L: 0.1207, METEOR: 0.0607, Emotion: 0.9900, Combined: 0.2036\n",
            "\n",
            "[139/288] Testing top_p=0.8, top_k=10, temp=1.2\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1445, ROUGE-2: 0.0318, ROUGE-L: 0.1387, METEOR: 0.0600, Emotion: 0.9700, Combined: 0.2078\n",
            "\n",
            "[140/288] Testing top_p=0.8, top_k=10, temp=1.3\n",
            "  BLEU: 0.0117, ROUGE-1: 0.1159, ROUGE-2: 0.0088, ROUGE-L: 0.1053, METEOR: 0.0451, Emotion: 0.9800, Combined: 0.1939\n",
            "\n",
            "[141/288] Testing top_p=0.8, top_k=15, temp=1.0\n",
            "  BLEU: 0.0148, ROUGE-1: 0.1442, ROUGE-2: 0.0227, ROUGE-L: 0.1351, METEOR: 0.0588, Emotion: 0.9900, Combined: 0.2090\n",
            "\n",
            "[142/288] Testing top_p=0.8, top_k=15, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1252, ROUGE-2: 0.0136, ROUGE-L: 0.1215, METEOR: 0.0442, Emotion: 0.9800, Combined: 0.1978\n",
            "\n",
            "[143/288] Testing top_p=0.8, top_k=15, temp=1.2\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1342, ROUGE-2: 0.0212, ROUGE-L: 0.1286, METEOR: 0.0638, Emotion: 0.9700, Combined: 0.2041\n",
            "\n",
            "[144/288] Testing top_p=0.8, top_k=15, temp=1.3\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1141, ROUGE-2: 0.0138, ROUGE-L: 0.1038, METEOR: 0.0453, Emotion: 0.9900, Combined: 0.1948\n",
            "\n",
            "[145/288] Testing top_p=0.8, top_k=20, temp=1.0\n",
            "  BLEU: 0.0132, ROUGE-1: 0.1364, ROUGE-2: 0.0157, ROUGE-L: 0.1279, METEOR: 0.0437, Emotion: 0.9900, Combined: 0.2024\n",
            "\n",
            "[146/288] Testing top_p=0.8, top_k=20, temp=1.1\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1295, ROUGE-2: 0.0139, ROUGE-L: 0.1222, METEOR: 0.0491, Emotion: 0.9800, Combined: 0.1993\n",
            "\n",
            "[147/288] Testing top_p=0.8, top_k=20, temp=1.2\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1357, ROUGE-2: 0.0208, ROUGE-L: 0.1277, METEOR: 0.0464, Emotion: 0.9900, Combined: 0.2031\n",
            "\n",
            "[148/288] Testing top_p=0.8, top_k=20, temp=1.3\n",
            "  BLEU: 0.0125, ROUGE-1: 0.1569, ROUGE-2: 0.0194, ROUGE-L: 0.1477, METEOR: 0.0607, Emotion: 0.9800, Combined: 0.2112\n",
            "\n",
            "[149/288] Testing top_p=0.8, top_k=25, temp=1.0\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1230, ROUGE-2: 0.0086, ROUGE-L: 0.1204, METEOR: 0.0413, Emotion: 0.9900, Combined: 0.1970\n",
            "\n",
            "[150/288] Testing top_p=0.8, top_k=25, temp=1.1\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1080, ROUGE-2: 0.0109, ROUGE-L: 0.0992, METEOR: 0.0492, Emotion: 0.9800, Combined: 0.1922\n",
            "\n",
            "[151/288] Testing top_p=0.8, top_k=25, temp=1.2\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1259, ROUGE-2: 0.0181, ROUGE-L: 0.1207, METEOR: 0.0545, Emotion: 0.9900, Combined: 0.2017\n",
            "\n",
            "[152/288] Testing top_p=0.8, top_k=25, temp=1.3\n",
            "  BLEU: 0.0117, ROUGE-1: 0.1120, ROUGE-2: 0.0210, ROUGE-L: 0.1060, METEOR: 0.0526, Emotion: 0.9800, Combined: 0.1967\n",
            "\n",
            "[153/288] Testing top_p=0.8, top_k=30, temp=1.0\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1075, ROUGE-2: 0.0179, ROUGE-L: 0.1041, METEOR: 0.0424, Emotion: 0.9800, Combined: 0.1924\n",
            "\n",
            "[154/288] Testing top_p=0.8, top_k=30, temp=1.1\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1083, ROUGE-2: 0.0129, ROUGE-L: 0.1048, METEOR: 0.0420, Emotion: 0.9900, Combined: 0.1928\n",
            "\n",
            "[155/288] Testing top_p=0.8, top_k=30, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1063, ROUGE-2: 0.0053, ROUGE-L: 0.0997, METEOR: 0.0440, Emotion: 0.9900, Combined: 0.1912\n",
            "\n",
            "[156/288] Testing top_p=0.8, top_k=30, temp=1.3\n",
            "  BLEU: 0.0134, ROUGE-1: 0.1386, ROUGE-2: 0.0235, ROUGE-L: 0.1298, METEOR: 0.0557, Emotion: 0.9600, Combined: 0.2031\n",
            "\n",
            "[157/288] Testing top_p=0.8, top_k=35, temp=1.0\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1209, ROUGE-2: 0.0151, ROUGE-L: 0.1144, METEOR: 0.0466, Emotion: 0.9900, Combined: 0.1980\n",
            "\n",
            "[158/288] Testing top_p=0.8, top_k=35, temp=1.1\n",
            "  BLEU: 0.0139, ROUGE-1: 0.1363, ROUGE-2: 0.0187, ROUGE-L: 0.1294, METEOR: 0.0579, Emotion: 0.9900, Combined: 0.2060\n",
            "\n",
            "[159/288] Testing top_p=0.8, top_k=35, temp=1.2\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1216, ROUGE-2: 0.0092, ROUGE-L: 0.1100, METEOR: 0.0420, Emotion: 0.9800, Combined: 0.1943\n",
            "\n",
            "[160/288] Testing top_p=0.8, top_k=35, temp=1.3\n",
            "  BLEU: 0.0067, ROUGE-1: 0.1082, ROUGE-2: 0.0095, ROUGE-L: 0.1070, METEOR: 0.0412, Emotion: 0.9800, Combined: 0.1913\n",
            "\n",
            "[161/288] Testing top_p=0.85, top_k=0, temp=1.0\n",
            "  BLEU: 0.0056, ROUGE-1: 0.1245, ROUGE-2: 0.0079, ROUGE-L: 0.1158, METEOR: 0.0373, Emotion: 0.9900, Combined: 0.1948\n",
            "\n",
            "[162/288] Testing top_p=0.85, top_k=0, temp=1.1\n",
            "  BLEU: 0.0218, ROUGE-1: 0.1336, ROUGE-2: 0.0262, ROUGE-L: 0.1312, METEOR: 0.0603, Emotion: 0.9600, Combined: 0.2051\n",
            "\n",
            "[163/288] Testing top_p=0.85, top_k=0, temp=1.2\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1138, ROUGE-2: 0.0069, ROUGE-L: 0.1091, METEOR: 0.0375, Emotion: 0.9600, Combined: 0.1886\n",
            "\n",
            "[164/288] Testing top_p=0.85, top_k=0, temp=1.3\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1039, ROUGE-2: 0.0099, ROUGE-L: 0.0944, METEOR: 0.0499, Emotion: 0.8700, Combined: 0.1774\n",
            "\n",
            "[165/288] Testing top_p=0.85, top_k=5, temp=1.0\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1435, ROUGE-2: 0.0317, ROUGE-L: 0.1361, METEOR: 0.0601, Emotion: 0.9800, Combined: 0.2089\n",
            "\n",
            "[166/288] Testing top_p=0.85, top_k=5, temp=1.1\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1249, ROUGE-2: 0.0175, ROUGE-L: 0.1210, METEOR: 0.0390, Emotion: 0.9700, Combined: 0.1952\n",
            "\n",
            "[167/288] Testing top_p=0.85, top_k=5, temp=1.2\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1296, ROUGE-2: 0.0177, ROUGE-L: 0.1211, METEOR: 0.0517, Emotion: 0.9800, Combined: 0.2010\n",
            "\n",
            "[168/288] Testing top_p=0.85, top_k=5, temp=1.3\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1372, ROUGE-2: 0.0202, ROUGE-L: 0.1323, METEOR: 0.0502, Emotion: 0.9800, Combined: 0.2035\n",
            "\n",
            "[169/288] Testing top_p=0.85, top_k=10, temp=1.0\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1134, ROUGE-2: 0.0189, ROUGE-L: 0.1080, METEOR: 0.0436, Emotion: 0.9800, Combined: 0.1946\n",
            "\n",
            "[170/288] Testing top_p=0.85, top_k=10, temp=1.1\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1192, ROUGE-2: 0.0162, ROUGE-L: 0.1051, METEOR: 0.0462, Emotion: 0.9800, Combined: 0.1952\n",
            "\n",
            "[171/288] Testing top_p=0.85, top_k=10, temp=1.2\n",
            "  BLEU: 0.0076, ROUGE-1: 0.1360, ROUGE-2: 0.0155, ROUGE-L: 0.1261, METEOR: 0.0455, Emotion: 0.9900, Combined: 0.2013\n",
            "\n",
            "[172/288] Testing top_p=0.85, top_k=10, temp=1.3\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1196, ROUGE-2: 0.0184, ROUGE-L: 0.1096, METEOR: 0.0477, Emotion: 0.9800, Combined: 0.1961\n",
            "\n",
            "[173/288] Testing top_p=0.85, top_k=15, temp=1.0\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1240, ROUGE-2: 0.0236, ROUGE-L: 0.1205, METEOR: 0.0427, Emotion: 0.9900, Combined: 0.2001\n",
            "\n",
            "[174/288] Testing top_p=0.85, top_k=15, temp=1.1\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1312, ROUGE-2: 0.0160, ROUGE-L: 0.1220, METEOR: 0.0598, Emotion: 0.9800, Combined: 0.2027\n",
            "\n",
            "[175/288] Testing top_p=0.85, top_k=15, temp=1.2\n",
            "  BLEU: 0.0085, ROUGE-1: 0.1129, ROUGE-2: 0.0104, ROUGE-L: 0.1064, METEOR: 0.0462, Emotion: 0.9700, Combined: 0.1924\n",
            "\n",
            "[176/288] Testing top_p=0.85, top_k=15, temp=1.3\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1303, ROUGE-2: 0.0122, ROUGE-L: 0.1188, METEOR: 0.0572, Emotion: 0.9700, Combined: 0.1994\n",
            "\n",
            "[177/288] Testing top_p=0.85, top_k=20, temp=1.0\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1187, ROUGE-2: 0.0109, ROUGE-L: 0.1129, METEOR: 0.0452, Emotion: 0.9700, Combined: 0.1943\n",
            "\n",
            "[178/288] Testing top_p=0.85, top_k=20, temp=1.1\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1287, ROUGE-2: 0.0159, ROUGE-L: 0.1258, METEOR: 0.0528, Emotion: 0.9900, Combined: 0.2018\n",
            "\n",
            "[179/288] Testing top_p=0.85, top_k=20, temp=1.2\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1247, ROUGE-2: 0.0184, ROUGE-L: 0.1199, METEOR: 0.0585, Emotion: 0.9700, Combined: 0.1998\n",
            "\n",
            "[180/288] Testing top_p=0.85, top_k=20, temp=1.3\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1157, ROUGE-2: 0.0135, ROUGE-L: 0.1067, METEOR: 0.0484, Emotion: 0.9800, Combined: 0.1948\n",
            "\n",
            "[181/288] Testing top_p=0.85, top_k=25, temp=1.0\n",
            "  BLEU: 0.0153, ROUGE-1: 0.1336, ROUGE-2: 0.0315, ROUGE-L: 0.1293, METEOR: 0.0569, Emotion: 0.9800, Combined: 0.2066\n",
            "\n",
            "[182/288] Testing top_p=0.85, top_k=25, temp=1.1\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1207, ROUGE-2: 0.0145, ROUGE-L: 0.1171, METEOR: 0.0493, Emotion: 0.9800, Combined: 0.1975\n",
            "\n",
            "[183/288] Testing top_p=0.85, top_k=25, temp=1.2\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1200, ROUGE-2: 0.0203, ROUGE-L: 0.1151, METEOR: 0.0664, Emotion: 0.9900, Combined: 0.2028\n",
            "\n",
            "[184/288] Testing top_p=0.85, top_k=25, temp=1.3\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1142, ROUGE-2: 0.0084, ROUGE-L: 0.1118, METEOR: 0.0483, Emotion: 0.9800, Combined: 0.1943\n",
            "\n",
            "[185/288] Testing top_p=0.85, top_k=30, temp=1.0\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1493, ROUGE-2: 0.0234, ROUGE-L: 0.1394, METEOR: 0.0510, Emotion: 0.9800, Combined: 0.2069\n",
            "\n",
            "[186/288] Testing top_p=0.85, top_k=30, temp=1.1\n",
            "  BLEU: 0.0115, ROUGE-1: 0.1154, ROUGE-2: 0.0109, ROUGE-L: 0.1093, METEOR: 0.0450, Emotion: 0.9900, Combined: 0.1956\n",
            "\n",
            "[187/288] Testing top_p=0.85, top_k=30, temp=1.2\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1104, ROUGE-2: 0.0109, ROUGE-L: 0.1034, METEOR: 0.0466, Emotion: 0.9600, Combined: 0.1899\n",
            "\n",
            "[188/288] Testing top_p=0.85, top_k=30, temp=1.3\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1231, ROUGE-2: 0.0095, ROUGE-L: 0.1180, METEOR: 0.0427, Emotion: 0.9400, Combined: 0.1900\n",
            "\n",
            "[189/288] Testing top_p=0.85, top_k=35, temp=1.0\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1265, ROUGE-2: 0.0238, ROUGE-L: 0.1192, METEOR: 0.0472, Emotion: 0.9800, Combined: 0.2000\n",
            "\n",
            "[190/288] Testing top_p=0.85, top_k=35, temp=1.1\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1202, ROUGE-2: 0.0199, ROUGE-L: 0.1145, METEOR: 0.0577, Emotion: 0.9800, Combined: 0.2004\n",
            "\n",
            "[191/288] Testing top_p=0.85, top_k=35, temp=1.2\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1258, ROUGE-2: 0.0178, ROUGE-L: 0.1200, METEOR: 0.0604, Emotion: 0.9800, Combined: 0.2021\n",
            "\n",
            "[192/288] Testing top_p=0.85, top_k=35, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1085, ROUGE-2: 0.0108, ROUGE-L: 0.1026, METEOR: 0.0385, Emotion: 0.9500, Combined: 0.1856\n",
            "\n",
            "[193/288] Testing top_p=0.9, top_k=0, temp=1.0\n",
            "  BLEU: 0.0090, ROUGE-1: 0.1307, ROUGE-2: 0.0130, ROUGE-L: 0.1197, METEOR: 0.0480, Emotion: 0.9600, Combined: 0.1964\n",
            "\n",
            "[194/288] Testing top_p=0.9, top_k=0, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1069, ROUGE-2: 0.0089, ROUGE-L: 0.1035, METEOR: 0.0372, Emotion: 0.9200, Combined: 0.1821\n",
            "\n",
            "[195/288] Testing top_p=0.9, top_k=0, temp=1.2\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1039, ROUGE-2: 0.0097, ROUGE-L: 0.0989, METEOR: 0.0478, Emotion: 0.9100, Combined: 0.1824\n",
            "\n",
            "[196/288] Testing top_p=0.9, top_k=0, temp=1.3\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1123, ROUGE-2: 0.0121, ROUGE-L: 0.1060, METEOR: 0.0552, Emotion: 0.7800, Combined: 0.1720\n",
            "\n",
            "[197/288] Testing top_p=0.9, top_k=5, temp=1.0\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1167, ROUGE-2: 0.0164, ROUGE-L: 0.1123, METEOR: 0.0429, Emotion: 0.9700, Combined: 0.1942\n",
            "\n",
            "[198/288] Testing top_p=0.9, top_k=5, temp=1.1\n",
            "  BLEU: 0.0063, ROUGE-1: 0.1085, ROUGE-2: 0.0081, ROUGE-L: 0.1013, METEOR: 0.0284, Emotion: 0.9800, Combined: 0.1876\n",
            "\n",
            "[199/288] Testing top_p=0.9, top_k=5, temp=1.2\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1215, ROUGE-2: 0.0192, ROUGE-L: 0.1144, METEOR: 0.0539, Emotion: 0.9900, Combined: 0.2000\n",
            "\n",
            "[200/288] Testing top_p=0.9, top_k=5, temp=1.3\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1378, ROUGE-2: 0.0133, ROUGE-L: 0.1277, METEOR: 0.0507, Emotion: 0.9900, Combined: 0.2032\n",
            "\n",
            "[201/288] Testing top_p=0.9, top_k=10, temp=1.0\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1278, ROUGE-2: 0.0147, ROUGE-L: 0.1225, METEOR: 0.0463, Emotion: 0.9900, Combined: 0.2002\n",
            "\n",
            "[202/288] Testing top_p=0.9, top_k=10, temp=1.1\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1334, ROUGE-2: 0.0162, ROUGE-L: 0.1210, METEOR: 0.0542, Emotion: 0.9900, Combined: 0.2023\n",
            "\n",
            "[203/288] Testing top_p=0.9, top_k=10, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1169, ROUGE-2: 0.0106, ROUGE-L: 0.1126, METEOR: 0.0486, Emotion: 0.9800, Combined: 0.1955\n",
            "\n",
            "[204/288] Testing top_p=0.9, top_k=10, temp=1.3\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1238, ROUGE-2: 0.0064, ROUGE-L: 0.1108, METEOR: 0.0408, Emotion: 0.9800, Combined: 0.1943\n",
            "\n",
            "[205/288] Testing top_p=0.9, top_k=15, temp=1.0\n",
            "  BLEU: 0.0109, ROUGE-1: 0.1345, ROUGE-2: 0.0204, ROUGE-L: 0.1250, METEOR: 0.0525, Emotion: 0.9900, Combined: 0.2037\n",
            "\n",
            "[206/288] Testing top_p=0.9, top_k=15, temp=1.1\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1175, ROUGE-2: 0.0142, ROUGE-L: 0.1129, METEOR: 0.0501, Emotion: 0.9900, Combined: 0.1976\n",
            "\n",
            "[207/288] Testing top_p=0.9, top_k=15, temp=1.2\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1278, ROUGE-2: 0.0261, ROUGE-L: 0.1258, METEOR: 0.0735, Emotion: 0.9500, Combined: 0.2041\n",
            "\n",
            "[208/288] Testing top_p=0.9, top_k=15, temp=1.3\n",
            "  BLEU: 0.0080, ROUGE-1: 0.0974, ROUGE-2: 0.0026, ROUGE-L: 0.0900, METEOR: 0.0426, Emotion: 0.9700, Combined: 0.1851\n",
            "\n",
            "[209/288] Testing top_p=0.9, top_k=20, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1245, ROUGE-2: 0.0145, ROUGE-L: 0.1193, METEOR: 0.0473, Emotion: 0.9700, Combined: 0.1972\n",
            "\n",
            "[210/288] Testing top_p=0.9, top_k=20, temp=1.1\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1222, ROUGE-2: 0.0070, ROUGE-L: 0.1161, METEOR: 0.0406, Emotion: 0.9800, Combined: 0.1945\n",
            "\n",
            "[211/288] Testing top_p=0.9, top_k=20, temp=1.2\n",
            "  BLEU: 0.0101, ROUGE-1: 0.1292, ROUGE-2: 0.0132, ROUGE-L: 0.1283, METEOR: 0.0454, Emotion: 0.9700, Combined: 0.1982\n",
            "\n",
            "[212/288] Testing top_p=0.9, top_k=20, temp=1.3\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1213, ROUGE-2: 0.0089, ROUGE-L: 0.1180, METEOR: 0.0426, Emotion: 0.9800, Combined: 0.1953\n",
            "\n",
            "[213/288] Testing top_p=0.9, top_k=25, temp=1.0\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1166, ROUGE-2: 0.0090, ROUGE-L: 0.1096, METEOR: 0.0362, Emotion: 0.9800, Combined: 0.1923\n",
            "\n",
            "[214/288] Testing top_p=0.9, top_k=25, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1244, ROUGE-2: 0.0081, ROUGE-L: 0.1161, METEOR: 0.0440, Emotion: 0.9700, Combined: 0.1950\n",
            "\n",
            "[215/288] Testing top_p=0.9, top_k=25, temp=1.2\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1251, ROUGE-2: 0.0126, ROUGE-L: 0.1183, METEOR: 0.0469, Emotion: 0.9500, Combined: 0.1932\n",
            "\n",
            "[216/288] Testing top_p=0.9, top_k=25, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1233, ROUGE-2: 0.0124, ROUGE-L: 0.1176, METEOR: 0.0548, Emotion: 0.9300, Combined: 0.1911\n",
            "\n",
            "[217/288] Testing top_p=0.9, top_k=30, temp=1.0\n",
            "  BLEU: 0.0191, ROUGE-1: 0.1262, ROUGE-2: 0.0159, ROUGE-L: 0.1209, METEOR: 0.0471, Emotion: 0.9800, Combined: 0.2007\n",
            "\n",
            "[218/288] Testing top_p=0.9, top_k=30, temp=1.1\n",
            "  BLEU: 0.0073, ROUGE-1: 0.1128, ROUGE-2: 0.0089, ROUGE-L: 0.1012, METEOR: 0.0416, Emotion: 0.9700, Combined: 0.1892\n",
            "\n",
            "[219/288] Testing top_p=0.9, top_k=30, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.0993, ROUGE-2: 0.0057, ROUGE-L: 0.0900, METEOR: 0.0403, Emotion: 0.9600, Combined: 0.1840\n",
            "\n",
            "[220/288] Testing top_p=0.9, top_k=30, temp=1.3\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1092, ROUGE-2: 0.0112, ROUGE-L: 0.1035, METEOR: 0.0411, Emotion: 0.9400, Combined: 0.1858\n",
            "\n",
            "[221/288] Testing top_p=0.9, top_k=35, temp=1.0\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1300, ROUGE-2: 0.0118, ROUGE-L: 0.1262, METEOR: 0.0444, Emotion: 0.9800, Combined: 0.1993\n",
            "\n",
            "[222/288] Testing top_p=0.9, top_k=35, temp=1.1\n",
            "  BLEU: 0.0160, ROUGE-1: 0.1414, ROUGE-2: 0.0224, ROUGE-L: 0.1380, METEOR: 0.0647, Emotion: 0.9800, Combined: 0.2089\n",
            "\n",
            "[223/288] Testing top_p=0.9, top_k=35, temp=1.2\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1182, ROUGE-2: 0.0142, ROUGE-L: 0.1141, METEOR: 0.0499, Emotion: 0.9700, Combined: 0.1952\n",
            "\n",
            "[224/288] Testing top_p=0.9, top_k=35, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1059, ROUGE-2: 0.0074, ROUGE-L: 0.0980, METEOR: 0.0454, Emotion: 0.9500, Combined: 0.1862\n",
            "\n",
            "[225/288] Testing top_p=0.95, top_k=0, temp=1.0\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1080, ROUGE-2: 0.0114, ROUGE-L: 0.1039, METEOR: 0.0403, Emotion: 0.9800, Combined: 0.1908\n",
            "\n",
            "[226/288] Testing top_p=0.95, top_k=0, temp=1.1\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1119, ROUGE-2: 0.0154, ROUGE-L: 0.1038, METEOR: 0.0590, Emotion: 0.9600, Combined: 0.1947\n",
            "\n",
            "[227/288] Testing top_p=0.95, top_k=0, temp=1.2\n",
            "  BLEU: 0.0141, ROUGE-1: 0.1355, ROUGE-2: 0.0186, ROUGE-L: 0.1245, METEOR: 0.0709, Emotion: 0.9100, Combined: 0.1993\n",
            "\n",
            "[228/288] Testing top_p=0.95, top_k=0, temp=1.3\n",
            "  BLEU: 0.0079, ROUGE-1: 0.0928, ROUGE-2: 0.0056, ROUGE-L: 0.0854, METEOR: 0.0465, Emotion: 0.8200, Combined: 0.1679\n",
            "\n",
            "[229/288] Testing top_p=0.95, top_k=5, temp=1.0\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1406, ROUGE-2: 0.0242, ROUGE-L: 0.1352, METEOR: 0.0567, Emotion: 0.9800, Combined: 0.2064\n",
            "\n",
            "[230/288] Testing top_p=0.95, top_k=5, temp=1.1\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1260, ROUGE-2: 0.0161, ROUGE-L: 0.1163, METEOR: 0.0426, Emotion: 0.9800, Combined: 0.1967\n",
            "\n",
            "[231/288] Testing top_p=0.95, top_k=5, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1200, ROUGE-2: 0.0128, ROUGE-L: 0.1142, METEOR: 0.0417, Emotion: 0.9800, Combined: 0.1948\n",
            "\n",
            "[232/288] Testing top_p=0.95, top_k=5, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1087, ROUGE-2: 0.0160, ROUGE-L: 0.1027, METEOR: 0.0478, Emotion: 0.9700, Combined: 0.1913\n",
            "\n",
            "[233/288] Testing top_p=0.95, top_k=10, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1309, ROUGE-2: 0.0130, ROUGE-L: 0.1244, METEOR: 0.0430, Emotion: 0.9900, Combined: 0.1998\n",
            "\n",
            "[234/288] Testing top_p=0.95, top_k=10, temp=1.1\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1265, ROUGE-2: 0.0158, ROUGE-L: 0.1194, METEOR: 0.0494, Emotion: 0.9700, Combined: 0.1979\n",
            "\n",
            "[235/288] Testing top_p=0.95, top_k=10, temp=1.2\n",
            "  BLEU: 0.0066, ROUGE-1: 0.1086, ROUGE-2: 0.0103, ROUGE-L: 0.1027, METEOR: 0.0416, Emotion: 0.9600, Combined: 0.1874\n",
            "\n",
            "[236/288] Testing top_p=0.95, top_k=10, temp=1.3\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1206, ROUGE-2: 0.0110, ROUGE-L: 0.1141, METEOR: 0.0545, Emotion: 0.9400, Combined: 0.1918\n",
            "\n",
            "[237/288] Testing top_p=0.95, top_k=15, temp=1.0\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1353, ROUGE-2: 0.0217, ROUGE-L: 0.1227, METEOR: 0.0577, Emotion: 0.9800, Combined: 0.2040\n",
            "\n",
            "[238/288] Testing top_p=0.95, top_k=15, temp=1.1\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1310, ROUGE-2: 0.0138, ROUGE-L: 0.1166, METEOR: 0.0602, Emotion: 0.9600, Combined: 0.1986\n",
            "\n",
            "[239/288] Testing top_p=0.95, top_k=15, temp=1.2\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1308, ROUGE-2: 0.0203, ROUGE-L: 0.1229, METEOR: 0.0633, Emotion: 0.9800, Combined: 0.2042\n",
            "\n",
            "[240/288] Testing top_p=0.95, top_k=15, temp=1.3\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1340, ROUGE-2: 0.0073, ROUGE-L: 0.1217, METEOR: 0.0515, Emotion: 0.9800, Combined: 0.1993\n",
            "\n",
            "[241/288] Testing top_p=0.95, top_k=20, temp=1.0\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1366, ROUGE-2: 0.0136, ROUGE-L: 0.1274, METEOR: 0.0489, Emotion: 0.9800, Combined: 0.2006\n",
            "\n",
            "[242/288] Testing top_p=0.95, top_k=20, temp=1.1\n",
            "  BLEU: 0.0147, ROUGE-1: 0.1336, ROUGE-2: 0.0207, ROUGE-L: 0.1290, METEOR: 0.0662, Emotion: 0.9500, Combined: 0.2022\n",
            "\n",
            "[243/288] Testing top_p=0.95, top_k=20, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1209, ROUGE-2: 0.0144, ROUGE-L: 0.1113, METEOR: 0.0518, Emotion: 0.9200, Combined: 0.1902\n",
            "\n",
            "[244/288] Testing top_p=0.95, top_k=20, temp=1.3\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1072, ROUGE-2: 0.0085, ROUGE-L: 0.0990, METEOR: 0.0495, Emotion: 0.9300, Combined: 0.1838\n",
            "\n",
            "[245/288] Testing top_p=0.95, top_k=25, temp=1.0\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1346, ROUGE-2: 0.0216, ROUGE-L: 0.1243, METEOR: 0.0603, Emotion: 0.9800, Combined: 0.2044\n",
            "\n",
            "[246/288] Testing top_p=0.95, top_k=25, temp=1.1\n",
            "  BLEU: 0.0158, ROUGE-1: 0.1427, ROUGE-2: 0.0327, ROUGE-L: 0.1339, METEOR: 0.0702, Emotion: 0.9800, Combined: 0.2111\n",
            "\n",
            "[247/288] Testing top_p=0.95, top_k=25, temp=1.2\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1226, ROUGE-2: 0.0164, ROUGE-L: 0.1109, METEOR: 0.0487, Emotion: 0.9300, Combined: 0.1899\n",
            "\n",
            "[248/288] Testing top_p=0.95, top_k=25, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1102, ROUGE-2: 0.0085, ROUGE-L: 0.1033, METEOR: 0.0375, Emotion: 0.9300, Combined: 0.1833\n",
            "\n",
            "[249/288] Testing top_p=0.95, top_k=30, temp=1.0\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1286, ROUGE-2: 0.0048, ROUGE-L: 0.1171, METEOR: 0.0540, Emotion: 0.9900, Combined: 0.1997\n",
            "\n",
            "[250/288] Testing top_p=0.95, top_k=30, temp=1.1\n",
            "  BLEU: 0.0170, ROUGE-1: 0.1221, ROUGE-2: 0.0262, ROUGE-L: 0.1187, METEOR: 0.0498, Emotion: 0.9700, Combined: 0.1999\n",
            "\n",
            "[251/288] Testing top_p=0.95, top_k=30, temp=1.2\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1287, ROUGE-2: 0.0049, ROUGE-L: 0.1135, METEOR: 0.0512, Emotion: 0.9300, Combined: 0.1895\n",
            "\n",
            "[252/288] Testing top_p=0.95, top_k=30, temp=1.3\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1067, ROUGE-2: 0.0076, ROUGE-L: 0.1012, METEOR: 0.0429, Emotion: 0.9600, Combined: 0.1877\n",
            "\n",
            "[253/288] Testing top_p=0.95, top_k=35, temp=1.0\n",
            "  BLEU: 0.0132, ROUGE-1: 0.1346, ROUGE-2: 0.0176, ROUGE-L: 0.1247, METEOR: 0.0468, Emotion: 0.9800, Combined: 0.2015\n",
            "\n",
            "[254/288] Testing top_p=0.95, top_k=35, temp=1.1\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1128, ROUGE-2: 0.0134, ROUGE-L: 0.1061, METEOR: 0.0491, Emotion: 0.9600, Combined: 0.1919\n",
            "\n",
            "[255/288] Testing top_p=0.95, top_k=35, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1012, ROUGE-2: 0.0068, ROUGE-L: 0.0914, METEOR: 0.0430, Emotion: 0.9100, Combined: 0.1773\n",
            "\n",
            "[256/288] Testing top_p=0.95, top_k=35, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1033, ROUGE-2: 0.0041, ROUGE-L: 0.0980, METEOR: 0.0342, Emotion: 0.9300, Combined: 0.1801\n",
            "\n",
            "[257/288] Testing top_p=1.0, top_k=0, temp=1.0\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1035, ROUGE-2: 0.0094, ROUGE-L: 0.0958, METEOR: 0.0405, Emotion: 0.9400, Combined: 0.1844\n",
            "\n",
            "[258/288] Testing top_p=1.0, top_k=0, temp=1.1\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1008, ROUGE-2: 0.0106, ROUGE-L: 0.0997, METEOR: 0.0501, Emotion: 0.9500, Combined: 0.1877\n",
            "\n",
            "[259/288] Testing top_p=1.0, top_k=0, temp=1.2\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0928, ROUGE-2: 0.0126, ROUGE-L: 0.0894, METEOR: 0.0497, Emotion: 0.8500, Combined: 0.1750\n",
            "\n",
            "[260/288] Testing top_p=1.0, top_k=0, temp=1.3\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1049, ROUGE-2: 0.0128, ROUGE-L: 0.0946, METEOR: 0.0589, Emotion: 0.8400, Combined: 0.1777\n",
            "\n",
            "[261/288] Testing top_p=1.0, top_k=5, temp=1.0\n",
            "  BLEU: 0.0116, ROUGE-1: 0.1201, ROUGE-2: 0.0180, ROUGE-L: 0.1170, METEOR: 0.0479, Emotion: 0.9800, Combined: 0.1977\n",
            "\n",
            "[262/288] Testing top_p=1.0, top_k=5, temp=1.1\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1193, ROUGE-2: 0.0103, ROUGE-L: 0.1101, METEOR: 0.0477, Emotion: 0.9700, Combined: 0.1941\n",
            "\n",
            "[263/288] Testing top_p=1.0, top_k=5, temp=1.2\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1321, ROUGE-2: 0.0157, ROUGE-L: 0.1219, METEOR: 0.0437, Emotion: 0.9600, Combined: 0.1962\n",
            "\n",
            "[264/288] Testing top_p=1.0, top_k=5, temp=1.3\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1333, ROUGE-2: 0.0123, ROUGE-L: 0.1245, METEOR: 0.0552, Emotion: 0.9700, Combined: 0.2002\n",
            "\n",
            "[265/288] Testing top_p=1.0, top_k=10, temp=1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL Evaluation"
      ],
      "metadata": {
        "id": "09pA5qM6Y_fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Format Detection ======================\n",
        "def detect_model_format(model, tokenizer, device='cuda', test_inputs=None):\n",
        "    \"\"\"\n",
        "    Test model output format (should be consistent since both SFT and RL use same format)\n",
        "\n",
        "    Args:\n",
        "        model: The model to test\n",
        "        tokenizer: Model tokenizer\n",
        "        device: Device to run test on\n",
        "        test_inputs: List of test input strings, uses defaults if None\n",
        "\n",
        "    Returns:\n",
        "        str: 'standard' if using <therapist_emotion> format, 'unknown' otherwise\n",
        "    \"\"\"\n",
        "    if test_inputs is None:\n",
        "        test_inputs = [\n",
        "            \"<problem>anxiety <user>I'm worried about work <user_emotion>anxiety <therapist>\",\n",
        "            \"<problem>depression <user>I feel very sad <user_emotion>sadness <therapist>\",\n",
        "            \"<problem>relationship <user>My partner doesn't understand me <user_emotion>anger <therapist>\"\n",
        "        ]\n",
        "\n",
        "    emotion_tag_count = 0\n",
        "    total_tests = len(test_inputs)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_input in test_inputs:\n",
        "            # Tokenize and generate\n",
        "            input_ids = tokenizer.encode(test_input, return_tensors='pt').to(device)\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decode response\n",
        "            new_tokens = outputs[0][len(input_ids[0]):]\n",
        "            response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "            # Check for emotion tag\n",
        "            if '<therapist_emotion>' in response:\n",
        "                emotion_tag_count += 1\n",
        "\n",
        "    # Determine format\n",
        "    if emotion_tag_count >= total_tests * 0.5:\n",
        "        return 'standard'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"\n",
        "    Extract therapist text and emotion from model output.\n",
        "    Both SFT and RL models use format: 'text <therapist_emotion> emotion<eos>'\n",
        "\n",
        "    Returns:\n",
        "        therapist_text (str): Text before <therapist_emotion>\n",
        "        emotion (str): Emotion word after <therapist_emotion>\n",
        "        has_emotion_tag (bool): Whether emotion tag was found\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        # No emotion tag found, return entire response as text\n",
        "        return response, \"\", False\n",
        "\n",
        "def extract_emotion_only(response):\n",
        "    \"\"\"Extract only emotion from response (for compatibility with existing code)\"\"\"\n",
        "    _, emotion, has_emotion = extract_model_output(response)\n",
        "    return emotion if has_emotion else None\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDataset:\n",
        "    \"\"\"Dataset class for evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt\n",
        "                    input_parts = []\n",
        "                    if problem_type:\n",
        "                        input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                    input_parts.append(f\"<user>{combined_user_text}\")\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.append(f\"<user_emotion>{last_user_emotion}\")\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \" \".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_model(model, tokenizer, evaluation_dataset, device='cuda', max_new_tokens=128,\n",
        "                  top_p=0.7, top_k=10, temperature=1.2, do_sample=True):\n",
        "    \"\"\"\n",
        "    Evaluate model on therapy dataset\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: TherapyEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        do_sample: Whether to use sampling\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Detect model output format\n",
        "    detected_format = detect_model_format(model, tokenizer, device)\n",
        "    print(f\"Output format check: {detected_format.upper()}\")\n",
        "\n",
        "    print(f\"Evaluating model on {len(evaluation_data)} samples...\")\n",
        "\n",
        "    progress_bar = tqdm(evaluation_data, desc=\"Evaluating\",\n",
        "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "        if has_emotion:\n",
        "            emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "        else:\n",
        "            emotion_confusion[reference_emotion.lower()]['no_prediction'] += 1\n",
        "\n",
        "        # Store sample outputs for inspection\n",
        "        if i < 10:\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'full_response': response,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        if (i + 1) % 20 == 0 or i < 5:\n",
        "            sample_info = f\"Sample {i+1}: BLEU={bleu:.3f}, Emotion={'✓' if emotion_correct else '✗'}\"\n",
        "            progress_bar.set_description(f\"Evaluating - {sample_info}\")\n",
        "\n",
        "            if (i + 1) % 50 == 0 or i < 3:\n",
        "                print(f\"\\n\" + \"=\"*80)\n",
        "                print(f\"LIVE SAMPLE {i+1}/{len(evaluation_data)}\")\n",
        "                print(\"=\"*80)\n",
        "                print(f\"Input: {input_text[:120]}...\")\n",
        "                print(f\"Reference: {reference_text[:100]}...\")\n",
        "                print(f\"Generated: {predicted_text[:100]}...\")\n",
        "                print(f\"Full Response: {response[:150]}...\")\n",
        "                print(f\"Ref Emotion: {reference_emotion} | Pred Emotion: {predicted_emotion} | Match: {'✓' if emotion_correct else '✗'}\")\n",
        "                print(f\"BLEU: {bleu:.4f} | ROUGE-1: {rouge['rouge1']:.4f} | METEOR: {meteor:.4f}\")\n",
        "                print(\"=\"*80)\n",
        "        else:\n",
        "            if i > 0:\n",
        "                avg_bleu = np.mean(results['bleu_scores'])\n",
        "                avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "                progress_bar.set_description(f\"Evaluating - Avg BLEU: {avg_bleu:.3f}, Emotion Acc: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['detected_format'] = detected_format\n",
        "\n",
        "    # Print final progress summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUATION COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed {len(evaluation_data)} samples\")\n",
        "    print(f\"Average BLEU: {results['summary']['avg_bleu']:.4f}\")\n",
        "    print(f\"Average ROUGE-1: {results['summary']['avg_rouge1']:.4f}\")\n",
        "    print(f\"Emotion Accuracy: {results['summary']['emotion_accuracy']:.4f}\")\n",
        "    print(f\"Emotion Tag Coverage: {results['summary']['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"THERAPY MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Model Type: {results.get('model_type', 'Unknown').upper()}\")\n",
        "    print(f\"Output Format: {results.get('detected_format', 'Unknown').upper()}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction:\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Tag Coverage: {summary['emotion_tag_coverage']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Input: {sample['input'][:100]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:80]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:80]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']}\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"Checkpoint info: Epoch {checkpoint['epoch']}, Loss {checkpoint.get('valid_loss', 'N/A')}\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load model from directory\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Automatically detect and load model (SFT checkpoint or RL directory)\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        device: Device to load model on\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, model_type)\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        # It's a file - assume SFT checkpoint\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "\n",
        "    elif os.path.isdir(model_path):\n",
        "        # It's a directory - assume RL model\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Main Evaluation Function ======================\n",
        "def run_evaluation(model_path, tokenizer_path, test_data_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Run complete evaluation pipeline\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        test_data_path: Path to test JSON data\n",
        "        device: Device to run evaluation on\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    print(f\"Loading evaluation data from {test_data_path}...\")\n",
        "    eval_dataset = TherapyEvaluationDataset(test_data_path, tokenizer_path)\n",
        "\n",
        "    results = evaluate_model(model, tokenizer, eval_dataset, device=device)\n",
        "    results['model_type'] = model_type\n",
        "\n",
        "    print_evaluation_results(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4\"  # Will auto-detect type\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Run evaluation (works for both SFT and RL)\n",
        "    results = run_evaluation(MODEL_PATH, TOKENIZER_PATH, TEST_DATA_PATH, DEVICE)\n",
        "\n",
        "    # Optionally save results\n",
        "    import pickle\n",
        "    with open('/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/temp1dot3RL_evaluation_results.pkl', 'wb') as f:\n",
        "      pickle.dump(results, f)"
      ],
      "metadata": {
        "id": "vANZgUelY-I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT No Emotion Hyperarameter Tuning"
      ],
      "metadata": {
        "id": "4W-vjUmvZpvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set seed at import\n",
        "set_seed(42)\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output_no_emotion(response):\n",
        "    \"\"\"Extract therapist text from model output - NO EMOTION VERSION\"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Clean up any accidentally generated emotion tags (shouldn't happen)\n",
        "    if '<therapist_emotion>' in response:\n",
        "        response = response.split('<therapist_emotion>')[0].strip()\n",
        "        print(f\"WARNING: Model generated emotion tag (training issue)\")\n",
        "\n",
        "    # Remove any standalone emotion words at the end\n",
        "    emotion_words = ['anger', 'sadness', 'depression', 'disgust', 'fear', 'joy', 'neutral']\n",
        "    for emotion in emotion_words:\n",
        "        pattern = r'\\s+' + emotion + r'\\s*$'\n",
        "        response = re.sub(pattern, '', response, flags=re.IGNORECASE)\n",
        "\n",
        "    return response\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDatasetNoEmotion:\n",
        "    \"\"\"Dataset class for evaluation data processing - NO EMOTION VERSION\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None, subset_size=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self.subset_size = subset_size\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation - matches no-emotion training format\"\"\"\n",
        "        print(f\"Processing evaluation data (subset_size: {self.subset_size})...\")\n",
        "\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input prompt - MATCHES TRAINING FORMAT EXACTLY\n",
        "                    input_parts = [\"<bos>\"]\n",
        "\n",
        "                    if problem_type:\n",
        "                        input_parts.extend([\"<problem>\", problem_type])\n",
        "\n",
        "                    input_parts.extend([\"<user>\", combined_user_text])\n",
        "\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.extend([\"<user_emotion>\", last_user_emotion])\n",
        "\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "                    input_text = \"\".join([self.tokenizer.bos_token] +\n",
        "                                       ([f\"<problem>{problem_type}\"] if problem_type else []) +\n",
        "                                       [f\"<user>{combined_user_text}\"] +\n",
        "                                       ([f\"<user_emotion>{last_user_emotion}\"] if last_user_emotion else []) +\n",
        "                                       [\"<therapist>\"])\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "                    # Early stopping if subset size is reached\n",
        "                    if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                        break\n",
        "\n",
        "            # Early stopping if subset size is reached\n",
        "            if self.subset_size and len(self.evaluation_data) >= self.subset_size:\n",
        "                break\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetricsNoEmotion:\n",
        "    \"\"\"Class to compute evaluation metrics - NO EMOTION VERSION\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Fast Evaluation Function ======================\n",
        "def evaluate_hyperparameters_no_emotion(model, tokenizer, evaluation_dataset, device='cuda',\n",
        "                            max_new_tokens=64, top_p=0.8, top_k=0, temperature=1.0, do_sample=True,\n",
        "                            verbose=False):\n",
        "    \"\"\"\n",
        "    Fast evaluation for hyperparameter tuning - NO EMOTION VERSION\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: TherapyEvaluationDatasetNoEmotion instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        top_k: Top-k sampling parameter\n",
        "        temperature: Temperature for sampling\n",
        "        do_sample: Whether to use sampling\n",
        "        verbose: Whether to print detailed progress\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetricsNoEmotion()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': []\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Progress bar only if verbose\n",
        "    if verbose:\n",
        "        progress_bar = tqdm(evaluation_data, desc=f\"Eval p={top_p:.2f} k={top_k} T={temperature:.1f}\")\n",
        "        data_iter = progress_bar\n",
        "    else:\n",
        "        data_iter = evaluation_data\n",
        "\n",
        "    for i, sample in enumerate(data_iter):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text = extract_model_output_no_emotion(response)\n",
        "\n",
        "        # Compute metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "\n",
        "    if verbose and 'progress_bar' in locals():\n",
        "        progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    summary = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'total_samples': len(evaluation_data),\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'temperature': temperature\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_no_emotion_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load no-emotion SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading no-emotion checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# ====================== Hyperparameter Tuning Functions ======================\n",
        "def compute_combined_score_no_emotion(results, weights=None):\n",
        "    \"\"\"\n",
        "    Compute a combined score from multiple metrics - NO EMOTION VERSION\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary containing metric results\n",
        "        weights: Dictionary of weights for each metric\n",
        "\n",
        "    Returns:\n",
        "        Combined score (higher is better)\n",
        "    \"\"\"\n",
        "    if weights is None:\n",
        "        weights = {\n",
        "            'avg_bleu': 0.25,\n",
        "            'avg_rouge1': 0.20,\n",
        "            'avg_rouge2': 0.20,\n",
        "            'avg_rougeL': 0.20,\n",
        "            'avg_meteor': 0.15\n",
        "        }\n",
        "\n",
        "    score = 0.0\n",
        "    for metric, weight in weights.items():\n",
        "        if metric in results:\n",
        "            score += results[metric] * weight\n",
        "\n",
        "    return score\n",
        "\n",
        "def hyperparameter_search_no_emotion(model_path, tokenizer_path, test_data_path, device='cuda',\n",
        "                         top_p_values=None, top_k_values=None, temperature_values=None, subset_size=100,\n",
        "                         max_new_tokens=128, output_dir=None, weights=None):\n",
        "    \"\"\"\n",
        "    Perform grid search over top_p, top_k, and temperature values - NO EMOTION VERSION\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model checkpoint\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        test_data_path: Path to test JSON data\n",
        "        device: Device to run evaluation on\n",
        "        top_p_values: List of top_p values to test\n",
        "        top_k_values: List of top_k values to test\n",
        "        temperature_values: List of temperature values to test\n",
        "        subset_size: Number of samples to use for evaluation\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        output_dir: Directory to save results\n",
        "        weights: Weights for combining metrics\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all results and best parameters\n",
        "    \"\"\"\n",
        "\n",
        "    if top_p_values is None:\n",
        "        top_p_values = [0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "    if top_k_values is None:\n",
        "        top_k_values = [0, 5, 10, 20, 40, 50]\n",
        "\n",
        "    if temperature_values is None:\n",
        "        temperature_values = [0.7, 0.8, 1.0, 1.1, 1.2]\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    print(f\"Loading no-emotion model from {model_path}...\")\n",
        "    model, tokenizer = load_no_emotion_model(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded no-emotion SFT model successfully\")\n",
        "\n",
        "    # Load evaluation dataset (subset)\n",
        "    print(f\"Loading evaluation data subset (size: {subset_size})...\")\n",
        "    eval_dataset = TherapyEvaluationDatasetNoEmotion(test_data_path, tokenizer_path, subset_size=subset_size)\n",
        "\n",
        "    # Initialize results storage\n",
        "    all_results = []\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # Total combinations\n",
        "    total_combinations = len(top_p_values) * len(top_k_values) * len(temperature_values)\n",
        "    print(f\"Testing {total_combinations} hyperparameter combinations...\")\n",
        "    print(f\"top_p values: {top_p_values}\")\n",
        "    print(f\"top_k values: {top_k_values}\")\n",
        "    print(f\"temperature values: {temperature_values}\")\n",
        "    print(f\"Subset size: {subset_size} samples\")\n",
        "\n",
        "    # Grid search\n",
        "    combination_count = 0\n",
        "\n",
        "    for top_p in top_p_values:\n",
        "        for top_k in top_k_values:\n",
        "            for temperature in temperature_values:\n",
        "                combination_count += 1\n",
        "\n",
        "                print(f\"\\n[{combination_count}/{total_combinations}] Testing top_p={top_p}, top_k={top_k}, temp={temperature}\")\n",
        "\n",
        "                # Evaluate with current hyperparameters\n",
        "                results = evaluate_hyperparameters_no_emotion(\n",
        "                    model, tokenizer, eval_dataset, device,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    top_p=top_p, top_k=top_k, temperature=temperature,\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                # Compute combined score\n",
        "                combined_score = compute_combined_score_no_emotion(results, weights)\n",
        "                results['combined_score'] = combined_score\n",
        "\n",
        "                # Store results\n",
        "                all_results.append(results)\n",
        "\n",
        "                # Check if this is the best so far\n",
        "                if combined_score > best_score:\n",
        "                    best_score = combined_score\n",
        "                    best_params = {'top_p': top_p, 'top_k': top_k, 'temperature': temperature}\n",
        "                    print(f\"  *** NEW BEST *** Score: {combined_score:.4f}\")\n",
        "\n",
        "                # Print current results\n",
        "                print(f\"  BLEU: {results['avg_bleu']:.4f}, \"\n",
        "                      f\"ROUGE-1: {results['avg_rouge1']:.4f}, \"\n",
        "                      f\"ROUGE-2: {results['avg_rouge2']:.4f}, \"\n",
        "                      f\"ROUGE-L: {results['avg_rougeL']:.4f}, \"\n",
        "                      f\"METEOR: {results['avg_meteor']:.4f}, \"\n",
        "                      f\"Combined: {combined_score:.4f}\")\n",
        "\n",
        "    # Compile final results\n",
        "    final_results = {\n",
        "        'best_params': best_params,\n",
        "        'best_score': best_score,\n",
        "        'all_results': all_results,\n",
        "        'model_path': model_path,\n",
        "        'model_type': 'no_emotion_sft',\n",
        "        'subset_size': subset_size,\n",
        "        'search_space': {\n",
        "            'top_p_values': top_p_values,\n",
        "            'top_k_values': top_k_values,\n",
        "            'temperature_values': temperature_values\n",
        "        },\n",
        "        'weights': weights or {\n",
        "            'avg_bleu': 0.25,\n",
        "            'avg_rouge1': 0.20,\n",
        "            'avg_rouge2': 0.20,\n",
        "            'avg_rougeL': 0.20,\n",
        "            'avg_meteor': 0.15\n",
        "        },\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"NO-EMOTION HYPERPARAMETER SEARCH COMPLETED\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Best parameters: top_p={best_params['top_p']}, top_k={best_params['top_k']}, temperature={best_params['temperature']}\")\n",
        "    print(f\"Best combined score: {best_score:.4f}\")\n",
        "\n",
        "    # Find best result details\n",
        "    best_result = max(all_results, key=lambda x: x['combined_score'])\n",
        "    print(f\"\\nBest result details:\")\n",
        "    print(f\"  BLEU Score: {best_result['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1: {best_result['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2: {best_result['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L: {best_result['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR: {best_result['avg_meteor']:.4f}\")\n",
        "    print(f\"  Combined Score: {best_result['combined_score']:.4f}\")\n",
        "\n",
        "    # Save results if output directory specified\n",
        "    if output_dir:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_file = os.path.join(output_dir, f\"no_emotion_hyperparameter_search_{timestamp}.pkl\")\n",
        "\n",
        "        with open(results_file, 'wb') as f:\n",
        "            pickle.dump(final_results, f)\n",
        "\n",
        "        print(f\"\\nResults saved to: {results_file}\")\n",
        "\n",
        "        # Also save a summary CSV\n",
        "        try:\n",
        "            import pandas as pd\n",
        "            df_results = pd.DataFrame(all_results)\n",
        "            csv_file = os.path.join(output_dir, f\"no_emotion_hyperparameter_results_{timestamp}.csv\")\n",
        "            df_results.to_csv(csv_file, index=False)\n",
        "            print(f\"CSV summary saved to: {csv_file}\")\n",
        "        except ImportError:\n",
        "            print(\"pandas not available, skipping CSV export\")\n",
        "\n",
        "    return final_results\n",
        "\n",
        "def analyze_no_emotion_results(results_file):\n",
        "    \"\"\"Analyze no-emotion hyperparameter search results\"\"\"\n",
        "    with open(results_file, 'rb') as f:\n",
        "        results = pickle.load(f)\n",
        "\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(results['all_results'])\n",
        "\n",
        "        print(f\"No-Emotion Hyperparameter Search Analysis\")\n",
        "        print(f\"=\" * 50)\n",
        "        print(f\"Model: {results['model_path']}\")\n",
        "        print(f\"Search completed: {results['timestamp']}\")\n",
        "        print(f\"Total combinations tested: {len(df)}\")\n",
        "\n",
        "        # Top 5 results\n",
        "        print(f\"\\nTop 5 Results:\")\n",
        "        top_5 = df.nlargest(5, 'combined_score')[['top_p', 'top_k', 'temperature', 'avg_bleu', 'avg_rouge1',\n",
        "                                                  'avg_rouge2', 'avg_rougeL', 'avg_meteor', 'combined_score']]\n",
        "        print(top_5.to_string(index=False))\n",
        "\n",
        "        # Best for each metric\n",
        "        print(f\"\\nBest parameters for each metric:\")\n",
        "        for metric in ['avg_bleu', 'avg_rouge1', 'avg_rouge2', 'avg_rougeL', 'avg_meteor']:\n",
        "            best_row = df.loc[df[metric].idxmax()]\n",
        "            print(f\"  {metric}: top_p={best_row['top_p']}, top_k={best_row['top_k']}, temp={best_row['temperature']} (score: {best_row[metric]:.4f})\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"pandas not available, showing basic analysis\")\n",
        "        print(f\"Best parameters: {results['best_params']}\")\n",
        "        print(f\"Best score: {results['best_score']:.4f}\")\n",
        "        return results['all_results']\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/therapy_checkpoints_4thFIXED_noemotions/best_model.ckpt\"\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/train_processed_no_emotion_v1_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/val.json\"\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/hyperparameter_search\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Hyperparameter search space\n",
        "    TOP_P_VALUES = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.00]\n",
        "    TOP_K_VALUES = [0, 5, 10, 15, 20, 25, 30, 35]\n",
        "    TEMPERATURE_VALUES = [1.0, 1.1, 1.2, 1.3]\n",
        "\n",
        "    SUBSET_SIZE = 100\n",
        "\n",
        "    CUSTOM_WEIGHTS = None\n",
        "\n",
        "    results = hyperparameter_search_no_emotion(\n",
        "        model_path=MODEL_PATH,\n",
        "        tokenizer_path=TOKENIZER_PATH,\n",
        "        test_data_path=TEST_DATA_PATH,\n",
        "        device=DEVICE,\n",
        "        top_p_values=TOP_P_VALUES,\n",
        "        top_k_values=TOP_K_VALUES,\n",
        "        temperature_values=TEMPERATURE_VALUES,\n",
        "        subset_size=SUBSET_SIZE,\n",
        "        max_new_tokens=128,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        weights=CUSTOM_WEIGHTS\n",
        "    )\n",
        "\n",
        "    print(f\"\\nBest hyperparameters found:\")\n",
        "    print(f\"top_p: {results['best_params']['top_p']}\")\n",
        "    print(f\"top_k: {results['best_params']['top_k']}\")\n",
        "    print(f\"temperature: {results['best_params']['temperature']}\")\n",
        "    print(f\"Score: {results['best_score']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c17c02e527314b91911895893d0715ca",
            "1f56b94324a54dcd982da097b3c87b8d",
            "be8b327ebfde4d74b75490a8d79f92b1",
            "2bf27bf1dd9244518972ca8f08b86a78",
            "c109e6a101c34690a6672924f91f68d5",
            "1d4aa9e83f8841bfa4eca71b6836c84d",
            "9a451796cdf34dc6b20c78669b4f3e31",
            "0fec0bdecfeb4f8ab1e2ebbadfb9dba4",
            "1d3ad068c0de41d69169108cc0f13629",
            "2a9a59d538454528a8495516cdad0d43",
            "87837d4e947e494296289405d6b0f963",
            "b37c1198f21a4581b7106ebac92b1582",
            "2bb56f5f1ce548f2b6d9998fcbf193ab",
            "c4ab6a7f6a4441cfaf1855d9c050eddf",
            "f2c0f6fcecfc4050ac05d2f60845eef5",
            "2a0fb5a53efa429fb332e30090bd819c",
            "4150860e8edf4197b9edc3894562b701",
            "d097579224c84f92964dfd31be36229d",
            "3e8a0c6037c544348af7370fe3dde210",
            "352d8ceed7564427a63c2b6f9fdf126f",
            "a0e101f9784a42459b1d4a049bf761e0",
            "dcf8af30f4564d8d8cbff0901f82d2b9",
            "5a68e62158ea4a2d935797fd7c56a11f",
            "30094357ce484fcfa0234b3a0879c16e",
            "dd1e735dd0804349b4230a9d577db457",
            "2c6e1d35d8434907b624d58eac8bda2d",
            "1049dc196fdb43a3bdde0eff49ca624b",
            "82cdcd15df2f43058c884e35f8260929",
            "b1cca684038745a0a02fc82e7ccd937e",
            "01d9b054c75c4e0b98b0b8feb0e7346e",
            "dc587c1973024690962d9bb6d5020724",
            "7b1a308fc8ac4601b190e425b28a3741",
            "0e5c336ffb68460dbcdec4c0a22fb0c0"
          ]
        },
        "id": "Sr9dTRzK6sQg",
        "outputId": "3844f154-298d-4e08-e8ef-bf6a4b430b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading no-emotion model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/therapy_checkpoints_4thFIXED_noemotions/best_model.ckpt...\n",
            "Loading no-emotion checkpoint: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/therapy_checkpoints_4thFIXED_noemotions/best_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c17c02e527314b91911895893d0715ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b37c1198f21a4581b7106ebac92b1582"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a68e62158ea4a2d935797fd7c56a11f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded no-emotion SFT model successfully\n",
            "Loading evaluation data subset (size: 100)...\n",
            "Processing evaluation data (subset_size: 100)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing evaluation data:  25%|██▌       | 26/102 [00:00<00:00, 4784.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100 evaluation samples\n",
            "Testing 288 hyperparameter combinations...\n",
            "top_p values: [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]\n",
            "top_k values: [0, 5, 10, 15, 20, 25, 30, 35]\n",
            "temperature values: [1.0, 1.1, 1.2, 1.3]\n",
            "Subset size: 100 samples\n",
            "\n",
            "[1/288] Testing top_p=0.6, top_k=0, temp=1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  *** NEW BEST *** Score: 0.0808\n",
            "  BLEU: 0.0196, ROUGE-1: 0.1454, ROUGE-2: 0.0424, ROUGE-L: 0.1413, METEOR: 0.0672, Combined: 0.0808\n",
            "\n",
            "[2/288] Testing top_p=0.6, top_k=0, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1131, ROUGE-2: 0.0089, ROUGE-L: 0.1061, METEOR: 0.0428, Combined: 0.0542\n",
            "\n",
            "[3/288] Testing top_p=0.6, top_k=0, temp=1.2\n",
            "  BLEU: 0.0092, ROUGE-1: 0.0839, ROUGE-2: 0.0057, ROUGE-L: 0.0775, METEOR: 0.0366, Combined: 0.0412\n",
            "\n",
            "[4/288] Testing top_p=0.6, top_k=0, temp=1.3\n",
            "  BLEU: 0.0038, ROUGE-1: 0.0594, ROUGE-2: 0.0049, ROUGE-L: 0.0575, METEOR: 0.0276, Combined: 0.0294\n",
            "\n",
            "[5/288] Testing top_p=0.6, top_k=5, temp=1.0\n",
            "  BLEU: 0.0162, ROUGE-1: 0.1313, ROUGE-2: 0.0259, ROUGE-L: 0.1230, METEOR: 0.0496, Combined: 0.0675\n",
            "\n",
            "[6/288] Testing top_p=0.6, top_k=5, temp=1.1\n",
            "  BLEU: 0.0158, ROUGE-1: 0.1405, ROUGE-2: 0.0401, ROUGE-L: 0.1339, METEOR: 0.0594, Combined: 0.0758\n",
            "\n",
            "[7/288] Testing top_p=0.6, top_k=5, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1040, ROUGE-2: 0.0098, ROUGE-L: 0.0993, METEOR: 0.0352, Combined: 0.0498\n",
            "\n",
            "[8/288] Testing top_p=0.6, top_k=5, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1204, ROUGE-2: 0.0134, ROUGE-L: 0.1079, METEOR: 0.0389, Combined: 0.0564\n",
            "\n",
            "[9/288] Testing top_p=0.6, top_k=10, temp=1.0\n",
            "  BLEU: 0.0084, ROUGE-1: 0.0943, ROUGE-2: 0.0072, ROUGE-L: 0.0901, METEOR: 0.0296, Combined: 0.0449\n",
            "\n",
            "[10/288] Testing top_p=0.6, top_k=10, temp=1.1\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1230, ROUGE-2: 0.0270, ROUGE-L: 0.1178, METEOR: 0.0441, Combined: 0.0633\n",
            "\n",
            "[11/288] Testing top_p=0.6, top_k=10, temp=1.2\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1138, ROUGE-2: 0.0226, ROUGE-L: 0.1091, METEOR: 0.0580, Combined: 0.0606\n",
            "\n",
            "[12/288] Testing top_p=0.6, top_k=10, temp=1.3\n",
            "  BLEU: 0.0071, ROUGE-1: 0.1009, ROUGE-2: 0.0139, ROUGE-L: 0.0909, METEOR: 0.0391, Combined: 0.0488\n",
            "\n",
            "[13/288] Testing top_p=0.6, top_k=15, temp=1.0\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1073, ROUGE-2: 0.0084, ROUGE-L: 0.1032, METEOR: 0.0403, Combined: 0.0521\n",
            "\n",
            "[14/288] Testing top_p=0.6, top_k=15, temp=1.1\n",
            "  BLEU: 0.0081, ROUGE-1: 0.1116, ROUGE-2: 0.0131, ROUGE-L: 0.1061, METEOR: 0.0367, Combined: 0.0537\n",
            "\n",
            "[15/288] Testing top_p=0.6, top_k=15, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0881, ROUGE-2: 0.0070, ROUGE-L: 0.0852, METEOR: 0.0371, Combined: 0.0435\n",
            "\n",
            "[16/288] Testing top_p=0.6, top_k=15, temp=1.3\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1013, ROUGE-2: 0.0155, ROUGE-L: 0.0952, METEOR: 0.0390, Combined: 0.0506\n",
            "\n",
            "[17/288] Testing top_p=0.6, top_k=20, temp=1.0\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1335, ROUGE-2: 0.0127, ROUGE-L: 0.1229, METEOR: 0.0482, Combined: 0.0640\n",
            "\n",
            "[18/288] Testing top_p=0.6, top_k=20, temp=1.1\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1089, ROUGE-2: 0.0114, ROUGE-L: 0.1024, METEOR: 0.0385, Combined: 0.0522\n",
            "\n",
            "[19/288] Testing top_p=0.6, top_k=20, temp=1.2\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0915, ROUGE-2: 0.0086, ROUGE-L: 0.0882, METEOR: 0.0373, Combined: 0.0447\n",
            "\n",
            "[20/288] Testing top_p=0.6, top_k=20, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1060, ROUGE-2: 0.0044, ROUGE-L: 0.0981, METEOR: 0.0356, Combined: 0.0493\n",
            "\n",
            "[21/288] Testing top_p=0.6, top_k=25, temp=1.0\n",
            "  BLEU: 0.0090, ROUGE-1: 0.1116, ROUGE-2: 0.0162, ROUGE-L: 0.1098, METEOR: 0.0355, Combined: 0.0551\n",
            "\n",
            "[22/288] Testing top_p=0.6, top_k=25, temp=1.1\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1078, ROUGE-2: 0.0147, ROUGE-L: 0.1000, METEOR: 0.0434, Combined: 0.0539\n",
            "\n",
            "[23/288] Testing top_p=0.6, top_k=25, temp=1.2\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1307, ROUGE-2: 0.0257, ROUGE-L: 0.1222, METEOR: 0.0588, Combined: 0.0676\n",
            "\n",
            "[24/288] Testing top_p=0.6, top_k=25, temp=1.3\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0937, ROUGE-2: 0.0120, ROUGE-L: 0.0910, METEOR: 0.0424, Combined: 0.0476\n",
            "\n",
            "[25/288] Testing top_p=0.6, top_k=30, temp=1.0\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1140, ROUGE-2: 0.0183, ROUGE-L: 0.1102, METEOR: 0.0480, Combined: 0.0586\n",
            "\n",
            "[26/288] Testing top_p=0.6, top_k=30, temp=1.1\n",
            "  BLEU: 0.0131, ROUGE-1: 0.1483, ROUGE-2: 0.0200, ROUGE-L: 0.1366, METEOR: 0.0581, Combined: 0.0730\n",
            "\n",
            "[27/288] Testing top_p=0.6, top_k=30, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1069, ROUGE-2: 0.0124, ROUGE-L: 0.1032, METEOR: 0.0386, Combined: 0.0527\n",
            "\n",
            "[28/288] Testing top_p=0.6, top_k=30, temp=1.3\n",
            "  BLEU: 0.0072, ROUGE-1: 0.0807, ROUGE-2: 0.0162, ROUGE-L: 0.0780, METEOR: 0.0425, Combined: 0.0431\n",
            "\n",
            "[29/288] Testing top_p=0.6, top_k=35, temp=1.0\n",
            "  BLEU: 0.0090, ROUGE-1: 0.1269, ROUGE-2: 0.0242, ROUGE-L: 0.1226, METEOR: 0.0446, Combined: 0.0637\n",
            "\n",
            "[30/288] Testing top_p=0.6, top_k=35, temp=1.1\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1187, ROUGE-2: 0.0234, ROUGE-L: 0.1099, METEOR: 0.0445, Combined: 0.0599\n",
            "\n",
            "[31/288] Testing top_p=0.6, top_k=35, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.0995, ROUGE-2: 0.0099, ROUGE-L: 0.0932, METEOR: 0.0410, Combined: 0.0491\n",
            "\n",
            "[32/288] Testing top_p=0.6, top_k=35, temp=1.3\n",
            "  BLEU: 0.0135, ROUGE-1: 0.1248, ROUGE-2: 0.0154, ROUGE-L: 0.1164, METEOR: 0.0505, Combined: 0.0623\n",
            "\n",
            "[33/288] Testing top_p=0.65, top_k=0, temp=1.0\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1260, ROUGE-2: 0.0124, ROUGE-L: 0.1187, METEOR: 0.0424, Combined: 0.0601\n",
            "\n",
            "[34/288] Testing top_p=0.65, top_k=0, temp=1.1\n",
            "  BLEU: 0.0077, ROUGE-1: 0.1035, ROUGE-2: 0.0203, ROUGE-L: 0.0941, METEOR: 0.0502, Combined: 0.0530\n",
            "\n",
            "[35/288] Testing top_p=0.65, top_k=0, temp=1.2\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1022, ROUGE-2: 0.0128, ROUGE-L: 0.0954, METEOR: 0.0408, Combined: 0.0504\n",
            "\n",
            "[36/288] Testing top_p=0.65, top_k=0, temp=1.3\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0944, ROUGE-2: 0.0102, ROUGE-L: 0.0845, METEOR: 0.0382, Combined: 0.0455\n",
            "\n",
            "[37/288] Testing top_p=0.65, top_k=5, temp=1.0\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1325, ROUGE-2: 0.0160, ROUGE-L: 0.1221, METEOR: 0.0570, Combined: 0.0657\n",
            "\n",
            "[38/288] Testing top_p=0.65, top_k=5, temp=1.1\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1203, ROUGE-2: 0.0109, ROUGE-L: 0.1055, METEOR: 0.0489, Combined: 0.0571\n",
            "\n",
            "[39/288] Testing top_p=0.65, top_k=5, temp=1.2\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1460, ROUGE-2: 0.0162, ROUGE-L: 0.1378, METEOR: 0.0450, Combined: 0.0693\n",
            "\n",
            "[40/288] Testing top_p=0.65, top_k=5, temp=1.3\n",
            "  BLEU: 0.0148, ROUGE-1: 0.1199, ROUGE-2: 0.0188, ROUGE-L: 0.1134, METEOR: 0.0508, Combined: 0.0617\n",
            "\n",
            "[41/288] Testing top_p=0.65, top_k=10, temp=1.0\n",
            "  BLEU: 0.0119, ROUGE-1: 0.1230, ROUGE-2: 0.0207, ROUGE-L: 0.1180, METEOR: 0.0451, Combined: 0.0621\n",
            "\n",
            "[42/288] Testing top_p=0.65, top_k=10, temp=1.1\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1092, ROUGE-2: 0.0162, ROUGE-L: 0.1060, METEOR: 0.0391, Combined: 0.0544\n",
            "\n",
            "[43/288] Testing top_p=0.65, top_k=10, temp=1.2\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1178, ROUGE-2: 0.0168, ROUGE-L: 0.1021, METEOR: 0.0433, Combined: 0.0565\n",
            "\n",
            "[44/288] Testing top_p=0.65, top_k=10, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1012, ROUGE-2: 0.0096, ROUGE-L: 0.0921, METEOR: 0.0360, Combined: 0.0478\n",
            "\n",
            "[45/288] Testing top_p=0.65, top_k=15, temp=1.0\n",
            "  BLEU: 0.0079, ROUGE-1: 0.0949, ROUGE-2: 0.0088, ROUGE-L: 0.0893, METEOR: 0.0346, Combined: 0.0458\n",
            "\n",
            "[46/288] Testing top_p=0.65, top_k=15, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1136, ROUGE-2: 0.0178, ROUGE-L: 0.1067, METEOR: 0.0545, Combined: 0.0582\n",
            "\n",
            "[47/288] Testing top_p=0.65, top_k=15, temp=1.2\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1173, ROUGE-2: 0.0092, ROUGE-L: 0.1105, METEOR: 0.0445, Combined: 0.0569\n",
            "\n",
            "[48/288] Testing top_p=0.65, top_k=15, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1089, ROUGE-2: 0.0192, ROUGE-L: 0.1089, METEOR: 0.0383, Combined: 0.0554\n",
            "\n",
            "[49/288] Testing top_p=0.65, top_k=20, temp=1.0\n",
            "  BLEU: 0.0103, ROUGE-1: 0.1085, ROUGE-2: 0.0205, ROUGE-L: 0.1057, METEOR: 0.0510, Combined: 0.0571\n",
            "\n",
            "[50/288] Testing top_p=0.65, top_k=20, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1039, ROUGE-2: 0.0092, ROUGE-L: 0.0955, METEOR: 0.0401, Combined: 0.0499\n",
            "\n",
            "[51/288] Testing top_p=0.65, top_k=20, temp=1.2\n",
            "  BLEU: 0.0054, ROUGE-1: 0.0940, ROUGE-2: 0.0120, ROUGE-L: 0.0911, METEOR: 0.0316, Combined: 0.0455\n",
            "\n",
            "[52/288] Testing top_p=0.65, top_k=20, temp=1.3\n",
            "  BLEU: 0.0088, ROUGE-1: 0.0937, ROUGE-2: 0.0110, ROUGE-L: 0.0872, METEOR: 0.0389, Combined: 0.0464\n",
            "\n",
            "[53/288] Testing top_p=0.65, top_k=25, temp=1.0\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1116, ROUGE-2: 0.0218, ROUGE-L: 0.1056, METEOR: 0.0367, Combined: 0.0559\n",
            "\n",
            "[54/288] Testing top_p=0.65, top_k=25, temp=1.1\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1125, ROUGE-2: 0.0219, ROUGE-L: 0.1067, METEOR: 0.0443, Combined: 0.0580\n",
            "\n",
            "[55/288] Testing top_p=0.65, top_k=25, temp=1.2\n",
            "  BLEU: 0.0066, ROUGE-1: 0.0994, ROUGE-2: 0.0113, ROUGE-L: 0.0894, METEOR: 0.0352, Combined: 0.0469\n",
            "\n",
            "[56/288] Testing top_p=0.65, top_k=25, temp=1.3\n",
            "  BLEU: 0.0117, ROUGE-1: 0.1092, ROUGE-2: 0.0058, ROUGE-L: 0.1055, METEOR: 0.0377, Combined: 0.0527\n",
            "\n",
            "[57/288] Testing top_p=0.65, top_k=30, temp=1.0\n",
            "  BLEU: 0.0076, ROUGE-1: 0.0984, ROUGE-2: 0.0092, ROUGE-L: 0.0936, METEOR: 0.0360, Combined: 0.0475\n",
            "\n",
            "[58/288] Testing top_p=0.65, top_k=30, temp=1.1\n",
            "  BLEU: 0.0053, ROUGE-1: 0.0998, ROUGE-2: 0.0074, ROUGE-L: 0.0936, METEOR: 0.0297, Combined: 0.0460\n",
            "\n",
            "[59/288] Testing top_p=0.65, top_k=30, temp=1.2\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0957, ROUGE-2: 0.0081, ROUGE-L: 0.0859, METEOR: 0.0321, Combined: 0.0442\n",
            "\n",
            "[60/288] Testing top_p=0.65, top_k=30, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.1187, ROUGE-2: 0.0108, ROUGE-L: 0.1135, METEOR: 0.0365, Combined: 0.0560\n",
            "\n",
            "[61/288] Testing top_p=0.65, top_k=35, temp=1.0\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1157, ROUGE-2: 0.0202, ROUGE-L: 0.1136, METEOR: 0.0432, Combined: 0.0592\n",
            "\n",
            "[62/288] Testing top_p=0.65, top_k=35, temp=1.1\n",
            "  BLEU: 0.0084, ROUGE-1: 0.1035, ROUGE-2: 0.0108, ROUGE-L: 0.0988, METEOR: 0.0401, Combined: 0.0507\n",
            "\n",
            "[63/288] Testing top_p=0.65, top_k=35, temp=1.2\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1154, ROUGE-2: 0.0108, ROUGE-L: 0.1115, METEOR: 0.0533, Combined: 0.0586\n",
            "\n",
            "[64/288] Testing top_p=0.65, top_k=35, temp=1.3\n",
            "  BLEU: 0.0122, ROUGE-1: 0.1231, ROUGE-2: 0.0122, ROUGE-L: 0.1158, METEOR: 0.0527, Combined: 0.0612\n",
            "\n",
            "[65/288] Testing top_p=0.7, top_k=0, temp=1.0\n",
            "  BLEU: 0.0128, ROUGE-1: 0.0978, ROUGE-2: 0.0201, ROUGE-L: 0.0968, METEOR: 0.0520, Combined: 0.0539\n",
            "\n",
            "[66/288] Testing top_p=0.7, top_k=0, temp=1.1\n",
            "  BLEU: 0.0092, ROUGE-1: 0.0903, ROUGE-2: 0.0058, ROUGE-L: 0.0872, METEOR: 0.0351, Combined: 0.0442\n",
            "\n",
            "[67/288] Testing top_p=0.7, top_k=0, temp=1.2\n",
            "  BLEU: 0.0073, ROUGE-1: 0.0832, ROUGE-2: 0.0085, ROUGE-L: 0.0778, METEOR: 0.0388, Combined: 0.0416\n",
            "\n",
            "[68/288] Testing top_p=0.7, top_k=0, temp=1.3\n",
            "  BLEU: 0.0073, ROUGE-1: 0.0804, ROUGE-2: 0.0050, ROUGE-L: 0.0750, METEOR: 0.0320, Combined: 0.0387\n",
            "\n",
            "[69/288] Testing top_p=0.7, top_k=5, temp=1.0\n",
            "  BLEU: 0.0137, ROUGE-1: 0.1258, ROUGE-2: 0.0157, ROUGE-L: 0.1175, METEOR: 0.0497, Combined: 0.0626\n",
            "\n",
            "[70/288] Testing top_p=0.7, top_k=5, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1233, ROUGE-2: 0.0144, ROUGE-L: 0.1162, METEOR: 0.0400, Combined: 0.0589\n",
            "\n",
            "[71/288] Testing top_p=0.7, top_k=5, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1187, ROUGE-2: 0.0108, ROUGE-L: 0.1141, METEOR: 0.0349, Combined: 0.0561\n",
            "\n",
            "[72/288] Testing top_p=0.7, top_k=5, temp=1.3\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1066, ROUGE-2: 0.0103, ROUGE-L: 0.1008, METEOR: 0.0423, Combined: 0.0523\n",
            "\n",
            "[73/288] Testing top_p=0.7, top_k=10, temp=1.0\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1094, ROUGE-2: 0.0157, ROUGE-L: 0.1033, METEOR: 0.0508, Combined: 0.0559\n",
            "\n",
            "[74/288] Testing top_p=0.7, top_k=10, temp=1.1\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1207, ROUGE-2: 0.0173, ROUGE-L: 0.1176, METEOR: 0.0391, Combined: 0.0597\n",
            "\n",
            "[75/288] Testing top_p=0.7, top_k=10, temp=1.2\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1238, ROUGE-2: 0.0211, ROUGE-L: 0.1151, METEOR: 0.0491, Combined: 0.0616\n",
            "\n",
            "[76/288] Testing top_p=0.7, top_k=10, temp=1.3\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1264, ROUGE-2: 0.0184, ROUGE-L: 0.1178, METEOR: 0.0447, Combined: 0.0619\n",
            "\n",
            "[77/288] Testing top_p=0.7, top_k=15, temp=1.0\n",
            "  BLEU: 0.0129, ROUGE-1: 0.1366, ROUGE-2: 0.0237, ROUGE-L: 0.1261, METEOR: 0.0480, Combined: 0.0677\n",
            "\n",
            "[78/288] Testing top_p=0.7, top_k=15, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1110, ROUGE-2: 0.0124, ROUGE-L: 0.1050, METEOR: 0.0400, Combined: 0.0538\n",
            "\n",
            "[79/288] Testing top_p=0.7, top_k=15, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1062, ROUGE-2: 0.0194, ROUGE-L: 0.0980, METEOR: 0.0465, Combined: 0.0539\n",
            "\n",
            "[80/288] Testing top_p=0.7, top_k=15, temp=1.3\n",
            "  BLEU: 0.0055, ROUGE-1: 0.1073, ROUGE-2: 0.0000, ROUGE-L: 0.0997, METEOR: 0.0343, Combined: 0.0479\n",
            "\n",
            "[81/288] Testing top_p=0.7, top_k=20, temp=1.0\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1250, ROUGE-2: 0.0147, ROUGE-L: 0.1149, METEOR: 0.0453, Combined: 0.0605\n",
            "\n",
            "[82/288] Testing top_p=0.7, top_k=20, temp=1.1\n",
            "  BLEU: 0.0080, ROUGE-1: 0.1136, ROUGE-2: 0.0109, ROUGE-L: 0.1057, METEOR: 0.0375, Combined: 0.0537\n",
            "\n",
            "[83/288] Testing top_p=0.7, top_k=20, temp=1.2\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1286, ROUGE-2: 0.0177, ROUGE-L: 0.1164, METEOR: 0.0555, Combined: 0.0637\n",
            "\n",
            "[84/288] Testing top_p=0.7, top_k=20, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1021, ROUGE-2: 0.0132, ROUGE-L: 0.0963, METEOR: 0.0323, Combined: 0.0495\n",
            "\n",
            "[85/288] Testing top_p=0.7, top_k=25, temp=1.0\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1066, ROUGE-2: 0.0138, ROUGE-L: 0.1000, METEOR: 0.0474, Combined: 0.0536\n",
            "\n",
            "[86/288] Testing top_p=0.7, top_k=25, temp=1.1\n",
            "  BLEU: 0.0080, ROUGE-1: 0.1041, ROUGE-2: 0.0114, ROUGE-L: 0.0954, METEOR: 0.0400, Combined: 0.0502\n",
            "\n",
            "[87/288] Testing top_p=0.7, top_k=25, temp=1.2\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0649, ROUGE-2: 0.0036, ROUGE-L: 0.0613, METEOR: 0.0308, Combined: 0.0320\n",
            "\n",
            "[88/288] Testing top_p=0.7, top_k=25, temp=1.3\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1038, ROUGE-2: 0.0143, ROUGE-L: 0.1010, METEOR: 0.0465, Combined: 0.0533\n",
            "\n",
            "[89/288] Testing top_p=0.7, top_k=30, temp=1.0\n",
            "  BLEU: 0.0113, ROUGE-1: 0.1193, ROUGE-2: 0.0295, ROUGE-L: 0.1161, METEOR: 0.0451, Combined: 0.0626\n",
            "\n",
            "[90/288] Testing top_p=0.7, top_k=30, temp=1.1\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1163, ROUGE-2: 0.0123, ROUGE-L: 0.1092, METEOR: 0.0396, Combined: 0.0558\n",
            "\n",
            "[91/288] Testing top_p=0.7, top_k=30, temp=1.2\n",
            "  BLEU: 0.0103, ROUGE-1: 0.0859, ROUGE-2: 0.0171, ROUGE-L: 0.0816, METEOR: 0.0370, Combined: 0.0450\n",
            "\n",
            "[92/288] Testing top_p=0.7, top_k=30, temp=1.3\n",
            "  BLEU: 0.0090, ROUGE-1: 0.0891, ROUGE-2: 0.0154, ROUGE-L: 0.0862, METEOR: 0.0427, Combined: 0.0468\n",
            "\n",
            "[93/288] Testing top_p=0.7, top_k=35, temp=1.0\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0875, ROUGE-2: 0.0046, ROUGE-L: 0.0853, METEOR: 0.0308, Combined: 0.0416\n",
            "\n",
            "[94/288] Testing top_p=0.7, top_k=35, temp=1.1\n",
            "  BLEU: 0.0072, ROUGE-1: 0.1051, ROUGE-2: 0.0080, ROUGE-L: 0.0925, METEOR: 0.0338, Combined: 0.0480\n",
            "\n",
            "[95/288] Testing top_p=0.7, top_k=35, temp=1.2\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1056, ROUGE-2: 0.0192, ROUGE-L: 0.1000, METEOR: 0.0430, Combined: 0.0537\n",
            "\n",
            "[96/288] Testing top_p=0.7, top_k=35, temp=1.3\n",
            "  BLEU: 0.0058, ROUGE-1: 0.1065, ROUGE-2: 0.0042, ROUGE-L: 0.0976, METEOR: 0.0353, Combined: 0.0484\n",
            "\n",
            "[97/288] Testing top_p=0.75, top_k=0, temp=1.0\n",
            "  BLEU: 0.0094, ROUGE-1: 0.0936, ROUGE-2: 0.0113, ROUGE-L: 0.0904, METEOR: 0.0380, Combined: 0.0471\n",
            "\n",
            "[98/288] Testing top_p=0.75, top_k=0, temp=1.1\n",
            "  BLEU: 0.0054, ROUGE-1: 0.0860, ROUGE-2: 0.0060, ROUGE-L: 0.0823, METEOR: 0.0249, Combined: 0.0399\n",
            "\n",
            "[99/288] Testing top_p=0.75, top_k=0, temp=1.2\n",
            "  BLEU: 0.0047, ROUGE-1: 0.0775, ROUGE-2: 0.0059, ROUGE-L: 0.0734, METEOR: 0.0248, Combined: 0.0363\n",
            "\n",
            "[100/288] Testing top_p=0.75, top_k=0, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.0886, ROUGE-2: 0.0178, ROUGE-L: 0.0842, METEOR: 0.0411, Combined: 0.0465\n",
            "\n",
            "[101/288] Testing top_p=0.75, top_k=5, temp=1.0\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1182, ROUGE-2: 0.0195, ROUGE-L: 0.1159, METEOR: 0.0404, Combined: 0.0591\n",
            "\n",
            "[102/288] Testing top_p=0.75, top_k=5, temp=1.1\n",
            "  BLEU: 0.0118, ROUGE-1: 0.1329, ROUGE-2: 0.0117, ROUGE-L: 0.1229, METEOR: 0.0458, Combined: 0.0633\n",
            "\n",
            "[103/288] Testing top_p=0.75, top_k=5, temp=1.2\n",
            "  BLEU: 0.0156, ROUGE-1: 0.1350, ROUGE-2: 0.0205, ROUGE-L: 0.1294, METEOR: 0.0523, Combined: 0.0687\n",
            "\n",
            "[104/288] Testing top_p=0.75, top_k=5, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1158, ROUGE-2: 0.0130, ROUGE-L: 0.1066, METEOR: 0.0456, Combined: 0.0562\n",
            "\n",
            "[105/288] Testing top_p=0.75, top_k=10, temp=1.0\n",
            "  BLEU: 0.0142, ROUGE-1: 0.1471, ROUGE-2: 0.0289, ROUGE-L: 0.1390, METEOR: 0.0560, Combined: 0.0750\n",
            "\n",
            "[106/288] Testing top_p=0.75, top_k=10, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1082, ROUGE-2: 0.0097, ROUGE-L: 0.1016, METEOR: 0.0520, Combined: 0.0541\n",
            "\n",
            "[107/288] Testing top_p=0.75, top_k=10, temp=1.2\n",
            "  BLEU: 0.0141, ROUGE-1: 0.1195, ROUGE-2: 0.0215, ROUGE-L: 0.1136, METEOR: 0.0554, Combined: 0.0627\n",
            "\n",
            "[108/288] Testing top_p=0.75, top_k=10, temp=1.3\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1033, ROUGE-2: 0.0148, ROUGE-L: 0.0994, METEOR: 0.0504, Combined: 0.0534\n",
            "\n",
            "[109/288] Testing top_p=0.75, top_k=15, temp=1.0\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1325, ROUGE-2: 0.0154, ROUGE-L: 0.1225, METEOR: 0.0512, Combined: 0.0641\n",
            "\n",
            "[110/288] Testing top_p=0.75, top_k=15, temp=1.1\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1058, ROUGE-2: 0.0093, ROUGE-L: 0.0996, METEOR: 0.0490, Combined: 0.0525\n",
            "\n",
            "[111/288] Testing top_p=0.75, top_k=15, temp=1.2\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1041, ROUGE-2: 0.0210, ROUGE-L: 0.0980, METEOR: 0.0459, Combined: 0.0543\n",
            "\n",
            "[112/288] Testing top_p=0.75, top_k=15, temp=1.3\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1109, ROUGE-2: 0.0136, ROUGE-L: 0.1103, METEOR: 0.0533, Combined: 0.0570\n",
            "\n",
            "[113/288] Testing top_p=0.75, top_k=20, temp=1.0\n",
            "  BLEU: 0.0131, ROUGE-1: 0.1313, ROUGE-2: 0.0144, ROUGE-L: 0.1238, METEOR: 0.0474, Combined: 0.0643\n",
            "\n",
            "[114/288] Testing top_p=0.75, top_k=20, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1154, ROUGE-2: 0.0042, ROUGE-L: 0.1134, METEOR: 0.0360, Combined: 0.0541\n",
            "\n",
            "[115/288] Testing top_p=0.75, top_k=20, temp=1.2\n",
            "  BLEU: 0.0064, ROUGE-1: 0.1081, ROUGE-2: 0.0094, ROUGE-L: 0.1062, METEOR: 0.0337, Combined: 0.0514\n",
            "\n",
            "[116/288] Testing top_p=0.75, top_k=20, temp=1.3\n",
            "  BLEU: 0.0086, ROUGE-1: 0.0942, ROUGE-2: 0.0136, ROUGE-L: 0.0918, METEOR: 0.0408, Combined: 0.0482\n",
            "\n",
            "[117/288] Testing top_p=0.75, top_k=25, temp=1.0\n",
            "  BLEU: 0.0120, ROUGE-1: 0.1201, ROUGE-2: 0.0174, ROUGE-L: 0.1106, METEOR: 0.0470, Combined: 0.0597\n",
            "\n",
            "[118/288] Testing top_p=0.75, top_k=25, temp=1.1\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1126, ROUGE-2: 0.0172, ROUGE-L: 0.1071, METEOR: 0.0370, Combined: 0.0551\n",
            "\n",
            "[119/288] Testing top_p=0.75, top_k=25, temp=1.2\n",
            "  BLEU: 0.0060, ROUGE-1: 0.0920, ROUGE-2: 0.0034, ROUGE-L: 0.0886, METEOR: 0.0348, Combined: 0.0435\n",
            "\n",
            "[120/288] Testing top_p=0.75, top_k=25, temp=1.3\n",
            "  BLEU: 0.0064, ROUGE-1: 0.1066, ROUGE-2: 0.0057, ROUGE-L: 0.1025, METEOR: 0.0399, Combined: 0.0506\n",
            "\n",
            "[121/288] Testing top_p=0.75, top_k=30, temp=1.0\n",
            "  BLEU: 0.0141, ROUGE-1: 0.1331, ROUGE-2: 0.0253, ROUGE-L: 0.1240, METEOR: 0.0538, Combined: 0.0681\n",
            "\n",
            "[122/288] Testing top_p=0.75, top_k=30, temp=1.1\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1071, ROUGE-2: 0.0139, ROUGE-L: 0.1038, METEOR: 0.0372, Combined: 0.0526\n",
            "\n",
            "[123/288] Testing top_p=0.75, top_k=30, temp=1.2\n",
            "  BLEU: 0.0072, ROUGE-1: 0.0908, ROUGE-2: 0.0082, ROUGE-L: 0.0874, METEOR: 0.0372, Combined: 0.0446\n",
            "\n",
            "[124/288] Testing top_p=0.75, top_k=30, temp=1.3\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1045, ROUGE-2: 0.0158, ROUGE-L: 0.0977, METEOR: 0.0469, Combined: 0.0532\n",
            "\n",
            "[125/288] Testing top_p=0.75, top_k=35, temp=1.0\n",
            "  BLEU: 0.0147, ROUGE-1: 0.0943, ROUGE-2: 0.0223, ROUGE-L: 0.0874, METEOR: 0.0502, Combined: 0.0520\n",
            "\n",
            "[126/288] Testing top_p=0.75, top_k=35, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.1046, ROUGE-2: 0.0113, ROUGE-L: 0.0980, METEOR: 0.0465, Combined: 0.0521\n",
            "\n",
            "[127/288] Testing top_p=0.75, top_k=35, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0959, ROUGE-2: 0.0155, ROUGE-L: 0.0838, METEOR: 0.0396, Combined: 0.0469\n",
            "\n",
            "[128/288] Testing top_p=0.75, top_k=35, temp=1.3\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1165, ROUGE-2: 0.0018, ROUGE-L: 0.1088, METEOR: 0.0486, Combined: 0.0555\n",
            "\n",
            "[129/288] Testing top_p=0.8, top_k=0, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1000, ROUGE-2: 0.0128, ROUGE-L: 0.0889, METEOR: 0.0406, Combined: 0.0489\n",
            "\n",
            "[130/288] Testing top_p=0.8, top_k=0, temp=1.1\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0910, ROUGE-2: 0.0054, ROUGE-L: 0.0870, METEOR: 0.0372, Combined: 0.0446\n",
            "\n",
            "[131/288] Testing top_p=0.8, top_k=0, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.0729, ROUGE-2: 0.0045, ROUGE-L: 0.0712, METEOR: 0.0362, Combined: 0.0369\n",
            "\n",
            "[132/288] Testing top_p=0.8, top_k=0, temp=1.3\n",
            "  BLEU: 0.0047, ROUGE-1: 0.0777, ROUGE-2: 0.0046, ROUGE-L: 0.0686, METEOR: 0.0339, Combined: 0.0364\n",
            "\n",
            "[133/288] Testing top_p=0.8, top_k=5, temp=1.0\n",
            "  BLEU: 0.0074, ROUGE-1: 0.0963, ROUGE-2: 0.0124, ROUGE-L: 0.0894, METEOR: 0.0402, Combined: 0.0475\n",
            "\n",
            "[134/288] Testing top_p=0.8, top_k=5, temp=1.1\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1402, ROUGE-2: 0.0295, ROUGE-L: 0.1333, METEOR: 0.0466, Combined: 0.0702\n",
            "\n",
            "[135/288] Testing top_p=0.8, top_k=5, temp=1.2\n",
            "  BLEU: 0.0150, ROUGE-1: 0.1378, ROUGE-2: 0.0292, ROUGE-L: 0.1291, METEOR: 0.0598, Combined: 0.0720\n",
            "\n",
            "[136/288] Testing top_p=0.8, top_k=5, temp=1.3\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1032, ROUGE-2: 0.0075, ROUGE-L: 0.1032, METEOR: 0.0416, Combined: 0.0512\n",
            "\n",
            "[137/288] Testing top_p=0.8, top_k=10, temp=1.0\n",
            "  BLEU: 0.0091, ROUGE-1: 0.1140, ROUGE-2: 0.0173, ROUGE-L: 0.1041, METEOR: 0.0457, Combined: 0.0562\n",
            "\n",
            "[138/288] Testing top_p=0.8, top_k=10, temp=1.1\n",
            "  BLEU: 0.0062, ROUGE-1: 0.0846, ROUGE-2: 0.0060, ROUGE-L: 0.0791, METEOR: 0.0266, Combined: 0.0394\n",
            "\n",
            "[139/288] Testing top_p=0.8, top_k=10, temp=1.2\n",
            "  BLEU: 0.0107, ROUGE-1: 0.1078, ROUGE-2: 0.0204, ROUGE-L: 0.1042, METEOR: 0.0437, Combined: 0.0557\n",
            "\n",
            "[140/288] Testing top_p=0.8, top_k=10, temp=1.3\n",
            "  BLEU: 0.0062, ROUGE-1: 0.0969, ROUGE-2: 0.0071, ROUGE-L: 0.0887, METEOR: 0.0310, Combined: 0.0448\n",
            "\n",
            "[141/288] Testing top_p=0.8, top_k=15, temp=1.0\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1045, ROUGE-2: 0.0184, ROUGE-L: 0.1008, METEOR: 0.0477, Combined: 0.0544\n",
            "\n",
            "[142/288] Testing top_p=0.8, top_k=15, temp=1.1\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0936, ROUGE-2: 0.0098, ROUGE-L: 0.0904, METEOR: 0.0361, Combined: 0.0456\n",
            "\n",
            "[143/288] Testing top_p=0.8, top_k=15, temp=1.2\n",
            "  BLEU: 0.0064, ROUGE-1: 0.1057, ROUGE-2: 0.0049, ROUGE-L: 0.1016, METEOR: 0.0361, Combined: 0.0495\n",
            "\n",
            "[144/288] Testing top_p=0.8, top_k=15, temp=1.3\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0903, ROUGE-2: 0.0156, ROUGE-L: 0.0848, METEOR: 0.0523, Combined: 0.0483\n",
            "\n",
            "[145/288] Testing top_p=0.8, top_k=20, temp=1.0\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1129, ROUGE-2: 0.0164, ROUGE-L: 0.1056, METEOR: 0.0474, Combined: 0.0565\n",
            "\n",
            "[146/288] Testing top_p=0.8, top_k=20, temp=1.1\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1124, ROUGE-2: 0.0200, ROUGE-L: 0.1013, METEOR: 0.0522, Combined: 0.0573\n",
            "\n",
            "[147/288] Testing top_p=0.8, top_k=20, temp=1.2\n",
            "  BLEU: 0.0045, ROUGE-1: 0.0969, ROUGE-2: 0.0074, ROUGE-L: 0.0867, METEOR: 0.0262, Combined: 0.0433\n",
            "\n",
            "[148/288] Testing top_p=0.8, top_k=20, temp=1.3\n",
            "  BLEU: 0.0079, ROUGE-1: 0.1037, ROUGE-2: 0.0110, ROUGE-L: 0.0975, METEOR: 0.0368, Combined: 0.0499\n",
            "\n",
            "[149/288] Testing top_p=0.8, top_k=25, temp=1.0\n",
            "  BLEU: 0.0102, ROUGE-1: 0.0988, ROUGE-2: 0.0186, ROUGE-L: 0.0951, METEOR: 0.0395, Combined: 0.0510\n",
            "\n",
            "[150/288] Testing top_p=0.8, top_k=25, temp=1.1\n",
            "  BLEU: 0.0062, ROUGE-1: 0.0783, ROUGE-2: 0.0080, ROUGE-L: 0.0747, METEOR: 0.0227, Combined: 0.0371\n",
            "\n",
            "[151/288] Testing top_p=0.8, top_k=25, temp=1.2\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1230, ROUGE-2: 0.0146, ROUGE-L: 0.1132, METEOR: 0.0570, Combined: 0.0613\n",
            "\n",
            "[152/288] Testing top_p=0.8, top_k=25, temp=1.3\n",
            "  BLEU: 0.0072, ROUGE-1: 0.0809, ROUGE-2: 0.0000, ROUGE-L: 0.0777, METEOR: 0.0251, Combined: 0.0373\n",
            "\n",
            "[153/288] Testing top_p=0.8, top_k=30, temp=1.0\n",
            "  BLEU: 0.0038, ROUGE-1: 0.0757, ROUGE-2: 0.0010, ROUGE-L: 0.0757, METEOR: 0.0291, Combined: 0.0358\n",
            "\n",
            "[154/288] Testing top_p=0.8, top_k=30, temp=1.1\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1264, ROUGE-2: 0.0148, ROUGE-L: 0.1175, METEOR: 0.0485, Combined: 0.0616\n",
            "\n",
            "[155/288] Testing top_p=0.8, top_k=30, temp=1.2\n",
            "  BLEU: 0.0058, ROUGE-1: 0.0885, ROUGE-2: 0.0097, ROUGE-L: 0.0838, METEOR: 0.0320, Combined: 0.0427\n",
            "\n",
            "[156/288] Testing top_p=0.8, top_k=30, temp=1.3\n",
            "  BLEU: 0.0057, ROUGE-1: 0.0970, ROUGE-2: 0.0040, ROUGE-L: 0.0887, METEOR: 0.0364, Combined: 0.0448\n",
            "\n",
            "[157/288] Testing top_p=0.8, top_k=35, temp=1.0\n",
            "  BLEU: 0.0164, ROUGE-1: 0.1329, ROUGE-2: 0.0249, ROUGE-L: 0.1246, METEOR: 0.0544, Combined: 0.0688\n",
            "\n",
            "[158/288] Testing top_p=0.8, top_k=35, temp=1.1\n",
            "  BLEU: 0.0098, ROUGE-1: 0.1081, ROUGE-2: 0.0108, ROUGE-L: 0.1013, METEOR: 0.0467, Combined: 0.0535\n",
            "\n",
            "[159/288] Testing top_p=0.8, top_k=35, temp=1.2\n",
            "  BLEU: 0.0124, ROUGE-1: 0.1067, ROUGE-2: 0.0229, ROUGE-L: 0.1035, METEOR: 0.0498, Combined: 0.0572\n",
            "\n",
            "[160/288] Testing top_p=0.8, top_k=35, temp=1.3\n",
            "  BLEU: 0.0106, ROUGE-1: 0.1167, ROUGE-2: 0.0045, ROUGE-L: 0.1068, METEOR: 0.0424, Combined: 0.0546\n",
            "\n",
            "[161/288] Testing top_p=0.85, top_k=0, temp=1.0\n",
            "  BLEU: 0.0094, ROUGE-1: 0.1218, ROUGE-2: 0.0108, ROUGE-L: 0.1161, METEOR: 0.0432, Combined: 0.0586\n",
            "\n",
            "[162/288] Testing top_p=0.85, top_k=0, temp=1.1\n",
            "  BLEU: 0.0070, ROUGE-1: 0.0803, ROUGE-2: 0.0013, ROUGE-L: 0.0719, METEOR: 0.0285, Combined: 0.0367\n",
            "\n",
            "[163/288] Testing top_p=0.85, top_k=0, temp=1.2\n",
            "  BLEU: 0.0065, ROUGE-1: 0.0690, ROUGE-2: 0.0067, ROUGE-L: 0.0636, METEOR: 0.0344, Combined: 0.0347\n",
            "\n",
            "[164/288] Testing top_p=0.85, top_k=0, temp=1.3\n",
            "  BLEU: 0.0022, ROUGE-1: 0.0491, ROUGE-2: 0.0007, ROUGE-L: 0.0444, METEOR: 0.0208, Combined: 0.0225\n",
            "\n",
            "[165/288] Testing top_p=0.85, top_k=5, temp=1.0\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1143, ROUGE-2: 0.0243, ROUGE-L: 0.1134, METEOR: 0.0421, Combined: 0.0593\n",
            "\n",
            "[166/288] Testing top_p=0.85, top_k=5, temp=1.1\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1363, ROUGE-2: 0.0264, ROUGE-L: 0.1284, METEOR: 0.0468, Combined: 0.0681\n",
            "\n",
            "[167/288] Testing top_p=0.85, top_k=5, temp=1.2\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1106, ROUGE-2: 0.0139, ROUGE-L: 0.1077, METEOR: 0.0412, Combined: 0.0548\n",
            "\n",
            "[168/288] Testing top_p=0.85, top_k=5, temp=1.3\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1095, ROUGE-2: 0.0127, ROUGE-L: 0.1034, METEOR: 0.0503, Combined: 0.0550\n",
            "\n",
            "[169/288] Testing top_p=0.85, top_k=10, temp=1.0\n",
            "  BLEU: 0.0086, ROUGE-1: 0.1075, ROUGE-2: 0.0215, ROUGE-L: 0.1043, METEOR: 0.0423, Combined: 0.0552\n",
            "\n",
            "[170/288] Testing top_p=0.85, top_k=10, temp=1.1\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1051, ROUGE-2: 0.0182, ROUGE-L: 0.1006, METEOR: 0.0417, Combined: 0.0542\n",
            "\n",
            "[171/288] Testing top_p=0.85, top_k=10, temp=1.2\n",
            "  BLEU: 0.0099, ROUGE-1: 0.1156, ROUGE-2: 0.0113, ROUGE-L: 0.1092, METEOR: 0.0439, Combined: 0.0563\n",
            "\n",
            "[172/288] Testing top_p=0.85, top_k=10, temp=1.3\n",
            "  BLEU: 0.0075, ROUGE-1: 0.1114, ROUGE-2: 0.0100, ROUGE-L: 0.1044, METEOR: 0.0298, Combined: 0.0515\n",
            "\n",
            "[173/288] Testing top_p=0.85, top_k=15, temp=1.0\n",
            "  BLEU: 0.0134, ROUGE-1: 0.1019, ROUGE-2: 0.0186, ROUGE-L: 0.0956, METEOR: 0.0574, Combined: 0.0552\n",
            "\n",
            "[174/288] Testing top_p=0.85, top_k=15, temp=1.1\n",
            "  BLEU: 0.0082, ROUGE-1: 0.1053, ROUGE-2: 0.0107, ROUGE-L: 0.0986, METEOR: 0.0373, Combined: 0.0506\n",
            "\n",
            "[175/288] Testing top_p=0.85, top_k=15, temp=1.2\n",
            "  BLEU: 0.0078, ROUGE-1: 0.1020, ROUGE-2: 0.0120, ROUGE-L: 0.0972, METEOR: 0.0442, Combined: 0.0508\n",
            "\n",
            "[176/288] Testing top_p=0.85, top_k=15, temp=1.3\n",
            "  BLEU: 0.0105, ROUGE-1: 0.1106, ROUGE-2: 0.0116, ROUGE-L: 0.1077, METEOR: 0.0441, Combined: 0.0552\n",
            "\n",
            "[177/288] Testing top_p=0.85, top_k=20, temp=1.0\n",
            "  BLEU: 0.0126, ROUGE-1: 0.0941, ROUGE-2: 0.0214, ROUGE-L: 0.0880, METEOR: 0.0472, Combined: 0.0509\n",
            "\n",
            "[178/288] Testing top_p=0.85, top_k=20, temp=1.1\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1127, ROUGE-2: 0.0147, ROUGE-L: 0.1093, METEOR: 0.0469, Combined: 0.0570\n",
            "\n",
            "[179/288] Testing top_p=0.85, top_k=20, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0893, ROUGE-2: 0.0104, ROUGE-L: 0.0830, METEOR: 0.0433, Combined: 0.0449\n",
            "\n",
            "[180/288] Testing top_p=0.85, top_k=20, temp=1.3\n",
            "  BLEU: 0.0080, ROUGE-1: 0.0942, ROUGE-2: 0.0041, ROUGE-L: 0.0914, METEOR: 0.0349, Combined: 0.0452\n",
            "\n",
            "[181/288] Testing top_p=0.85, top_k=25, temp=1.0\n",
            "  BLEU: 0.0133, ROUGE-1: 0.1260, ROUGE-2: 0.0257, ROUGE-L: 0.1203, METEOR: 0.0518, Combined: 0.0655\n",
            "\n",
            "[182/288] Testing top_p=0.85, top_k=25, temp=1.1\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0906, ROUGE-2: 0.0027, ROUGE-L: 0.0860, METEOR: 0.0307, Combined: 0.0424\n",
            "\n",
            "[183/288] Testing top_p=0.85, top_k=25, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.0887, ROUGE-2: 0.0043, ROUGE-L: 0.0847, METEOR: 0.0326, Combined: 0.0422\n",
            "\n",
            "[184/288] Testing top_p=0.85, top_k=25, temp=1.3\n",
            "  BLEU: 0.0063, ROUGE-1: 0.1052, ROUGE-2: 0.0138, ROUGE-L: 0.1013, METEOR: 0.0312, Combined: 0.0503\n",
            "\n",
            "[185/288] Testing top_p=0.85, top_k=30, temp=1.0\n",
            "  BLEU: 0.0063, ROUGE-1: 0.1023, ROUGE-2: 0.0078, ROUGE-L: 0.0958, METEOR: 0.0404, Combined: 0.0488\n",
            "\n",
            "[186/288] Testing top_p=0.85, top_k=30, temp=1.1\n",
            "  BLEU: 0.0076, ROUGE-1: 0.0878, ROUGE-2: 0.0087, ROUGE-L: 0.0847, METEOR: 0.0411, Combined: 0.0443\n",
            "\n",
            "[187/288] Testing top_p=0.85, top_k=30, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.0936, ROUGE-2: 0.0130, ROUGE-L: 0.0909, METEOR: 0.0355, Combined: 0.0466\n",
            "\n",
            "[188/288] Testing top_p=0.85, top_k=30, temp=1.3\n",
            "  BLEU: 0.0074, ROUGE-1: 0.0674, ROUGE-2: 0.0078, ROUGE-L: 0.0640, METEOR: 0.0314, Combined: 0.0344\n",
            "\n",
            "[189/288] Testing top_p=0.85, top_k=35, temp=1.0\n",
            "  BLEU: 0.0097, ROUGE-1: 0.0929, ROUGE-2: 0.0096, ROUGE-L: 0.0866, METEOR: 0.0392, Combined: 0.0461\n",
            "\n",
            "[190/288] Testing top_p=0.85, top_k=35, temp=1.1\n",
            "  BLEU: 0.0070, ROUGE-1: 0.0994, ROUGE-2: 0.0074, ROUGE-L: 0.0931, METEOR: 0.0321, Combined: 0.0465\n",
            "\n",
            "[191/288] Testing top_p=0.85, top_k=35, temp=1.2\n",
            "  BLEU: 0.0127, ROUGE-1: 0.1164, ROUGE-2: 0.0167, ROUGE-L: 0.1109, METEOR: 0.0545, Combined: 0.0602\n",
            "\n",
            "[192/288] Testing top_p=0.85, top_k=35, temp=1.3\n",
            "  BLEU: 0.0066, ROUGE-1: 0.0869, ROUGE-2: 0.0033, ROUGE-L: 0.0843, METEOR: 0.0250, Combined: 0.0403\n",
            "\n",
            "[193/288] Testing top_p=0.9, top_k=0, temp=1.0\n",
            "  BLEU: 0.0053, ROUGE-1: 0.0811, ROUGE-2: 0.0053, ROUGE-L: 0.0743, METEOR: 0.0229, Combined: 0.0369\n",
            "\n",
            "[194/288] Testing top_p=0.9, top_k=0, temp=1.1\n",
            "  BLEU: 0.0088, ROUGE-1: 0.0946, ROUGE-2: 0.0150, ROUGE-L: 0.0888, METEOR: 0.0465, Combined: 0.0489\n",
            "\n",
            "[195/288] Testing top_p=0.9, top_k=0, temp=1.2\n",
            "  BLEU: 0.0040, ROUGE-1: 0.0648, ROUGE-2: 0.0091, ROUGE-L: 0.0639, METEOR: 0.0332, Combined: 0.0335\n",
            "\n",
            "[196/288] Testing top_p=0.9, top_k=0, temp=1.3\n",
            "  BLEU: 0.0042, ROUGE-1: 0.0696, ROUGE-2: 0.0020, ROUGE-L: 0.0611, METEOR: 0.0263, Combined: 0.0315\n",
            "\n",
            "[197/288] Testing top_p=0.9, top_k=5, temp=1.0\n",
            "  BLEU: 0.0089, ROUGE-1: 0.1054, ROUGE-2: 0.0124, ROUGE-L: 0.0993, METEOR: 0.0474, Combined: 0.0528\n",
            "\n",
            "[198/288] Testing top_p=0.9, top_k=5, temp=1.1\n",
            "  BLEU: 0.0126, ROUGE-1: 0.1258, ROUGE-2: 0.0250, ROUGE-L: 0.1185, METEOR: 0.0494, Combined: 0.0644\n",
            "\n",
            "[199/288] Testing top_p=0.9, top_k=5, temp=1.2\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1233, ROUGE-2: 0.0218, ROUGE-L: 0.1118, METEOR: 0.0479, Combined: 0.0613\n",
            "\n",
            "[200/288] Testing top_p=0.9, top_k=5, temp=1.3\n",
            "  BLEU: 0.0096, ROUGE-1: 0.1195, ROUGE-2: 0.0175, ROUGE-L: 0.1113, METEOR: 0.0462, Combined: 0.0590\n",
            "\n",
            "[201/288] Testing top_p=0.9, top_k=10, temp=1.0\n",
            "  BLEU: 0.0112, ROUGE-1: 0.1126, ROUGE-2: 0.0251, ROUGE-L: 0.1072, METEOR: 0.0440, Combined: 0.0584\n",
            "\n",
            "[202/288] Testing top_p=0.9, top_k=10, temp=1.1\n",
            "  BLEU: 0.0083, ROUGE-1: 0.1077, ROUGE-2: 0.0046, ROUGE-L: 0.0958, METEOR: 0.0321, Combined: 0.0485\n",
            "\n",
            "[203/288] Testing top_p=0.9, top_k=10, temp=1.2\n",
            "  BLEU: 0.0081, ROUGE-1: 0.1135, ROUGE-2: 0.0130, ROUGE-L: 0.1105, METEOR: 0.0370, Combined: 0.0550\n",
            "\n",
            "[204/288] Testing top_p=0.9, top_k=10, temp=1.3\n",
            "  BLEU: 0.0081, ROUGE-1: 0.1114, ROUGE-2: 0.0121, ROUGE-L: 0.1069, METEOR: 0.0429, Combined: 0.0546\n",
            "\n",
            "[205/288] Testing top_p=0.9, top_k=15, temp=1.0\n",
            "  BLEU: 0.0145, ROUGE-1: 0.1365, ROUGE-2: 0.0131, ROUGE-L: 0.1273, METEOR: 0.0475, Combined: 0.0661\n",
            "\n",
            "[206/288] Testing top_p=0.9, top_k=15, temp=1.1\n",
            "  BLEU: 0.0085, ROUGE-1: 0.1012, ROUGE-2: 0.0049, ROUGE-L: 0.0948, METEOR: 0.0344, Combined: 0.0475\n",
            "\n",
            "[207/288] Testing top_p=0.9, top_k=15, temp=1.2\n",
            "  BLEU: 0.0069, ROUGE-1: 0.0916, ROUGE-2: 0.0043, ROUGE-L: 0.0845, METEOR: 0.0286, Combined: 0.0421\n",
            "\n",
            "[208/288] Testing top_p=0.9, top_k=15, temp=1.3\n",
            "  BLEU: 0.0087, ROUGE-1: 0.1048, ROUGE-2: 0.0134, ROUGE-L: 0.0960, METEOR: 0.0493, Combined: 0.0524\n",
            "\n",
            "[209/288] Testing top_p=0.9, top_k=20, temp=1.0\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1063, ROUGE-2: 0.0146, ROUGE-L: 0.1007, METEOR: 0.0423, Combined: 0.0524\n",
            "\n",
            "[210/288] Testing top_p=0.9, top_k=20, temp=1.1\n",
            "  BLEU: 0.0087, ROUGE-1: 0.0917, ROUGE-2: 0.0103, ROUGE-L: 0.0896, METEOR: 0.0358, Combined: 0.0459\n",
            "\n",
            "[211/288] Testing top_p=0.9, top_k=20, temp=1.2\n",
            "  BLEU: 0.0065, ROUGE-1: 0.1001, ROUGE-2: 0.0063, ROUGE-L: 0.0913, METEOR: 0.0345, Combined: 0.0463\n",
            "\n",
            "[212/288] Testing top_p=0.9, top_k=20, temp=1.3\n",
            "  BLEU: 0.0113, ROUGE-1: 0.0927, ROUGE-2: 0.0053, ROUGE-L: 0.0840, METEOR: 0.0398, Combined: 0.0452\n",
            "\n",
            "[213/288] Testing top_p=0.9, top_k=25, temp=1.0\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0947, ROUGE-2: 0.0103, ROUGE-L: 0.0902, METEOR: 0.0397, Combined: 0.0473\n",
            "\n",
            "[214/288] Testing top_p=0.9, top_k=25, temp=1.1\n",
            "  BLEU: 0.0071, ROUGE-1: 0.1054, ROUGE-2: 0.0080, ROUGE-L: 0.1003, METEOR: 0.0412, Combined: 0.0507\n",
            "\n",
            "[215/288] Testing top_p=0.9, top_k=25, temp=1.2\n",
            "  BLEU: 0.0085, ROUGE-1: 0.0886, ROUGE-2: 0.0114, ROUGE-L: 0.0854, METEOR: 0.0374, Combined: 0.0448\n",
            "\n",
            "[216/288] Testing top_p=0.9, top_k=25, temp=1.3\n",
            "  BLEU: 0.0085, ROUGE-1: 0.0856, ROUGE-2: 0.0153, ROUGE-L: 0.0817, METEOR: 0.0428, Combined: 0.0451\n",
            "\n",
            "[217/288] Testing top_p=0.9, top_k=30, temp=1.0\n",
            "  BLEU: 0.0088, ROUGE-1: 0.0913, ROUGE-2: 0.0084, ROUGE-L: 0.0854, METEOR: 0.0366, Combined: 0.0447\n",
            "\n",
            "[218/288] Testing top_p=0.9, top_k=30, temp=1.1\n",
            "  BLEU: 0.0087, ROUGE-1: 0.0921, ROUGE-2: 0.0100, ROUGE-L: 0.0825, METEOR: 0.0403, Combined: 0.0451\n",
            "\n",
            "[219/288] Testing top_p=0.9, top_k=30, temp=1.2\n",
            "  BLEU: 0.0072, ROUGE-1: 0.0935, ROUGE-2: 0.0064, ROUGE-L: 0.0866, METEOR: 0.0403, Combined: 0.0451\n",
            "\n",
            "[220/288] Testing top_p=0.9, top_k=30, temp=1.3\n",
            "  BLEU: 0.0052, ROUGE-1: 0.0807, ROUGE-2: 0.0066, ROUGE-L: 0.0730, METEOR: 0.0237, Combined: 0.0369\n",
            "\n",
            "[221/288] Testing top_p=0.9, top_k=35, temp=1.0\n",
            "  BLEU: 0.0069, ROUGE-1: 0.1103, ROUGE-2: 0.0120, ROUGE-L: 0.1048, METEOR: 0.0440, Combined: 0.0537\n",
            "\n",
            "[222/288] Testing top_p=0.9, top_k=35, temp=1.1\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0840, ROUGE-2: 0.0072, ROUGE-L: 0.0794, METEOR: 0.0325, Combined: 0.0409\n",
            "\n",
            "[223/288] Testing top_p=0.9, top_k=35, temp=1.2\n",
            "  BLEU: 0.0086, ROUGE-1: 0.0895, ROUGE-2: 0.0096, ROUGE-L: 0.0826, METEOR: 0.0404, Combined: 0.0445\n",
            "\n",
            "[224/288] Testing top_p=0.9, top_k=35, temp=1.3\n",
            "  BLEU: 0.0121, ROUGE-1: 0.1158, ROUGE-2: 0.0142, ROUGE-L: 0.1077, METEOR: 0.0516, Combined: 0.0583\n",
            "\n",
            "[225/288] Testing top_p=0.95, top_k=0, temp=1.0\n",
            "  BLEU: 0.0083, ROUGE-1: 0.0924, ROUGE-2: 0.0056, ROUGE-L: 0.0862, METEOR: 0.0348, Combined: 0.0441\n",
            "\n",
            "[226/288] Testing top_p=0.95, top_k=0, temp=1.1\n",
            "  BLEU: 0.0048, ROUGE-1: 0.0722, ROUGE-2: 0.0077, ROUGE-L: 0.0636, METEOR: 0.0262, Combined: 0.0338\n",
            "\n",
            "[227/288] Testing top_p=0.95, top_k=0, temp=1.2\n",
            "  BLEU: 0.0040, ROUGE-1: 0.0593, ROUGE-2: 0.0000, ROUGE-L: 0.0582, METEOR: 0.0222, Combined: 0.0278\n",
            "\n",
            "[228/288] Testing top_p=0.95, top_k=0, temp=1.3\n",
            "  BLEU: 0.0089, ROUGE-1: 0.0801, ROUGE-2: 0.0009, ROUGE-L: 0.0750, METEOR: 0.0393, Combined: 0.0393\n",
            "\n",
            "[229/288] Testing top_p=0.95, top_k=5, temp=1.0\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1290, ROUGE-2: 0.0140, ROUGE-L: 0.1229, METEOR: 0.0518, Combined: 0.0635\n",
            "\n",
            "[230/288] Testing top_p=0.95, top_k=5, temp=1.1\n",
            "  BLEU: 0.0126, ROUGE-1: 0.1301, ROUGE-2: 0.0161, ROUGE-L: 0.1198, METEOR: 0.0537, Combined: 0.0644\n",
            "\n",
            "[231/288] Testing top_p=0.95, top_k=5, temp=1.2\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1154, ROUGE-2: 0.0181, ROUGE-L: 0.1102, METEOR: 0.0387, Combined: 0.0569\n",
            "\n",
            "[232/288] Testing top_p=0.95, top_k=5, temp=1.3\n",
            "  BLEU: 0.0065, ROUGE-1: 0.1001, ROUGE-2: 0.0171, ROUGE-L: 0.0944, METEOR: 0.0387, Combined: 0.0498\n",
            "\n",
            "[233/288] Testing top_p=0.95, top_k=10, temp=1.0\n",
            "  BLEU: 0.0110, ROUGE-1: 0.1100, ROUGE-2: 0.0165, ROUGE-L: 0.1044, METEOR: 0.0443, Combined: 0.0556\n",
            "\n",
            "[234/288] Testing top_p=0.95, top_k=10, temp=1.1\n",
            "  BLEU: 0.0095, ROUGE-1: 0.0985, ROUGE-2: 0.0210, ROUGE-L: 0.0941, METEOR: 0.0444, Combined: 0.0517\n",
            "\n",
            "[235/288] Testing top_p=0.95, top_k=10, temp=1.2\n",
            "  BLEU: 0.0050, ROUGE-1: 0.0784, ROUGE-2: 0.0057, ROUGE-L: 0.0712, METEOR: 0.0255, Combined: 0.0361\n",
            "\n",
            "[236/288] Testing top_p=0.95, top_k=10, temp=1.3\n",
            "  BLEU: 0.0078, ROUGE-1: 0.0900, ROUGE-2: 0.0039, ROUGE-L: 0.0850, METEOR: 0.0323, Combined: 0.0426\n",
            "\n",
            "[237/288] Testing top_p=0.95, top_k=15, temp=1.0\n",
            "  BLEU: 0.0066, ROUGE-1: 0.0760, ROUGE-2: 0.0030, ROUGE-L: 0.0726, METEOR: 0.0320, Combined: 0.0368\n",
            "\n",
            "[238/288] Testing top_p=0.95, top_k=15, temp=1.1\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1070, ROUGE-2: 0.0151, ROUGE-L: 0.1009, METEOR: 0.0409, Combined: 0.0534\n",
            "\n",
            "[239/288] Testing top_p=0.95, top_k=15, temp=1.2\n",
            "  BLEU: 0.0051, ROUGE-1: 0.1000, ROUGE-2: 0.0047, ROUGE-L: 0.0954, METEOR: 0.0366, Combined: 0.0468\n",
            "\n",
            "[240/288] Testing top_p=0.95, top_k=15, temp=1.3\n",
            "  BLEU: 0.0081, ROUGE-1: 0.0888, ROUGE-2: 0.0090, ROUGE-L: 0.0831, METEOR: 0.0380, Combined: 0.0439\n",
            "\n",
            "[241/288] Testing top_p=0.95, top_k=20, temp=1.0\n",
            "  BLEU: 0.0065, ROUGE-1: 0.0950, ROUGE-2: 0.0098, ROUGE-L: 0.0891, METEOR: 0.0325, Combined: 0.0453\n",
            "\n",
            "[242/288] Testing top_p=0.95, top_k=20, temp=1.1\n",
            "  BLEU: 0.0100, ROUGE-1: 0.1106, ROUGE-2: 0.0128, ROUGE-L: 0.0981, METEOR: 0.0482, Combined: 0.0540\n",
            "\n",
            "[243/288] Testing top_p=0.95, top_k=20, temp=1.2\n",
            "  BLEU: 0.0097, ROUGE-1: 0.1045, ROUGE-2: 0.0168, ROUGE-L: 0.1024, METEOR: 0.0435, Combined: 0.0537\n",
            "\n",
            "[244/288] Testing top_p=0.95, top_k=20, temp=1.3\n",
            "  BLEU: 0.0082, ROUGE-1: 0.0928, ROUGE-2: 0.0147, ROUGE-L: 0.0872, METEOR: 0.0374, Combined: 0.0466\n",
            "\n",
            "[245/288] Testing top_p=0.95, top_k=25, temp=1.0\n",
            "  BLEU: 0.0092, ROUGE-1: 0.1027, ROUGE-2: 0.0050, ROUGE-L: 0.0973, METEOR: 0.0403, Combined: 0.0493\n",
            "\n",
            "[246/288] Testing top_p=0.95, top_k=25, temp=1.1\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1056, ROUGE-2: 0.0101, ROUGE-L: 0.1002, METEOR: 0.0406, Combined: 0.0518\n",
            "\n",
            "[247/288] Testing top_p=0.95, top_k=25, temp=1.2\n",
            "  BLEU: 0.0067, ROUGE-1: 0.0920, ROUGE-2: 0.0058, ROUGE-L: 0.0839, METEOR: 0.0396, Combined: 0.0440\n",
            "\n",
            "[248/288] Testing top_p=0.95, top_k=25, temp=1.3\n",
            "  BLEU: 0.0068, ROUGE-1: 0.0939, ROUGE-2: 0.0080, ROUGE-L: 0.0916, METEOR: 0.0344, Combined: 0.0456\n",
            "\n",
            "[249/288] Testing top_p=0.95, top_k=30, temp=1.0\n",
            "  BLEU: 0.0096, ROUGE-1: 0.0854, ROUGE-2: 0.0059, ROUGE-L: 0.0799, METEOR: 0.0367, Combined: 0.0421\n",
            "\n",
            "[250/288] Testing top_p=0.95, top_k=30, temp=1.1\n",
            "  BLEU: 0.0073, ROUGE-1: 0.0902, ROUGE-2: 0.0101, ROUGE-L: 0.0867, METEOR: 0.0359, Combined: 0.0446\n",
            "\n",
            "[251/288] Testing top_p=0.95, top_k=30, temp=1.2\n",
            "  BLEU: 0.0077, ROUGE-1: 0.0906, ROUGE-2: 0.0074, ROUGE-L: 0.0885, METEOR: 0.0425, Combined: 0.0456\n",
            "\n",
            "[252/288] Testing top_p=0.95, top_k=30, temp=1.3\n",
            "  BLEU: 0.0063, ROUGE-1: 0.0839, ROUGE-2: 0.0082, ROUGE-L: 0.0817, METEOR: 0.0353, Combined: 0.0416\n",
            "\n",
            "[253/288] Testing top_p=0.95, top_k=35, temp=1.0\n",
            "  BLEU: 0.0064, ROUGE-1: 0.0893, ROUGE-2: 0.0043, ROUGE-L: 0.0871, METEOR: 0.0302, Combined: 0.0423\n",
            "\n",
            "[254/288] Testing top_p=0.95, top_k=35, temp=1.1\n",
            "  BLEU: 0.0088, ROUGE-1: 0.1032, ROUGE-2: 0.0107, ROUGE-L: 0.0959, METEOR: 0.0400, Combined: 0.0502\n",
            "\n",
            "[255/288] Testing top_p=0.95, top_k=35, temp=1.2\n",
            "  BLEU: 0.0096, ROUGE-1: 0.0839, ROUGE-2: 0.0045, ROUGE-L: 0.0789, METEOR: 0.0418, Combined: 0.0421\n",
            "\n",
            "[256/288] Testing top_p=0.95, top_k=35, temp=1.3\n",
            "  BLEU: 0.0053, ROUGE-1: 0.0757, ROUGE-2: 0.0024, ROUGE-L: 0.0726, METEOR: 0.0280, Combined: 0.0356\n",
            "\n",
            "[257/288] Testing top_p=1.0, top_k=0, temp=1.0\n",
            "  BLEU: 0.0049, ROUGE-1: 0.0528, ROUGE-2: 0.0000, ROUGE-L: 0.0528, METEOR: 0.0260, Combined: 0.0262\n",
            "\n",
            "[258/288] Testing top_p=1.0, top_k=0, temp=1.1\n",
            "  BLEU: 0.0046, ROUGE-1: 0.0614, ROUGE-2: 0.0015, ROUGE-L: 0.0551, METEOR: 0.0280, Combined: 0.0290\n",
            "\n",
            "[259/288] Testing top_p=1.0, top_k=0, temp=1.2\n",
            "  BLEU: 0.0042, ROUGE-1: 0.0617, ROUGE-2: 0.0032, ROUGE-L: 0.0601, METEOR: 0.0272, Combined: 0.0301\n",
            "\n",
            "[260/288] Testing top_p=1.0, top_k=0, temp=1.3\n",
            "  BLEU: 0.0035, ROUGE-1: 0.0561, ROUGE-2: 0.0037, ROUGE-L: 0.0553, METEOR: 0.0245, Combined: 0.0275\n",
            "\n",
            "[261/288] Testing top_p=1.0, top_k=5, temp=1.0\n",
            "  BLEU: 0.0108, ROUGE-1: 0.1193, ROUGE-2: 0.0082, ROUGE-L: 0.1161, METEOR: 0.0410, Combined: 0.0576\n",
            "\n",
            "[262/288] Testing top_p=1.0, top_k=5, temp=1.1\n",
            "  BLEU: 0.0104, ROUGE-1: 0.1173, ROUGE-2: 0.0163, ROUGE-L: 0.1076, METEOR: 0.0490, Combined: 0.0582\n",
            "\n",
            "[263/288] Testing top_p=1.0, top_k=5, temp=1.2\n",
            "  BLEU: 0.0082, ROUGE-1: 0.0988, ROUGE-2: 0.0080, ROUGE-L: 0.0964, METEOR: 0.0378, Combined: 0.0484\n",
            "\n",
            "[264/288] Testing top_p=1.0, top_k=5, temp=1.3\n",
            "  BLEU: 0.0066, ROUGE-1: 0.1100, ROUGE-2: 0.0084, ROUGE-L: 0.1022, METEOR: 0.0443, Combined: 0.0524\n",
            "\n",
            "[265/288] Testing top_p=1.0, top_k=10, temp=1.0\n",
            "  BLEU: 0.0123, ROUGE-1: 0.1004, ROUGE-2: 0.0168, ROUGE-L: 0.0957, METEOR: 0.0423, Combined: 0.0520\n",
            "\n",
            "[266/288] Testing top_p=1.0, top_k=10, temp=1.1\n",
            "  BLEU: 0.0066, ROUGE-1: 0.0959, ROUGE-2: 0.0020, ROUGE-L: 0.0915, METEOR: 0.0365, Combined: 0.0450\n",
            "\n",
            "[267/288] Testing top_p=1.0, top_k=10, temp=1.2\n",
            "  BLEU: 0.0111, ROUGE-1: 0.1099, ROUGE-2: 0.0183, ROUGE-L: 0.1020, METEOR: 0.0547, Combined: 0.0570\n",
            "\n",
            "[268/288] Testing top_p=1.0, top_k=10, temp=1.3\n",
            "  BLEU: 0.0047, ROUGE-1: 0.0987, ROUGE-2: 0.0077, ROUGE-L: 0.0912, METEOR: 0.0307, Combined: 0.0453\n",
            "\n",
            "[269/288] Testing top_p=1.0, top_k=15, temp=1.0\n",
            "  BLEU: 0.0084, ROUGE-1: 0.0981, ROUGE-2: 0.0193, ROUGE-L: 0.0903, METEOR: 0.0381, Combined: 0.0493\n",
            "\n",
            "[270/288] Testing top_p=1.0, top_k=15, temp=1.1\n",
            "  BLEU: 0.0084, ROUGE-1: 0.0972, ROUGE-2: 0.0117, ROUGE-L: 0.0921, METEOR: 0.0485, Combined: 0.0496\n",
            "\n",
            "[271/288] Testing top_p=1.0, top_k=15, temp=1.2\n",
            "  BLEU: 0.0064, ROUGE-1: 0.0868, ROUGE-2: 0.0125, ROUGE-L: 0.0820, METEOR: 0.0353, Combined: 0.0432\n",
            "\n",
            "[272/288] Testing top_p=1.0, top_k=15, temp=1.3\n",
            "  BLEU: 0.0047, ROUGE-1: 0.0828, ROUGE-2: 0.0033, ROUGE-L: 0.0763, METEOR: 0.0288, Combined: 0.0380\n",
            "\n",
            "[273/288] Testing top_p=1.0, top_k=20, temp=1.0\n",
            "  BLEU: 0.0064, ROUGE-1: 0.0943, ROUGE-2: 0.0087, ROUGE-L: 0.0877, METEOR: 0.0341, Combined: 0.0449\n",
            "\n",
            "[274/288] Testing top_p=1.0, top_k=20, temp=1.1\n",
            "  BLEU: 0.0040, ROUGE-1: 0.0745, ROUGE-2: 0.0146, ROUGE-L: 0.0688, METEOR: 0.0330, Combined: 0.0375\n",
            "\n",
            "[275/288] Testing top_p=1.0, top_k=20, temp=1.2\n",
            "  BLEU: 0.0050, ROUGE-1: 0.0972, ROUGE-2: 0.0114, ROUGE-L: 0.0875, METEOR: 0.0311, Combined: 0.0451\n",
            "\n",
            "[276/288] Testing top_p=1.0, top_k=20, temp=1.3\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0868, ROUGE-2: 0.0088, ROUGE-L: 0.0822, METEOR: 0.0360, Combined: 0.0428\n",
            "\n",
            "[277/288] Testing top_p=1.0, top_k=25, temp=1.0\n",
            "  BLEU: 0.0105, ROUGE-1: 0.0959, ROUGE-2: 0.0084, ROUGE-L: 0.0934, METEOR: 0.0436, Combined: 0.0487\n",
            "\n",
            "[278/288] Testing top_p=1.0, top_k=25, temp=1.1\n",
            "  BLEU: 0.0114, ROUGE-1: 0.1091, ROUGE-2: 0.0102, ROUGE-L: 0.1017, METEOR: 0.0502, Combined: 0.0546\n",
            "\n",
            "[279/288] Testing top_p=1.0, top_k=25, temp=1.2\n",
            "  BLEU: 0.0093, ROUGE-1: 0.0933, ROUGE-2: 0.0119, ROUGE-L: 0.0865, METEOR: 0.0378, Combined: 0.0463\n",
            "\n",
            "[280/288] Testing top_p=1.0, top_k=25, temp=1.3\n",
            "  BLEU: 0.0060, ROUGE-1: 0.0812, ROUGE-2: 0.0022, ROUGE-L: 0.0749, METEOR: 0.0338, Combined: 0.0382\n",
            "\n",
            "[281/288] Testing top_p=1.0, top_k=30, temp=1.0\n",
            "  BLEU: 0.0079, ROUGE-1: 0.0868, ROUGE-2: 0.0120, ROUGE-L: 0.0824, METEOR: 0.0350, Combined: 0.0435\n",
            "\n",
            "[282/288] Testing top_p=1.0, top_k=30, temp=1.1\n",
            "  BLEU: 0.0074, ROUGE-1: 0.0692, ROUGE-2: 0.0044, ROUGE-L: 0.0671, METEOR: 0.0358, Combined: 0.0354\n",
            "\n",
            "[283/288] Testing top_p=1.0, top_k=30, temp=1.2\n",
            "  BLEU: 0.0075, ROUGE-1: 0.0755, ROUGE-2: 0.0058, ROUGE-L: 0.0703, METEOR: 0.0314, Combined: 0.0369\n",
            "\n",
            "[284/288] Testing top_p=1.0, top_k=30, temp=1.3\n",
            "  BLEU: 0.0053, ROUGE-1: 0.0849, ROUGE-2: 0.0036, ROUGE-L: 0.0783, METEOR: 0.0325, Combined: 0.0396\n",
            "\n",
            "[285/288] Testing top_p=1.0, top_k=35, temp=1.0\n",
            "  BLEU: 0.0093, ROUGE-1: 0.1040, ROUGE-2: 0.0122, ROUGE-L: 0.0958, METEOR: 0.0411, Combined: 0.0509\n",
            "\n",
            "[286/288] Testing top_p=1.0, top_k=35, temp=1.1\n",
            "  BLEU: 0.0102, ROUGE-1: 0.1046, ROUGE-2: 0.0168, ROUGE-L: 0.0951, METEOR: 0.0443, Combined: 0.0525\n",
            "\n",
            "[287/288] Testing top_p=1.0, top_k=35, temp=1.2\n",
            "  BLEU: 0.0085, ROUGE-1: 0.1099, ROUGE-2: 0.0100, ROUGE-L: 0.1023, METEOR: 0.0404, Combined: 0.0526\n",
            "\n",
            "[288/288] Testing top_p=1.0, top_k=35, temp=1.3\n",
            "  BLEU: 0.0081, ROUGE-1: 0.0790, ROUGE-2: 0.0141, ROUGE-L: 0.0766, METEOR: 0.0406, Combined: 0.0421\n",
            "\n",
            "============================================================\n",
            "NO-EMOTION HYPERPARAMETER SEARCH COMPLETED\n",
            "============================================================\n",
            "Best parameters: top_p=0.6, top_k=0, temperature=1.0\n",
            "Best combined score: 0.0808\n",
            "\n",
            "Best result details:\n",
            "  BLEU Score: 0.0196\n",
            "  ROUGE-1: 0.1454\n",
            "  ROUGE-2: 0.0424\n",
            "  ROUGE-L: 0.1413\n",
            "  METEOR: 0.0672\n",
            "  Combined Score: 0.0808\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/hyperparameter_search/no_emotion_hyperparameter_search_20250825_092453.pkl\n",
            "CSV summary saved to: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/hyperparameter_search/no_emotion_hyperparameter_results_20250825_092453.csv\n",
            "\n",
            "Best hyperparameters found:\n",
            "top_p: 0.6\n",
            "top_k: 0\n",
            "temperature: 1.0\n",
            "Score: 0.0808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT No Emotion EValuation"
      ],
      "metadata": {
        "id": "U9fGb7uhZtEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns from SFT data\"\"\"\n",
        "    expression_pattern = r'\\s*(The (?:speaker|emotion state)[^.]*\\.(?:[^.]*\\.)*)'\n",
        "    match = re.search(expression_pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_no_emotion_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load no-emotion trained model\"\"\"\n",
        "    print(f\"Loading no-emotion model: {checkpoint_path}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"No-emotion model loaded with vocab size: {len(tokenizer)}\")\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_baseline_gpt2(device='cuda'):\n",
        "    \"\"\"Load vanilla GPT-2 model\"\"\"\n",
        "    print(\"Loading vanilla GPT-2 model...\")\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Vanilla GPT-2 loaded with vocab size: {len(tokenizer)}\")\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_emotion_classifier(device='cuda'):\n",
        "    \"\"\"Load RoBERTa emotion classifier\"\"\"\n",
        "    print(\"Loading emotion classifier...\")\n",
        "    emotion_tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
        "    emotion_model = AutoModelForSequenceClassification.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
        "    emotion_model.to(device)\n",
        "    emotion_model.eval()\n",
        "    return emotion_model, emotion_tokenizer\n",
        "\n",
        "def predict_emotion_roberta(text, emotion_model, emotion_tokenizer, device='cuda'):\n",
        "    \"\"\"Predict emotion using RoBERTa model, constrained to therapy emotions\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "    therapy_emotions = ['anger', 'joy', 'neutral', 'sadness', 'depression', 'disgust', 'fear']\n",
        "\n",
        "    # Tokenize and predict\n",
        "    inputs = emotion_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = emotion_model(**inputs)\n",
        "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    # Get all emotion labels from RoBERTa model\n",
        "    emotion_labels = emotion_model.config.id2label\n",
        "\n",
        "    # Enhanced mapping based on the 28 RoBERTa emotions\n",
        "    emotion_mapping = {\n",
        "        # Direct matches\n",
        "        'anger': 'anger',\n",
        "        'joy': 'joy',\n",
        "        'sadness': 'sadness',\n",
        "        'fear': 'fear',\n",
        "        'disgust': 'disgust',\n",
        "        'neutral': 'neutral',\n",
        "\n",
        "        # Joy-related emotions\n",
        "        'amusement': 'joy',\n",
        "        'excitement': 'joy',\n",
        "        'gratitude': 'joy',\n",
        "        'love': 'joy',\n",
        "        'optimism': 'joy',\n",
        "        'pride': 'joy',\n",
        "        'relief': 'joy',\n",
        "        'admiration': 'joy',\n",
        "\n",
        "        # Sadness-related emotions (potential depression indicators)\n",
        "        'disappointment': 'sadness',\n",
        "        'embarrassment': 'sadness',\n",
        "        'grief': 'sadness',\n",
        "        'remorse': 'sadness',\n",
        "\n",
        "        # Anger-related emotions\n",
        "        'annoyance': 'anger',\n",
        "        'disapproval': 'anger',\n",
        "\n",
        "        # Fear-related emotions\n",
        "        'nervousness': 'fear',\n",
        "\n",
        "        # Neutral-related emotions\n",
        "        'approval': 'neutral',\n",
        "        'caring': 'neutral',\n",
        "        'confusion': 'neutral',\n",
        "        'curiosity': 'neutral',\n",
        "        'desire': 'neutral',\n",
        "        'realization': 'neutral',\n",
        "        'surprise': 'neutral'\n",
        "    }\n",
        "\n",
        "    therapy_scores = {emotion: 0.0 for emotion in therapy_emotions}\n",
        "\n",
        "    for class_id, score in enumerate(predictions[0]):\n",
        "        go_emotion = emotion_labels[class_id]\n",
        "        therapy_emotion = emotion_mapping.get(go_emotion, 'neutral')\n",
        "        therapy_scores[therapy_emotion] += score.item()\n",
        "\n",
        "    best_emotion = max(therapy_scores, key=therapy_scores.get)\n",
        "    best_score = therapy_scores[best_emotion]\n",
        "\n",
        "    if best_emotion == 'sadness':\n",
        "        depression_indicators = ['grief', 'remorse', 'disappointment', 'embarrassment']\n",
        "        depression_score = sum(predictions[0][class_id].item()\n",
        "                              for class_id, label in emotion_labels.items()\n",
        "                              if label in depression_indicators)\n",
        "\n",
        "        if depression_score > 0.2 or (emotion_labels.get(predictions[0].argmax().item()) in ['grief', 'remorse']):\n",
        "            best_emotion = 'depression'\n",
        "            best_score = depression_score\n",
        "\n",
        "    return best_emotion, best_score\n",
        "\n",
        "# ====================== Reference Data Processing ======================\n",
        "class TherapyEvaluationDatasetNoEmotion:\n",
        "    \"\"\"Dataset class for evaluation data processing - No Emotion Version\"\"\"\n",
        "\n",
        "    def __init__(self, json_path):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            self._data = json.load(f)\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_evaluation_data()\n",
        "\n",
        "    def _process_evaluation_data(self):\n",
        "        \"\"\"Process dialog data for evaluation\"\"\"\n",
        "        for conv in tqdm(self._data, desc=\"Processing evaluation data\"):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            user_text_parts = []\n",
        "            user_emotions = []\n",
        "\n",
        "            for turn in dialog:\n",
        "                speaker = turn.get(\"speaker\", \"\")\n",
        "                text = clean_therapy_text(turn.get(\"text\", \"\"))\n",
        "                emotion = turn.get(\"emotion\", \"\").strip()\n",
        "\n",
        "                if speaker != \"sys\":  # User turn\n",
        "                    if text:\n",
        "                        user_text_parts.append(text)\n",
        "                    if emotion:\n",
        "                        user_emotions.append(emotion)\n",
        "                else:  # Therapist turn\n",
        "                    if not user_text_parts:\n",
        "                        continue\n",
        "\n",
        "                    therapist_text = clean_therapy_text(text)\n",
        "                    therapist_emotion = emotion\n",
        "\n",
        "                    combined_user_text = \" \".join(user_text_parts)\n",
        "                    last_user_emotion = user_emotions[-1] if user_emotions else \"\"\n",
        "\n",
        "                    # Create input in no-emotion training format\n",
        "                    input_parts = [\"<bos>\"]\n",
        "                    if problem_type:\n",
        "                        input_parts.extend([\"<problem>\", problem_type])\n",
        "                    input_parts.extend([\"<user>\", combined_user_text])\n",
        "                    if last_user_emotion:\n",
        "                        input_parts.extend([\"<user_emotion>\", last_user_emotion])\n",
        "                    input_parts.append(\"<therapist>\")\n",
        "\n",
        "                    input_text = \"\".join(input_parts)\n",
        "\n",
        "                    self.evaluation_data.append({\n",
        "                        'input_text': input_text,\n",
        "                        'reference_text': therapist_text,\n",
        "                        'reference_emotion': therapist_emotion,\n",
        "                        'user_input': combined_user_text,\n",
        "                        'user_emotion': last_user_emotion,\n",
        "                        'problem_type': problem_type\n",
        "                    })\n",
        "\n",
        "                    user_text_parts = []\n",
        "                    user_emotions = []\n",
        "\n",
        "        print(f\"Processed {len(self.evaluation_data)} evaluation samples\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_model_with_emotion_detection(model, tokenizer, evaluation_dataset, device='cuda',\n",
        "                                         top_p=0.6, top_k=0, temperature=1.0, max_new_tokens=64, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Evaluate model with RoBERTa emotion detection\n",
        "    \"\"\"\n",
        "    # Load emotion classifier\n",
        "    emotion_model, emotion_tokenizer = load_emotion_classifier(device)\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Evaluating {model_name} on {len(evaluation_data)} samples...\")\n",
        "\n",
        "    # Create progress bar\n",
        "    progress_bar = tqdm(evaluation_data, desc=f\"Evaluating {model_name}\")\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        if \"baseline\" in model_name.lower():\n",
        "            user_match = re.search(r'<user>(.*?)(?:<user_emotion>|<therapist>)', input_text)\n",
        "            if user_match:\n",
        "                processed_input = user_match.group(1).strip()\n",
        "            else:\n",
        "                processed_input = sample['user_input']\n",
        "        else:\n",
        "            # For trained model, use full structured input\n",
        "            processed_input = input_text\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(processed_input, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=True,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        predicted_text = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "        # Predict emotion using RoBERTa\n",
        "        predicted_emotion, emotion_confidence = predict_emotion_roberta(\n",
        "            predicted_text, emotion_model, emotion_tokenizer, device\n",
        "        )\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower())\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "\n",
        "        emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "\n",
        "        # Store sample outputs for inspection\n",
        "        if i < 5:\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'processed_input': processed_input,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'emotion_confidence': emotion_confidence,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        # Update progress\n",
        "        if (i + 1) % 20 == 0:\n",
        "            avg_bleu = np.mean(results['bleu_scores'])\n",
        "            avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "            progress_bar.set_description(f\"Evaluating {model_name} - BLEU: {avg_bleu:.3f}, Emotion: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['model_name'] = model_name\n",
        "    results['generation_params'] = {\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'temperature': temperature,\n",
        "        'max_new_tokens': max_new_tokens\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "    model_name = results.get('model_name', 'Unknown')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"{model_name.upper()} EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Show generation parameters\n",
        "    gen_params = results.get('generation_params', {})\n",
        "    if gen_params:\n",
        "        print(f\"Generation Params: top_p={gen_params.get('top_p', 'N/A')}, \"\n",
        "              f\"max_tokens={gen_params.get('max_new_tokens', 'N/A')}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction (via RoBERTa):\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Input: {sample['input'][:80]}...\")\n",
        "        print(f\"    Processed: {sample['processed_input'][:60]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:60]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:60]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']} (conf: {sample['emotion_confidence']:.3f})\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "def compare_models(results_list):\n",
        "    \"\"\"Compare multiple model results\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"{'Model':<30} {'BLEU':<8} {'ROUGE-1':<8} {'ROUGE-L':<8} {'METEOR':<8} {'Emotion Acc':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for results in results_list:\n",
        "        summary = results['summary']\n",
        "        model_name = results.get('model_name', 'Unknown')\n",
        "        print(f\"{model_name:<30} {summary['avg_bleu']:<8.4f} {summary['avg_rouge1']:<8.4f} \"\n",
        "              f\"{summary['avg_rougeL']:<8.4f} {summary['avg_meteor']:<8.4f} {summary['emotion_accuracy']:<12.4f}\")\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "    NO_EMOTION_MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/therapy_checkpoints_4thFIXED_noemotions/best_model.ckpt\"\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/train_processed_no_emotion_v1_tokenizer\"\n",
        "    TEST_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/test.json\"\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    eval_dataset = TherapyEvaluationDatasetNoEmotion(TEST_DATA_PATH)\n",
        "\n",
        "    results_list = []\n",
        "\n",
        "    print(\"=== EVALUATING NO-EMOTION TRAINED MODEL ===\")\n",
        "    no_emotion_model, no_emotion_tokenizer = load_no_emotion_model(NO_EMOTION_MODEL_PATH, TOKENIZER_PATH, DEVICE)\n",
        "    no_emotion_results = evaluate_model_with_emotion_detection(\n",
        "        no_emotion_model, no_emotion_tokenizer, eval_dataset, DEVICE,\n",
        "        top_p=0.6, top_k=0, temperature=1.0, max_new_tokens=128, model_name=\"No-Emotion Trained Model\"\n",
        "    )\n",
        "    print_evaluation_results(no_emotion_results)\n",
        "    results_list.append(no_emotion_results)\n",
        "\n",
        "\n",
        "    compare_models(results_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4bbc90b011d64936b861c6738eb51f7b",
            "e671951ce1214773ac266bea93932607",
            "c05ba641de32427d8688464dcafc75fc",
            "f2991937f56f4dd29da53dae5b02ff3e",
            "5dacea550b344a0e986a61938789e724",
            "0b91cee79c084eb899cb7fa90e2417c3",
            "81f50236448d4292a5f138788851bc64",
            "0ff1f4ce692241b888f0d32adc6e1f02",
            "c6dcce7e055641e288c87bc196b7c18a",
            "745ac7abe14c46b08ca4925a92627347",
            "816f522de974459b822a770d8c6d567e",
            "524437d999aa488fb37f5cd2b0a9c9bf",
            "eb08f2d1ccee43a486984178b877bbb3",
            "79c121513fdd4114934617db9e20660f",
            "dc923984e80e42388157fde6fe02437c",
            "a5c9b249059948acbf8ce17140d8ea61",
            "bd678ef9bfca44b783b8bbcc1aa14d36",
            "2c838e1ae0514f49a5497f82d81dc0ed",
            "3ace6e6a90ab4a2f83abc319504a9863",
            "4bce69901c32449486b6f0fd01a5018d",
            "6660c9826f754ce98d685b0eac0560d8",
            "ad3049d4392a4eba8e0713556c24b62a",
            "7478f0ae42bf436885d4c6b8c5ac94d8",
            "435dc24046ba4a25a4319df15560859e",
            "3516d37139f74f53b7f392c4b5eec522",
            "114450ebc064436db7cef87a081a87e9",
            "1fc1935bd4a64479a6ab62f4b618d585",
            "7ac8b942004942ac8bfb259bd18f93d7",
            "cea1e260ece04148a2938097525c2dde",
            "e8ee53941db84c318cf455785ec6305a",
            "888a4e39f8904a90bb8bcbf71dcb8919",
            "0540c2753f1442dfa8b99d68f0a58c80",
            "62e200e0c3314200bdc34eb167c699cf",
            "40ebd7865c11459993f16a615bc243c2",
            "fc4151e041c6461b960dec4b062efba0",
            "e392fc7af4bc44089b823b2b803233d2",
            "f407e98abbde444f92a3403a4bcb9c51",
            "c3037d339d1546af9c4a1224044773ad",
            "5d2bea38ae474c08be410939d71d6991",
            "357a8a5a02e247de8c1acf2bf07d42f2",
            "ef02bad7caee4914bd715703d43e66b7",
            "4dce151e6b7546b4ba12538d039471cc",
            "73c9c6a70fd94c5fb9237bd02f27a3e0",
            "947b23b3f1d448aab45f9f0be5eb114f",
            "b2050d6ff86a4dbfb7e1a5b5eb468c0a",
            "d02a7a1758754bab91c07fa5c47c84b6",
            "a2689f6815f745fd8894cbc7895bb79c",
            "ac00d546416d4d94b255101caff69dae",
            "a6631e9ddb274aeb8c487a7c5d97f7df",
            "e17b5009583d4d34aab5e4071822b536",
            "3275b1c8fc664d7db2e95740ee82a1a8",
            "b62a68f1613e40a38a756fc96a9b98f6",
            "c0e2fb855e4945c6b317e935a6c22b54",
            "d0d4bcafda2c44cab49801dab8018a0f",
            "c16eb98ea27f40b8b7712ba3ae37b486",
            "23ed12aee1c7460abb6c320bcdbc208a",
            "5b424f73c6a549e0a0293a852366514b",
            "749b447c559a41818dff382d345882a1",
            "a78712a33a524baba749f1c7e54a6433",
            "ff264ad7714e462f8a331a56e0010818",
            "dc67c4561e84439ea3071b82e80c7cba",
            "4ca16b35ad6b43afae0a7f4075f93453",
            "c92728534d8d4fbe87358caa9eeeb626",
            "97dc395ba1a6433f883b5b44d3ec8adf",
            "5f5dc20b802f40bd9f62a657caf4b8a0",
            "01c25f8598e2421e96055b12f3de5f41",
            "cf8517666e7a4619afa4e07a25d5db18",
            "9afc5690e260427083c908bd0e69c2bf",
            "005ca838a88f4d0eb7d97dbb6c339bd9",
            "3dbe9c3e7f6d429c9a5938f6e95e25c2",
            "a2222862d224431db68301f93280bd2e",
            "b8cdd7173e3347919bcff9ad6f2fd272",
            "155023b29f5f4e47920b3cac4c5a811b",
            "4768fd34ef83469e888e64ac58ecbc89",
            "2574691fa37643689f187a56ace6e424",
            "05e8a97005754141a7ddbd5039b63a01",
            "49f7c3dbab1447d6b87f7f4ed56e1f19",
            "dd124a8605734bb9b2f5a8578f200aee",
            "2f766f3fda444de6970b340dce4d1595",
            "4f65a5f89936446ebfcbc62273402014",
            "727c326635bf48b5b527beff0373961c",
            "14bce312c2244b528f33a7a687065fea",
            "e75e48df19444f75b6f3aec169b2c63c",
            "4ab8d5d8dbe0425bb2ce6ea964cf657a",
            "4984fb80953148deb2d3f22f9f084f1f",
            "2a65f81c72dd4541836822d39b055995",
            "b1708670f2d448ad93c8b74b9df4da02",
            "00c2b59dc6a84b5a8d295ea1cd8975ea",
            "a3f1bea78d5a40c2a8bc089069247eb3",
            "71618480a0394c1e97b054e97fa0bc17",
            "39285f7f516a488aaa0c978b266cbf1d",
            "21d67dbf4ba94619a5ab8e8662c4e41e",
            "370abcabb4744f7883c760bc53926d3c",
            "4f2097ecf4894ca8bb5ff4d542bb316f",
            "345c64ae42a5488c963e4cad04d50c24",
            "541ca562e0744d9299727513096d8638",
            "0c6c1acdad0b4c3d9315559de4e4f420",
            "2d5f7cfcf2ff4d94afd020891e2f70b0",
            "621e3dbdc80849f2a77dd1e17f661623",
            "88efadb6f2b843589ac31bea2a30b1b9",
            "b56c6a3da58c423f9961e0d918480494",
            "48264b9cebfe4d5f862274217b55dc05",
            "542bd6d484634636b7d52246ea4dc0a4",
            "6883692759704b28933027bfe451c7d6",
            "dbeff08377b741b6b137ce172254e596",
            "97e5827266e84ce582c1a8c879214f31",
            "c2cad09459f848deae4eb1341f6fe837",
            "af4aadd5f1614b7e92d0025cea3ae597",
            "719760902d0f40898edc18f70f91ed5f",
            "1b38f263daa34fdaaf9e03f3301f248a"
          ]
        },
        "id": "yjGHdstRUfVn",
        "outputId": "d73d8459-2932-49d7-830b-a6b413eb90ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "Processing evaluation data: 100%|██████████| 102/102 [00:00<00:00, 7074.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 454 evaluation samples\n",
            "=== EVALUATING NO-EMOTION TRAINED MODEL ===\n",
            "Loading no-emotion model: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/SFTNoemotions/therapy_checkpoints_4thFIXED_noemotions/best_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bbc90b011d64936b861c6738eb51f7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "524437d999aa488fb37f5cd2b0a9c9bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7478f0ae42bf436885d4c6b8c5ac94d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No-emotion model loaded with vocab size: 50269\n",
            "Loading emotion classifier...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40ebd7865c11459993f16a615bc243c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2050d6ff86a4dbfb7e1a5b5eb468c0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23ed12aee1c7460abb6c320bcdbc208a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf8517666e7a4619afa4e07a25d5db18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd124a8605734bb9b2f5a8578f200aee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3f1bea78d5a40c2a8bc089069247eb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88efadb6f2b843589ac31bea2a30b1b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating No-Emotion Trained Model on 454 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating No-Emotion Trained Model - BLEU: 0.011, Emotion: 0.807: 100%|██████████| 454/454 [00:47<00:00,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "NO-EMOTION TRAINED MODEL EVALUATION RESULTS\n",
            "============================================================\n",
            "Generation Params: top_p=0.6, max_tokens=128\n",
            "\n",
            "Text Generation Metrics:\n",
            "  BLEU Score:     0.0106\n",
            "  ROUGE-1:        0.1160\n",
            "  ROUGE-2:        0.0159\n",
            "  ROUGE-L:        0.1058\n",
            "  METEOR:         0.0433\n",
            "\n",
            "Emotion Prediction (via RoBERTa):\n",
            "  Emotion Accuracy:    0.8084\n",
            "\n",
            "Dataset Info:\n",
            "  Total Samples:  454\n",
            "\n",
            "Sample Outputs:\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <bos><problem>Breakups or Divorce<user>I mean, shit, don't you know that men are...\n",
            "    Processed: <bos><problem>Breakups or Divorce<user>I mean, shit, don't y...\n",
            "    Reference: But I thought you said...\n",
            "    Predicted: And what do you think it was about you that he lost touch wi...\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: neutral (conf: 0.984)\n",
            "    BLEU: 0.014, ROUGE-1: 0.105\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <bos><problem>Breakups or Divorce<user>Well, we were watching tv.But before that...\n",
            "    Processed: <bos><problem>Breakups or Divorce<user>Well, we were watchin...\n",
            "    Reference: So you were the one who came up with it....\n",
            "    Predicted: Well, I'm sure that's the option....\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: neutral (conf: 0.985)\n",
            "    BLEU: 0.021, ROUGE-1: 0.111\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <bos><problem>Breakups or Divorce<user>With what?<user_emotion>neutral<therapist...\n",
            "    Processed: <bos><problem>Breakups or Divorce<user>With what?<user_emoti...\n",
            "    Reference: The ultimatum....\n",
            "    Predicted: I'm not saying that she was always perfect....\n",
            "    Ref Emotion: neutral\n",
            "    Pred Emotion: anger (conf: 0.672)\n",
            "    BLEU: 0.000, ROUGE-1: 0.000\n",
            "\n",
            "================================================================================\n",
            "MODEL COMPARISON\n",
            "================================================================================\n",
            "Model                          BLEU     ROUGE-1  ROUGE-L  METEOR   Emotion Acc \n",
            "--------------------------------------------------------------------------------\n",
            "No-Emotion Trained Model       0.0106   0.1160   0.1058   0.0433   0.8084      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESCONV EVALUATION**"
      ],
      "metadata": {
        "id": "H8QkQubE6lnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RL"
      ],
      "metadata": {
        "id": "wIa9u5xYZ2Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns and clean text\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== ESConv Dataset Processing ======================\n",
        "class ESConvEvaluationDataset:\n",
        "    \"\"\"Dataset class for ESConv evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            if isinstance(data, dict):\n",
        "                self._data = [data]\n",
        "            else:\n",
        "                self._data = data\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            # Use default tokenizer if path not provided\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_esconv_data()\n",
        "\n",
        "    def _process_esconv_data(self):\n",
        "        \"\"\"Process ESConv dialog data for evaluation\"\"\"\n",
        "        print(\"Processing ESConv data...\")\n",
        "\n",
        "        for conv_idx, conv in enumerate(tqdm(self._data, desc=\"Processing conversations\")):\n",
        "            # Extract conversation metadata\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            emotion_type = conv.get(\"emotion_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            if not dialog:\n",
        "                continue\n",
        "\n",
        "            if conv_idx < 3:\n",
        "                print(f\"\\nProcessing conversation {conv_idx + 1}:\")\n",
        "                print(f\"  Problem type: {problem_type}\")\n",
        "                print(f\"  Emotion type: {emotion_type}\")\n",
        "                print(f\"  Dialog length: {len(dialog)} turns\")\n",
        "\n",
        "            # Track conversation state\n",
        "            user_messages = []  # Accumulate user messages\n",
        "\n",
        "            for turn_idx, turn in enumerate(dialog):\n",
        "                speaker = turn.get(\"speaker\", \"\").strip()\n",
        "                content = clean_therapy_text(turn.get(\"content\", \"\"))\n",
        "\n",
        "                if not content:\n",
        "                    continue\n",
        "\n",
        "                if speaker == \"seeker\":\n",
        "                    # Accumulate user (seeker) messages\n",
        "                    user_messages.append(content)\n",
        "\n",
        "                elif speaker == \"supporter\":\n",
        "                    if user_messages:  # Only if we have accumulated user messages\n",
        "\n",
        "                        # Combine all user messages for this interaction\n",
        "                        combined_user_text = \" \".join(user_messages)\n",
        "                        therapist_response = content\n",
        "\n",
        "                        # Create structured input in the expected format\n",
        "                        input_parts = []\n",
        "                        if problem_type:\n",
        "                            input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                        input_parts.append(f\"<user>{combined_user_text}\")\n",
        "\n",
        "                        if emotion_type:\n",
        "                            input_parts.append(f\"<user_emotion>{emotion_type}\")\n",
        "\n",
        "                        input_parts.append(\"<therapist>\")\n",
        "                        input_text = \" \".join(input_parts)\n",
        "\n",
        "                        # Create evaluation sample\n",
        "                        eval_sample = {\n",
        "                            'input_text': input_text,\n",
        "                            'reference_text': therapist_response,\n",
        "                            'reference_emotion': emotion_type,\n",
        "                            'user_input': combined_user_text,\n",
        "                            'user_emotion': emotion_type,\n",
        "                            'problem_type': problem_type,\n",
        "                            'conversation_id': conv_idx,\n",
        "                            'turn_id': turn_idx\n",
        "                        }\n",
        "\n",
        "                        self.evaluation_data.append(eval_sample)\n",
        "\n",
        "                        if len(self.evaluation_data) <= 3:\n",
        "                            print(f\"\\n  Sample {len(self.evaluation_data)}:\")\n",
        "                            print(f\"    Input: {input_text[:100]}...\")\n",
        "                            print(f\"    Reference: {therapist_response[:100]}...\")\n",
        "\n",
        "                        # Reset user messages for next interaction\n",
        "                        user_messages = []\n",
        "\n",
        "        print(f\"\\nProcessed {len(self.evaluation_data)} evaluation samples from {len(self._data)} conversations\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "    def print_sample_formats(self, num_samples=3):\n",
        "        \"\"\"Print sample input/output formats for verification\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"ESCONV SAMPLE INPUT/OUTPUT FORMATS\")\n",
        "        print('='*80)\n",
        "\n",
        "        for i, sample in enumerate(self.evaluation_data[:num_samples]):\n",
        "            print(f\"\\nSample {i+1}:\")\n",
        "            print(f\"  Problem Type: {sample['problem_type']}\")\n",
        "            print(f\"  User Emotion: {sample['user_emotion']}\")\n",
        "            print(f\"  Input Format: {sample['input_text'][:150]}...\")\n",
        "            print(f\"  Reference Response: {sample['reference_text'][:100]}...\")\n",
        "            print(f\"  User Input Only: {sample['user_input'][:100]}...\")\n",
        "\n",
        "# ====================== Model Format Detection ======================\n",
        "def detect_model_format(model, tokenizer, device='cuda', test_inputs=None):\n",
        "    \"\"\"\n",
        "    Test model output format (should be consistent since both SFT and RL use same format)\n",
        "\n",
        "    Args:\n",
        "        model: The model to test\n",
        "        tokenizer: Model tokenizer\n",
        "        device: Device to run test on\n",
        "        test_inputs: List of test input strings, uses defaults if None\n",
        "\n",
        "    Returns:\n",
        "        str: 'standard' if using <therapist_emotion> format, 'unknown' otherwise\n",
        "    \"\"\"\n",
        "    if test_inputs is None:\n",
        "        test_inputs = [\n",
        "            \"<problem>anxiety <user>I'm worried about work <user_emotion>anxiety <therapist>\",\n",
        "            \"<problem>depression <user>I feel very sad <user_emotion>sadness <therapist>\",\n",
        "            \"<problem>relationship <user>My partner doesn't understand me <user_emotion>anger <therapist>\"\n",
        "        ]\n",
        "\n",
        "    emotion_tag_count = 0\n",
        "    total_tests = len(test_inputs)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_input in test_inputs:\n",
        "            # Tokenize and generate\n",
        "            input_ids = tokenizer.encode(test_input, return_tensors='pt').to(device)\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decode response\n",
        "            new_tokens = outputs[0][len(input_ids[0]):]\n",
        "            response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "            # Check for emotion tag\n",
        "            if '<therapist_emotion>' in response:\n",
        "                emotion_tag_count += 1\n",
        "\n",
        "    # Determine format\n",
        "    if emotion_tag_count >= total_tests * 0.5:\n",
        "        return 'standard'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"\n",
        "    Extract therapist text and emotion from model output.\n",
        "    Both SFT and RL models use format: 'text <therapist_emotion> emotion<eos>'\n",
        "\n",
        "    Returns:\n",
        "        therapist_text (str): Text before <therapist_emotion>\n",
        "        emotion (str): Emotion word after <therapist_emotion>\n",
        "        has_emotion_tag (bool): Whether emotion tag was found\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        # No emotion tag found, return entire response as text\n",
        "        return response, \"\", False\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_model_esconv(model, tokenizer, evaluation_dataset, device='cuda', max_new_tokens=128,\n",
        "                         top_p=0.7, top_k=10, temperature=1.2, do_sample=True):\n",
        "    \"\"\"\n",
        "    Evaluate model on ESConv therapy dataset\n",
        "\n",
        "    Args:\n",
        "        model: Trained model (SFT or RL)\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: ESConvEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        do_sample: Whether to use sampling\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Detect model output format\n",
        "    detected_format = detect_model_format(model, tokenizer, device)\n",
        "    print(f\"Output format check: {detected_format.upper()}\")\n",
        "\n",
        "    print(f\"Evaluating model on {len(evaluation_data)} ESConv samples...\")\n",
        "\n",
        "    # Create progress bar with custom format\n",
        "    progress_bar = tqdm(evaluation_data, desc=\"Evaluating ESConv\",\n",
        "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "        # Update confusion matrix\n",
        "        if has_emotion:\n",
        "            emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "        else:\n",
        "            emotion_confusion[reference_emotion.lower()]['no_prediction'] += 1\n",
        "\n",
        "        # Store sample outputs for inspection\n",
        "        if i < 10:  # Store first 10 samples\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'full_response': response,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        # Show live samples during evaluation (every 20 samples)\n",
        "        if (i + 1) % 20 == 0 or i < 5:\n",
        "            # Update progress bar description with current sample info\n",
        "            sample_info = f\"Sample {i+1}: BLEU={bleu:.3f}, Emotion={'✓' if emotion_correct else '✗'}\"\n",
        "            progress_bar.set_description(f\"Evaluating ESConv - {sample_info}\")\n",
        "\n",
        "            if (i + 1) % 50 == 0 or i < 3:\n",
        "                print(f\"\\n\" + \"=\"*80)\n",
        "                print(f\"ESCONV LIVE SAMPLE {i+1}/{len(evaluation_data)}\")\n",
        "                print(\"=\"*80)\n",
        "                print(f\"Input: {input_text[:120]}...\")\n",
        "                print(f\"Reference: {reference_text[:100]}...\")\n",
        "                print(f\"Generated: {predicted_text[:100]}...\")\n",
        "                print(f\"Full Response: {response[:150]}...\")\n",
        "                print(f\"Ref Emotion: {reference_emotion} | Pred Emotion: {predicted_emotion} | Match: {'✓' if emotion_correct else '✗'}\")\n",
        "                print(f\"BLEU: {bleu:.4f} | ROUGE-1: {rouge['rouge1']:.4f} | METEOR: {meteor:.4f}\")\n",
        "                print(\"=\"*80)\n",
        "        else:\n",
        "            # Just update progress bar with running averages\n",
        "            if i > 0:\n",
        "                avg_bleu = np.mean(results['bleu_scores'])\n",
        "                avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "                progress_bar.set_description(f\"Evaluating ESConv - Avg BLEU: {avg_bleu:.3f}, Emotion Acc: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['detected_format'] = detected_format\n",
        "\n",
        "    # Print final progress summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ESCONV EVALUATION COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed {len(evaluation_data)} samples\")\n",
        "    print(f\"Average BLEU: {results['summary']['avg_bleu']:.4f}\")\n",
        "    print(f\"Average ROUGE-1: {results['summary']['avg_rouge1']:.4f}\")\n",
        "    print(f\"Emotion Accuracy: {results['summary']['emotion_accuracy']:.4f}\")\n",
        "    print(f\"Emotion Tag Coverage: {results['summary']['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ESCONV THERAPY MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Model Type: {results.get('model_type', 'Unknown').upper()}\")\n",
        "    print(f\"Output Format: {results.get('detected_format', 'Unknown').upper()}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction:\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Tag Coverage: {summary['emotion_tag_coverage']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    # Print emotion confusion matrix\n",
        "    if 'emotion_confusion_matrix' in results:\n",
        "        print(f\"\\nEmotion Confusion Matrix:\")\n",
        "        confusion = results['emotion_confusion_matrix']\n",
        "        for ref_emotion, pred_dict in confusion.items():\n",
        "            print(f\"  {ref_emotion}:\")\n",
        "            for pred_emotion, count in pred_dict.items():\n",
        "                print(f\"    -> {pred_emotion}: {count}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Input: {sample['input'][:100]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:80]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:80]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']}\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"Checkpoint info: Epoch {checkpoint['epoch']}, Loss {checkpoint.get('valid_loss', 'N/A')}\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Automatically detect and load model (SFT checkpoint or RL directory)\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        device: Device to load model on\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, model_type)\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "\n",
        "    elif os.path.isdir(model_path):\n",
        "        # It's a directory - assume RL model\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Main Evaluation Function ======================\n",
        "def run_esconv_evaluation(model_path, tokenizer_path, esconv_data_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Run complete evaluation pipeline on ESConv data\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        esconv_data_path: Path to ESConv JSON data\n",
        "        device: Device to run evaluation on\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model and tokenizer (auto-detect type)\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    print(f\"Loading ESConv evaluation data from {esconv_data_path}...\")\n",
        "    eval_dataset = ESConvEvaluationDataset(esconv_data_path, tokenizer_path)\n",
        "\n",
        "    # Print sample formats to verify conversion\n",
        "    eval_dataset.print_sample_formats(3)\n",
        "\n",
        "    # Run evaluation\n",
        "    results = evaluate_model_esconv(model, tokenizer, eval_dataset, device=device)\n",
        "    results['model_type'] = model_type\n",
        "    results['dataset_type'] = 'esconv'\n",
        "\n",
        "    # Print results\n",
        "    print_evaluation_results(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4\"\n",
        "\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    ESCONV_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/PESConv.json\"  # Update this path to your ESConv data\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    results = run_esconv_evaluation(MODEL_PATH, TOKENIZER_PATH, ESCONV_DATA_PATH, DEVICE)\n",
        "\n",
        "    import pickle\n",
        "    with open('/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/ESConv_RL_evaluation_results2.pkl', 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "    print(\"\\nEvaluation completed! Results saved to ESConv_RL_evaluation_results2.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQjb1B1GDfpf",
        "outputId": "1278321d-52a9-45a0-c3fa-3b84bf2857e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4...\n",
            "Detected RL model directory\n",
            "Loading RL model from directory: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/8m19enhanced_ppo_model/epoch_4 were not used when initializing GPT2LMHeadModel: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded RL model successfully\n",
            "Loading ESConv evaluation data from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/PESConv.json...\n",
            "Processing ESConv data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing conversations:  28%|██▊       | 365/1300 [00:00<00:00, 3649.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing conversation 1:\n",
            "  Problem type: job crisis\n",
            "  Emotion type: anxiety\n",
            "  Dialog length: 27 turns\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "    Reference: Hello, what would you like to talk about?...\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stre...\n",
            "    Reference: What makes your job stressful for you?...\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is ups...\n",
            "    Reference: Do you help your clients to make it to a better financial situation?...\n",
            "\n",
            "Processing conversation 2:\n",
            "  Problem type: problems with friends\n",
            "  Emotion type: anger\n",
            "  Dialog length: 69 turns\n",
            "\n",
            "Processing conversation 3:\n",
            "  Problem type: job crisis\n",
            "  Emotion type: fear\n",
            "  Dialog length: 37 turns\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing conversations: 100%|██████████| 1300/1300 [00:00<00:00, 3710.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 14642 evaluation samples from 1300 conversations\n",
            "\n",
            "================================================================================\n",
            "ESCONV SAMPLE INPUT/OUTPUT FORMATS\n",
            "================================================================================\n",
            "\n",
            "Sample 1:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "  Reference Response: Hello, what would you like to talk about?...\n",
            "  User Input Only: Hello...\n",
            "\n",
            "Sample 2:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stressful but pays well <user_emotion>anxiety <therapi...\n",
            "  Reference Response: What makes your job stressful for you?...\n",
            "  User Input Only: I am having a lot of anxiety about quitting my current job. It is too stressful but pays well...\n",
            "\n",
            "Sample 3:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is upsetting <user_emotion>anxiety <therapist>...\n",
            "  Reference Response: Do you help your clients to make it to a better financial situation?...\n",
            "  User Input Only: I have to deal with many people in hard financial situations and it is upsetting...\n",
            "Output format check: STANDARD\n",
            "Evaluating model on 14642 ESConv samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 1: BLEU=0.029, Emotion=✗:   0%|          | 1/14642 [00:00<38:54,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "Reference: Hello, what would you like to talk about?...\n",
            "Generated: you're nervous about what you're gonna say to me....\n",
            "Full Response: you're nervous about what you're gonna say to me. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0285 | ROUGE-1: 0.4211 | METEOR: 0.1235\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 3: BLEU=0.000, Emotion=✗:   0%|          | 2/14642 [00:00<49:48,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stressful but pays well ...\n",
            "Reference: What makes your job stressful for you?...\n",
            "Generated: you're worried about what you're going to do next month. What do you think about it?...\n",
            "Full Response: you're worried about what you're going to do next month. What do you think about it? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0123 | ROUGE-1: 0.1600 | METEOR: 0.2373\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is upsetting <user_emotion...\n",
            "Reference: Do you help your clients to make it to a better financial situation?...\n",
            "Generated: you're anxious?...\n",
            "Full Response: you're anxious? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.006, Emotion Acc: 0.000:   1%|          | 102/14642 [00:12<29:08,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>sorry about that, but that's good, people help each other Absolutely! Volunteering is a great ...\n",
            "Reference: Do you feel you will be getting the vaccine when it is rolled out where you are?...\n",
            "Generated: if you're going to do that, you need somebody who's going to help you,...\n",
            "Full Response: if you're going to do that, you need somebody who's going to help you, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0115 | ROUGE-1: 0.2424 | METEOR: 0.0898\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:   1%|▏         | 201/14642 [00:23<25:57,  9.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes, I really think you are correct! thank you so very much for your help today! <user_emotion...\n",
            "Reference: The survivor rate from COVID-19 infections is around 99%, so your chances of dying from the virus ar...\n",
            "Generated: I'm sorry, Alex....\n",
            "Full Response: I'm sorry, Alex. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   2%|▏         | 300/14642 [00:34<22:09, 10.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 300/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No I think I'm good <user_emotion>depression <therapist>...\n",
            "Reference: Please click \"Finish and Quit\" to close the chat.. thank you....\n",
            "Generated: I think you're good....\n",
            "Full Response: I think you're good. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   3%|▎         | 401/14642 [00:46<31:25,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>i will have to find somewhere i can properly exercise my awful vocals lol <user_emot...\n",
            "Reference: Ah! I like pop songs from the 60's :-)...\n",
            "Generated: you'll have to find somewhere i can adequately exercise your awful vocals?...\n",
            "Full Response: you'll have to find somewhere i can adequately exercise your awful vocals? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0909 | METEOR: 0.0538\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   3%|▎         | 501/14642 [00:58<26:51,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 500/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>yes , you prediction was so good <user_emotion>sadness <therapist>...\n",
            "Reference: That's lovely to hear. Have you tried discussing your doubts with your supervisor? There are times w...\n",
            "Generated: You're gonna make me a better boxer?...\n",
            "Full Response: You're gonna make me a better boxer? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0426 | METEOR: 0.0147\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   4%|▍         | 602/14642 [01:10<21:45, 10.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Merry Chirstmas. <user_emotion>anxiety <therapist>...\n",
            "Reference: I'm doing good!...\n",
            "Generated: you're worried about...\n",
            "Full Response: you're worried about <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   5%|▍         | 701/14642 [01:21<29:37,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>We are looking at other options via business visa but we don't know how that will go <...\n",
            "Reference: if you are an American, you can just go to Indonesia, get married to your beautiful fiancée and come...\n",
            "Generated: You're afraid that you're gonna be stopped by us?...\n",
            "Full Response: You're afraid that you're gonna be stopped by us? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1143 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   5%|▌         | 801/14642 [01:34<25:41,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Bye Have a Good Day Some Report preparation <user_emotion>anger <therapist>...\n",
            "Reference: Have an amazing Christmas!...\n",
            "Generated: You're feeling really anxious....\n",
            "Full Response: You're feeling really anxious. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   6%|▌         | 901/14642 [01:46<27:38,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That actually sounds like a good idea. I hope the shelter near me will take volunteers...\n",
            "Reference: If you are not comfortable going out due to COVID, you could involve some activities online promotin...\n",
            "Generated: You're gonna take the volunteers?...\n",
            "Full Response: You're gonna take the volunteers? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0606 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   7%|▋         | 1001/14642 [01:58<28:04,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I'll keep that in mind as I move forward. I really appreciate your help. <user_emotion>...\n",
            "Reference: I commend you for doing the thesis and I also know it can get weary as time passes, but with some go...\n",
            "Generated: you're helping me....\n",
            "Full Response: you're helping me. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0465 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   8%|▊         | 1101/14642 [02:10<28:37,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>With him... he was perfect (or at least I thought), but also, I'm lonely, and it's h...\n",
            "Reference: Have you tried making other connections online? A lot of people are home during this pandemic, you m...\n",
            "Generated: Do you feel lonely when you're alone?...\n",
            "Full Response: Do you feel lonely when you're alone? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0039 | ROUGE-1: 0.1333 | METEOR: 0.0488\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   8%|▊         | 1201/14642 [02:22<30:02,  7.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i usually try to follow the tutorials and do revisions <user_emotion>anxiety <therapist...\n",
            "Reference: Can you think of anything you can do, to help make your studying be more successful?...\n",
            "Generated: you're not sure you wanna follow the drawings?...\n",
            "Full Response: you're not sure you wanna follow the drawings? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0102 | ROUGE-1: 0.1600 | METEOR: 0.0658\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:   9%|▉         | 1301/14642 [02:34<25:48,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>And to you You doing alright? <user_emotion>anxiety <therapist>...\n",
            "Reference: How are you today? I am buried in cookie dough, lol, but happy and wwell....\n",
            "Generated: I'm... I'm fine....\n",
            "Full Response: I'm... I'm fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  10%|▉         | 1402/14642 [02:45<22:59,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Well, counselors are hard to get ahold of so close to the Holidays. The so-called teach...\n",
            "Reference: Are you confident in your abilities to succeed in those classes or you think you might lack the mate...\n",
            "Generated: who does not want you to be around her?...\n",
            "Full Response: who does not want you to be around her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0054 | ROUGE-1: 0.1212 | METEOR: 0.0667\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  10%|█         | 1501/14642 [02:57<28:07,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1500/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I am having a hard time.... Ok, I will look some of them online. I need some financial planner...\n",
            "Reference: If you want other suggestions, meditation is something that is extremely overlooked and will help yo...\n",
            "Generated: Do you think that you're being a good mom to your son?...\n",
            "Full Response: Do you think that you're being a good mom to your son? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0011 | ROUGE-1: 0.1905 | METEOR: 0.0649\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  11%|█         | 1602/14642 [03:10<26:53,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1600/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>no other questions, you have been most helpful, thank you! <user_emotion>anxiety <t...\n",
            "Reference: I have done volunteer work; people want to be friends with those who care and know how to use a nail...\n",
            "Generated: you've been most helpful,...\n",
            "Full Response: you've been most helpful, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0227\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  12%|█▏        | 1701/14642 [03:21<23:20,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I feel like a replaceable cog in a giant machine that doesn't give two shits whether I show up...\n",
            "Reference: you are doing your best and are working really hard...\n",
            "Generated: you're not getting your numbers up, you're just...\n",
            "Full Response: you're not getting your numbers up, you're just <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0216 | ROUGE-1: 0.2000 | METEOR: 0.0510\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  12%|█▏        | 1801/14642 [03:33<21:05, 10.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Do you smoke and drink alcohol? <user_emotion>depression <therapist>...\n",
            "Reference: No, I don't find that to be healthy, and I don't enjoy them....\n",
            "Generated: I'm just asking....\n",
            "Full Response: I'm just asking. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1053 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  13%|█▎        | 1901/14642 [03:45<26:37,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1900/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I think so? I think it is just the way the material is taught now. We have these \"Zoom\"...\n",
            "Reference: What happened when you reached out to the teacher?...\n",
            "Generated: Do you... Do you wish you could retire?...\n",
            "Full Response: Do you... Do you wish you could retire? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0245 | ROUGE-1: 0.1176 | METEOR: 0.0562\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  14%|█▎        | 2001/14642 [03:57<20:38, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Well thank you im okay <user_emotion>depression <therapist>...\n",
            "Reference: Hmm all the best...\n",
            "Generated: you're fine....\n",
            "Full Response: you're fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  14%|█▍        | 2101/14642 [04:08<24:45,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hmm, I didn't know that. I'm on a waiting list for a therapist through my medical insu...\n",
            "Reference: That is a good idea, especially at this time when it's probably not a good idea to see too many new ...\n",
            "Generated: Do you think you could get help from somebody...\n",
            "Full Response: Do you think you could get help from somebody <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0019 | ROUGE-1: 0.0952 | METEOR: 0.0337\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  15%|█▌        | 2201/14642 [04:19<22:34,  9.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2200/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>hi <user_emotion>anxiety <therapist>...\n",
            "Reference: Hello....\n",
            "Generated: I'm sorry....\n",
            "Full Response: I'm sorry. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  16%|█▌        | 2301/14642 [04:31<22:56,  8.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>did she start off doing that or was she employed by another company <user_emotion>fear <therap...\n",
            "Reference: She has over 100 companies that are hiring...\n",
            "Generated: you're not sure?...\n",
            "Full Response: you're not sure? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  16%|█▋        | 2401/14642 [04:43<21:52,  9.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I try to find a job but there is not many <user_emotion>anxiety <therapist>...\n",
            "Reference: I am sorry to hear that. How long have you been looking?...\n",
            "Generated: you can do that?...\n",
            "Full Response: you can do that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0109 | ROUGE-1: 0.2500 | METEOR: 0.0446\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 2500: BLEU=0.002, Emotion=✗:  17%|█▋        | 2500/14642 [04:54<23:25,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>my dog was 13 years old. she was very close to me. i had her when she was a puppy <u...\n",
            "Reference: The dog then lived a very happy and fulfilling life from what I can tell. Dogs are among the best co...\n",
            "Generated: you were very close to her?...\n",
            "Full Response: you were very close to her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0024 | ROUGE-1: 0.1333 | METEOR: 0.0676\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  18%|█▊        | 2601/14642 [05:06<27:15,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2600/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Friends not being there for me when I need emotional support. They also do not pay ...\n",
            "Reference: So just to make sure I understand, you are having issues with your friends not being there for you e...\n",
            "Generated: Why do you think they don't want you to be there for them?...\n",
            "Full Response: Why do you think they don't want you to be there for them? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0082 | ROUGE-1: 0.2917 | METEOR: 0.1795\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  18%|█▊        | 2702/14642 [05:18<20:39,  9.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That's a very optimistic view... <user_emotion>sadness <therapist>...\n",
            "Reference: Like I said, I used to be sad too and not optimistic. But now I am optimistic because I know what it...\n",
            "Generated: That's a very optimistic view?...\n",
            "Full Response: That's a very optimistic view? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0417 | METEOR: 0.0134\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  19%|█▉        | 2800/14642 [05:30<23:42,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I just lost interest. I'm losing interest in everything, man I think it's time for my ...\n",
            "Reference: I certainly hope you don't do that!...\n",
            "Generated: You don't think you're losing interest in everything?...\n",
            "Full Response: You don't think you're losing interest in everything? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0278 | ROUGE-1: 0.3333 | METEOR: 0.2641\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  20%|█▉        | 2901/14642 [05:41<23:30,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>yes, thanks a lot for your time <user_emotion>anger <therapist>...\n",
            "Reference: You are welcome. I hope you don't give up, and stay optimistic! It sounds like you have a great star...\n",
            "Generated: You're welcome....\n",
            "Full Response: You're welcome. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1667 | METEOR: 0.0275\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  20%|██        | 3001/14642 [05:53<24:16,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3000/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>that will be hard because i am soo used to her being around <user_emotion>sadness <t...\n",
            "Reference: I can understand that but the only way you can work it out with her if both of you two just talk...\n",
            "Generated: you're so used to seeing her around?...\n",
            "Full Response: you're so used to seeing her around? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0039 | ROUGE-1: 0.1333 | METEOR: 0.0488\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  21%|██        | 3100/14642 [06:05<19:13, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hi, I am doing ok, how are you? <user_emotion>fear <therapist>...\n",
            "Reference: Good thank you. Why only ok? What is bothering you?...\n",
            "Generated: Good. What are you doing?...\n",
            "Full Response: Good. What are you doing? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0198 | ROUGE-1: 0.4000 | METEOR: 0.0526\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  22%|██▏       | 3201/14642 [06:16<22:25,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>ohh 1 wow, I will definitely try that. It sounds like you're a doctor!\" Whenever I get tense o...\n",
            "Reference: Thank you that is very kind of you to say. I have just had alot of practice in dealing with anxiety....\n",
            "Generated: I know you're not perfect,...\n",
            "Full Response: I know you're not perfect, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0727 | METEOR: 0.0112\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  23%|██▎       | 3301/14642 [06:27<21:16,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i was mad, but now i am just upset. My professor put in grades for my class earlier thi...\n",
            "Reference: Just to make sure I understand, you got a bad grade in one of your classes and your grade dropped be...\n",
            "Generated: you're upset?...\n",
            "Full Response: you're upset? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  23%|██▎       | 3400/14642 [06:38<19:02,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3400/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Hello. <user_emotion>sadness <therapist>...\n",
            "Reference: Hello...\n",
            "Generated: I'm sorry?...\n",
            "Full Response: I'm sorry? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  24%|██▍       | 3502/14642 [06:50<19:23,  9.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hi <user_emotion>shame <therapist>...\n",
            "Reference: Hello...\n",
            "Generated: you're angry. What are you angry about?...\n",
            "Full Response: you're angry. What are you angry about? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  25%|██▍       | 3600/14642 [07:02<18:19, 10.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>you are so nice. i lost my job and having trouble finding a new on one <user_emotion>anxiety <...\n",
            "Reference: Oh, I'm so sorry. I can empathize a bit. I lost mine earlier this year due to covid, but they did br...\n",
            "Generated: you're so nice....\n",
            "Full Response: you're so nice. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.0690 | METEOR: 0.0228\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  25%|██▌       | 3701/14642 [07:14<20:08,  9.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I have sold wreaths for awhile but I did not have time to be as serious so I did not sell a to...\n",
            "Reference: That sounds like an excellent idea to me! I think that you are definitely doing the right thing....\n",
            "Generated: you're not serious?...\n",
            "Full Response: you're not serious? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0909 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  26%|██▌       | 3801/14642 [07:26<19:36,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3800/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>We have gotten him tutors in the past and it helps. I am not sure I could do a tutor wi...\n",
            "Reference: you are right. Have you tried helping him with his work?...\n",
            "Generated: I can do a tutor with him?...\n",
            "Full Response: I can do a tutor with him? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0187 | ROUGE-1: 0.2222 | METEOR: 0.0472\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  27%|██▋       | 3902/14642 [07:38<19:45,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>oh, i dont use it much <user_emotion>depression <therapist>...\n",
            "Reference: There is also proofreading that can help establish yourself...\n",
            "Generated: You don't really have to use it?...\n",
            "Full Response: You don't really have to use it? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  27%|██▋       | 4001/14642 [07:49<18:30,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Garbo hates small animals also. Especially skunks <user_emotion>anxiety <therapist>...\n",
            "Reference: Oh Garbo! Hahahaha! She sounds wonderful!...\n",
            "Generated: He can get you into trouble?...\n",
            "Full Response: He can get you into trouble? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  28%|██▊       | 4101/14642 [08:00<19:11,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>so sorry i had stepped away <user_emotion>sadness <therapist>...\n",
            "Reference: I have been having a bit of a bad time in life lately so I can understand and empathise if you are t...\n",
            "Generated: you were angry?...\n",
            "Full Response: you were angry? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.0769 | METEOR: 0.0238\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  29%|██▊       | 4201/14642 [08:12<20:02,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4200/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>haha YES! see it is a stupid thing. like dood we hook your ass up all the tome time...\n",
            "Reference: People suck....\n",
            "Generated: I'm sorry?...\n",
            "Full Response: I'm sorry? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  29%|██▉       | 4301/14642 [08:24<18:07,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yes, I am feeling very anxious about my school work lately. <user_emotion>anxiety <ther...\n",
            "Reference: I see, so your main worry is about academic pressure?...\n",
            "Generated: you're anxious?...\n",
            "Full Response: you're anxious? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  30%|███       | 4402/14642 [08:36<17:22,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>It was a political game where she isolated the president and made him no longer support her. I...\n",
            "Reference: ok so your director played a game she was not allowed to play and she got caught playing it and quit...\n",
            "Generated: You think she's acting like you?...\n",
            "Full Response: You think she's acting like you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0606 | METEOR: 0.0208\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  31%|███       | 4501/14642 [08:48<21:39,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>What are those? I heard of them, but never used them. Most of my old friends are no ...\n",
            "Reference: Social networks online, you can connect with family or old coworkers. And post pictures and see what...\n",
            "Generated: You don't think that's true?...\n",
            "Full Response: You don't think that's true? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0645 | METEOR: 0.0226\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  31%|███▏      | 4601/14642 [09:00<22:56,  7.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No, since too much time has passed <user_emotion>sadness <therapist>...\n",
            "Reference: Have you tried any local churches or agencies? findhelp.org is also a great resource....\n",
            "Generated: You've got a little bit of time....\n",
            "Full Response: You've got a little bit of time. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0122 | ROUGE-1: 0.1739 | METEOR: 0.0752\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  32%|███▏      | 4700/14642 [09:11<18:01,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4700/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>That makes sense but I just wish I knew why she said it. Did I do something to her,...\n",
            "Reference: maybe you should let her know that you love her and say that you would never want to hurt her, so if...\n",
            "Generated: you're afraid she'll say anything...\n",
            "Full Response: you're afraid she'll say anything <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0784 | METEOR: 0.0134\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  33%|███▎      | 4800/14642 [09:24<22:15,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>well, it was weird that he got so dressed up to go hang out with friends it makes se...\n",
            "Reference: Ok, so this is a HUGE red flag to you. You can ignore it, or not. Women KNOW when a man is cheating,...\n",
            "Generated: you didn't wanna be naked to go hang out with him?...\n",
            "Full Response: you didn't wanna be naked to go hang out with him? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0012 | ROUGE-1: 0.1071 | METEOR: 0.0369\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  33%|███▎      | 4901/14642 [09:35<19:03,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>i'm withdrawing from the work and that's bad. i still care about the work, but the toxic envir...\n",
            "Reference: maybe seek out someone more senior in a different department who can help...\n",
            "Generated: you're gonna do anything to help me?...\n",
            "Full Response: you're gonna do anything to help me? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0140 | ROUGE-1: 0.0952 | METEOR: 0.0403\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  34%|███▍      | 5002/14642 [09:47<18:20,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>How are you doing today? <user_emotion>anxiety <therapist>...\n",
            "Reference: I am doing well and how are you feeling today?...\n",
            "Generated: I'm fine....\n",
            "Full Response: I'm fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1538 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  35%|███▍      | 5101/14642 [10:00<17:52,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes. <user_emotion>fear <therapist>...\n",
            "Reference: I can understand how that feels. Have you tried to talk to them about it?...\n",
            "Generated: And what happened?...\n",
            "Full Response: And what happened? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.000:  36%|███▌      | 5201/14642 [10:11<13:38, 11.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Hello! Life is treating me fair, what about you? <user_emotion>anxiety <therapist>...\n",
            "Reference: Well, I've been a bit worried this year due to Covid and everything. Have you been worrying about an...\n",
            "Generated: You're anxious....\n",
            "Full Response: You're anxious. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0870 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  36%|███▌      | 5301/14642 [10:23<17:23,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I agree. She can't see past her own issues to see the whole situation. <user_emotio...\n",
            "Reference: If you think its a more serious problem maybe ask her to seek professional help....\n",
            "Generated: She's not seeing the whole picture?...\n",
            "Full Response: She's not seeing the whole picture? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  37%|███▋      | 5400/14642 [10:34<18:17,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Things have been pretty rough for the last few years. I found out she was hanging ou...\n",
            "Reference: So from what I am hearing, you ended things with your girlfriend because she was talking to her ex a...\n",
            "Generated: you're worried that she's going to come to her...\n",
            "Full Response: you're worried that she's going to come to her  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0044 | ROUGE-1: 0.2326 | METEOR: 0.0505\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  38%|███▊      | 5501/14642 [10:46<17:45,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>His latest obsession has been 3d printing. I have found weird sites with ' funny'' d...\n",
            "Reference: goodness...\n",
            "Generated: He might not like that?...\n",
            "Full Response: He might not like that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  38%|███▊      | 5600/14642 [10:57<18:03,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5600/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I enjoy snowboarding as a hobby. I might try to get back on my board depending on wh...\n",
            "Reference: Yes. when you are depressed it is hard to become motivated to do anything. However, it is extremely ...\n",
            "Generated: Do you think you'll find something else?...\n",
            "Full Response: Do you think you'll find something else? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0952 | METEOR: 0.0217\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  39%|███▉      | 5701/14642 [11:10<16:58,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>i am depressed <user_emotion>depression <therapist>...\n",
            "Reference: I'm sorry to hear that! When did you begin feeling this way?...\n",
            "Generated: You're depressed?...\n",
            "Full Response: You're depressed? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  40%|███▉      | 5801/14642 [11:22<14:10, 10.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I will follow your suggestion. Thanks a lot. <user_emotion>sadness <therapist>...\n",
            "Reference: You are so welcome! I hope you start to feel better soon....\n",
            "Generated: You'll follow me?...\n",
            "Full Response: You'll follow me? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  40%|████      | 5902/14642 [11:33<15:50,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5900/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I appreciate your help! I'll try to have a productive conversation with her soon. <...\n",
            "Reference: Great, the sooner the better. I have a feeling you'll both be relieved when you do....\n",
            "Generated: What do you mean, when she'll be happy?...\n",
            "Full Response: What do you mean, when she'll be happy? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0134 | ROUGE-1: 0.3846 | METEOR: 0.0987\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  41%|████      | 6001/14642 [11:44<15:50,  9.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I've been felling quite deppressed recently, just wanted to ask for some mental suppor...\n",
            "Reference: why are you feeling in that way? tell me what it's happening?...\n",
            "Generated: I'd like to ask for some support?...\n",
            "Full Response: I'd like to ask for some support? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  42%|████▏     | 6101/14642 [11:55<14:27,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>It's just me and my small family. I was at college but moved home a few weeks ago. At ...\n",
            "Reference: I have heard that is the norm among colleges. That has to be really tough. So much of college is in ...\n",
            "Generated: You're......\n",
            "Full Response: You're... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0392 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  42%|████▏     | 6202/14642 [12:08<14:48,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6200/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>yes i have faith in people very fast seriously its like your seeing my mind <user_em...\n",
            "Reference: Maybe this could be a learning experience? I always try to see the best in people, but have learned ...\n",
            "Generated: you're seeing your mind?...\n",
            "Full Response: you're seeing your mind? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0556 | METEOR: 0.0177\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  43%|████▎     | 6301/14642 [12:19<16:42,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yes, that is true. I just can't quite seem to quiet my mind. (8) <user_emotion>anxiety ...\n",
            "Reference: Well, I've tried meditating a few times before which doesn;t take it all away, it just takes the edg...\n",
            "Generated: You're not quite able to......\n",
            "Full Response: You're not quite able to... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0789 | METEOR: 0.0083\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  44%|████▎     | 6401/14642 [12:31<17:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>It might, I am not sure but I don't think my boss will like the idea <user_emotion>anxiety <th...\n",
            "Reference: Sometimes it's important to remember that part of your bosses job is having this kinds of conversati...\n",
            "Generated: you've brought in. What would you like me to do?...\n",
            "Full Response: you've brought in. What would you like me to do? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0056 | ROUGE-1: 0.1081 | METEOR: 0.0426\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  44%|████▍     | 6502/14642 [12:43<13:55,  9.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>but he thinks he is always right and blah blah blah yes My real concern is for the boy...\n",
            "Reference: I can tell this situation stresses you out and probably consumes a lot of your day to day energy. I ...\n",
            "Generated: you think it's okay that you're always wrong?...\n",
            "Full Response: you think it's okay that you're always wrong? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0008 | ROUGE-1: 0.0870 | METEOR: 0.0151\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  45%|████▌     | 6602/14642 [12:53<13:02, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>True That's a good idea. Thank you for your help I just have this as my mai n income r...\n",
            "Reference: Okay, then one of you will have income and then he can find a job later....\n",
            "Generated: Help me to continue to...\n",
            "Full Response: Help me to continue to <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  46%|████▌     | 6701/14642 [13:05<14:08,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6700/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i know thats why im so stress. stressed bye <user_emotion>depression <therapist>...\n",
            "Reference: Perhaps \"teacher\" is the right path, buth \"math\" is not. good Luck to you...\n",
            "Generated: I'm not gonna......\n",
            "Full Response: I'm not gonna... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1111 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  46%|████▋     | 6801/14642 [13:17<13:03, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6800/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Hi, I need to vent about an ongoing situation. Can I talk to you? <user_emotion>ang...\n",
            "Reference: Of course you can talk to me, What would you like to vent about?...\n",
            "Generated: Sure. How about this?...\n",
            "Full Response: Sure. How about this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1111 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  47%|████▋     | 6901/14642 [13:28<15:13,  8.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I do. My other sister is always a big help. Maybe I should text her more often? <user_...\n",
            "Reference: yes! that would always be a good idea. its always comforting to hear from a loved one....\n",
            "Generated: You don't want to talk to her too much?...\n",
            "Full Response: You don't want to talk to her too much? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0099 | ROUGE-1: 0.0741 | METEOR: 0.0309\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  48%|████▊     | 7001/14642 [13:41<17:33,  7.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7000/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>My breakup was a few months ago too. I'm in the Poconos. :) <user_emotion>depression...\n",
            "Reference: I've always wanted to go to Las Vegas. My brother and his girlfriend just took a trip out there not ...\n",
            "Generated: Do you think it's possible for you to...\n",
            "Full Response: Do you think it's possible for you to <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0043 | ROUGE-1: 0.0606 | METEOR: 0.0233\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  48%|████▊     | 7101/14642 [13:52<12:31, 10.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7100/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yeah, it can be very stressful when I don't understand though. I'm normally a very good...\n",
            "Reference: Yes, I had a 100% average almost in high school and still struggled with the class. I kind of wish t...\n",
            "Generated: you're not feeling well?...\n",
            "Full Response: you're not feeling well? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  49%|████▉     | 7201/14642 [14:06<17:06,  7.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>To be honest I have been a little afraid to approach them about the subject because the...\n",
            "Reference: Just from chatting to you, I can sense that you are anxious, however, as many students feel this way...\n",
            "Generated: You're afraid you're gonna be blamed?...\n",
            "Full Response: You're afraid you're gonna be blamed? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1053 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  50%|████▉     | 7301/14642 [14:17<12:57,  9.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I m not sure. why would my friend let it happen, and why would my boyfriend choose t...\n",
            "Reference: you've had some time to sit with this, i understand completely that you are disgusted, but how have ...\n",
            "Generated: you're angry with her?...\n",
            "Full Response: you're angry with her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0004 | ROUGE-1: 0.1290 | METEOR: 0.0218\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  51%|█████     | 7401/14642 [14:29<13:32,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That must have been difficult to deal with. Mental health affects so many people in so...\n",
            "Reference: It was. Luckily I had my doctor to help me. Family members meant well but chalked it up to \"that's w...\n",
            "Generated: That's what you're saying?...\n",
            "Full Response: That's what you're saying? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.1500 | METEOR: 0.0166\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  51%|█████     | 7501/14642 [14:41<13:58,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7500/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>feeling very shame <user_emotion>shame <therapist>...\n",
            "Reference: Oh my god ! What happened?...\n",
            "Generated: you're not shameful?...\n",
            "Full Response: you're not shameful? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  52%|█████▏    | 7601/14642 [14:52<12:02,  9.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yes I do hope so. <user_emotion>depression <therapist>...\n",
            "Reference: I love AMC/Holiday movies as well!...\n",
            "Generated: You're very happy....\n",
            "Full Response: You're very happy. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  53%|█████▎    | 7701/14642 [15:04<13:23,  8.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I've been better. Just stressed really bad. but I think everybody just about is at thi...\n",
            "Reference: it is a stressful time. what's bothering you the most?...\n",
            "Generated: Do you think everybody else is at this point?...\n",
            "Full Response: Do you think everybody else is at this point? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0255 | ROUGE-1: 0.2000 | METEOR: 0.1010\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  53%|█████▎    | 7800/14642 [15:15<12:49,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yeah maybe. I suppose nobody really understands but I could at least speak to them abo...\n",
            "Reference: everyone has problems and it is good to talk about them because a problem shared is a problem halved...\n",
            "Generated: You wanna speak to them about it?...\n",
            "Full Response: You wanna speak to them about it? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0003 | ROUGE-1: 0.1961 | METEOR: 0.0635\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  54%|█████▍    | 7901/14642 [15:27<13:18,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>yes <user_emotion>anxiety <therapist>...\n",
            "Reference: You are definitely not the only person to feel this way!...\n",
            "Generated: you're not gonna do that?...\n",
            "Full Response: you're not gonna do that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0162 | ROUGE-1: 0.2353 | METEOR: 0.0481\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  55%|█████▍    | 8000/14642 [15:40<13:03,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>yea, thats what my family is telling me to not rush into thigns <user_emotion>depressi...\n",
            "Reference: You have to do what's right for you...\n",
            "Generated: You're gonna rush into this?...\n",
            "Full Response: You're gonna rush into this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1333 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  55%|█████▌    | 8101/14642 [15:53<13:33,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>but anyhow, I have been conferring with my friend pretty much daily on the phone and t...\n",
            "Reference: that's great. having a supportive friend/family is so much a blessing during this pandemic...\n",
            "Generated: if you'd like to talk to him....\n",
            "Full Response: if you'd like to talk to him. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  56%|█████▌    | 8201/14642 [16:05<13:03,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hi <user_emotion>depression <therapist>...\n",
            "Reference: What can I help you with today?...\n",
            "Generated: You're just trying to get a clearer picture....\n",
            "Full Response: You're just trying to get a clearer picture. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  57%|█████▋    | 8302/14642 [16:17<12:08,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I'm just having a hard time dealing with hurtful things people have said to me. I f...\n",
            "Reference: that is really hard. Are you able to tell these people how their words are making you feel?...\n",
            "Generated: you're just having a hard time coping with hurtful things?...\n",
            "Full Response: you're just having a hard time coping with hurtful things? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1379 | METEOR: 0.0291\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  57%|█████▋    | 8401/14642 [16:28<12:47,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I don't want to. If there is a vaccine in the first quarter of 2021 then the company I worked ...\n",
            "Reference: you have determination! There is fire within! Tell me, what brings you joy?...\n",
            "Generated: you're not sure you want to go back to your old job?...\n",
            "Full Response: you're not sure you want to go back to your old job? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0157 | ROUGE-1: 0.1538 | METEOR: 0.0388\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  58%|█████▊    | 8500/14642 [16:39<09:27, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>My oldest is sad my youngest 7 couldnt care less. He loves that he can just play roblo...\n",
            "Reference: To be fair Roblox is pretty fun. Have you seen those videos on Facebook where family members visit t...\n",
            "Generated: You're not sure...\n",
            "Full Response: You're not sure <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0526 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  59%|█████▊    | 8602/14642 [16:53<10:44,  9.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I have practiced breathing techniques and meditation before and think that is a great ...\n",
            "Reference: Absolutely, and it's completely understandable, but it's very hard to wait. I hope that you are able...\n",
            "Generated: you're afraid he'll become ill?...\n",
            "Full Response: you're afraid he'll become ill? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0333 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  59%|█████▉    | 8701/14642 [17:05<13:00,  7.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8700/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I am not good . What about you? <user_emotion>depression <therapist>...\n",
            "Reference: i am so sorry to hear that. what seems to be worrying you today?...\n",
            "Generated: You're good. You're gonna be fine....\n",
            "Full Response: You're good. You're gonna be fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0108 | ROUGE-1: 0.1818 | METEOR: 0.0379\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  60%|██████    | 8801/14642 [17:17<12:02,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yeah, the anxiety of being trapped in my apartment has kind of gotten to me but I am d...\n",
            "Reference: Yeah, socially distancing is quite the isolating experience so I can relate to how you are feeling....\n",
            "Generated: Would you like me to talk to you about your anxiety?...\n",
            "Full Response: Would you like me to talk to you about your anxiety? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0130 | ROUGE-1: 0.1429 | METEOR: 0.0610\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  61%|██████    | 8900/14642 [17:29<10:43,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>It's good that you have had a similar experience and understand what I'm going throu...\n",
            "Reference: Oh I see. That's a huge step to make in a relationship. So you are hesitant to break up with her bec...\n",
            "Generated: You feel you're rejecting her?...\n",
            "Full Response: You feel you're rejecting her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1667 | METEOR: 0.0188\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  61%|██████▏   | 9001/14642 [17:40<10:03,  9.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No! I keep hearing the negative cruel remarks being repeated in my head over and over ...\n",
            "Reference: WHAT DO YOU HEAR?...\n",
            "Generated: you're not telling me you're afraid?...\n",
            "Full Response: you're not telling me you're afraid? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1667 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  62%|██████▏   | 9101/14642 [17:53<10:02,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes, sure. I work in an industry heavily impacted by COVID-19, and my company has announced pa...\n",
            "Reference: Woah. Blessings to you for existing in what sounds like a stressful situation. How is self care goin...\n",
            "Generated: you've been seeing this...\n",
            "Full Response: you've been seeing this <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1600 | METEOR: 0.0272\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  63%|██████▎   | 9201/14642 [18:05<09:55,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hi <user_emotion>sadness <therapist>...\n",
            "Reference: Hi there, how are you today?...\n",
            "Generated: You're sorry you didn't tell me?...\n",
            "Full Response: You're sorry you didn't tell me? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0408 | ROUGE-1: 0.1429 | METEOR: 0.0833\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  64%|██████▎   | 9301/14642 [18:17<10:13,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I thought I had everything set up for one of my resident's at a new placement and I called tod...\n",
            "Reference: I see. It seems as though you've done your best, but I understand your feelings. Is it possible you ...\n",
            "Generated: You're afraid she'll let you go?...\n",
            "Full Response: You're afraid she'll let you go? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0010 | ROUGE-1: 0.1081 | METEOR: 0.0194\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  64%|██████▍   | 9402/14642 [18:29<08:44, 10.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I don't know if it was good. Maybe he was just being mean. It's nice of you to liste...\n",
            "Reference: I know it's useless to tell you to not be sad. Go ahead and let it all out by crying or screaming bu...\n",
            "Generated: You'll be back in April....\n",
            "Full Response: You'll be back in April. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0004 | ROUGE-1: 0.1053 | METEOR: 0.0182\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  65%|██████▍   | 9501/14642 [18:40<09:04,  9.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>thanks. I hope you best of luck then with all your endeavours. I know we can all get t...\n",
            "Reference: Right on, same to you. It's okay to feel anxious right now. It's okay to feel unproductive right now...\n",
            "Generated: who you're traveling with....\n",
            "Full Response: who you're traveling with. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0400 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  66%|██████▌   | 9600/14642 [18:52<09:19,  9.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>She did but not so great anymore. I sure hope so. It's been hard on everybody. especia...\n",
            "Reference: Maybe she just needs some time to decompress. Being a teenager is a stressful time, especially this ...\n",
            "Generated: You think she's......\n",
            "Full Response: You think she's... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0541 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  66%|██████▋   | 9701/14642 [19:04<11:27,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9700/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I am not feeling very positive tonight but I think you are right. I think I reached ...\n",
            "Reference: Would you feel comfortable giving me a little more detail as far as you problem with self abuse? wha...\n",
            "Generated: What do you think you're saying to somebody...\n",
            "Full Response: What do you think you're saying to somebody <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0033 | ROUGE-1: 0.1765 | METEOR: 0.0429\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  67%|██████▋   | 9801/14642 [19:16<09:39,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>It's fine, no need to apologize <user_emotion>anxiety <therapist>...\n",
            "Reference: Have you had any chance for ME Time where husband friend or family could watch your kids and give mo...\n",
            "Generated: you can just... you can just......\n",
            "Full Response: you can just... you can just... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0003 | ROUGE-1: 0.0465 | METEOR: 0.0152\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  68%|██████▊   | 9901/14642 [19:28<07:55,  9.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>But when i see social media and News every day it increasing my stress level <user_emo...\n",
            "Reference: I live alone as well and also need to take care of myself. It can be so hard at times....\n",
            "Generated: You're worried about your Stress?...\n",
            "Full Response: You're worried about your Stress? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  68%|██████▊   | 10001/14642 [19:40<08:44,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I feel somewhat better just thin I feel a little better now. I look forward to talking...\n",
            "Reference: Be creative! Get silly! most important have fun! this is a hard year but its still a chance to make ...\n",
            "Generated: You wanna talk about Zoom?...\n",
            "Full Response: You wanna talk about Zoom? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0246\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  69%|██████▉   | 10102/14642 [19:51<08:14,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I just need to schedule an appointment with someone and go in and meet them face to ...\n",
            "Reference: It is great that you can identify what needs to be done in this situation. It sounds like you are re...\n",
            "Generated: What would you like to meet them face to face?...\n",
            "Full Response: What would you like to meet them face to face? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0013 | ROUGE-1: 0.1961 | METEOR: 0.0660\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  70%|██████▉   | 10201/14642 [20:03<08:17,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I'm so sorry that it's a situation that you can relate to, its such a hard situation w...\n",
            "Reference: Wow, that really is a lot to deal with. It seems as though you have a good understanding of what you...\n",
            "Generated: What do you wanna say to that?...\n",
            "Full Response: What do you wanna say to that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0941 | METEOR: 0.0214\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  70%|███████   | 10301/14642 [20:15<11:19,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thanks' so much , you lifted my mood , you being really helpful <user_emotion>depres...\n",
            "Reference: No problem at all! Sending positive vibes your way!! You can get through this!!...\n",
            "Generated: You're really glad I didn't feel like you lifted my mood....\n",
            "Full Response: You're really glad I didn't feel like you lifted my mood. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0741 | METEOR: 0.0365\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  71%|███████   | 10402/14642 [20:27<06:59, 10.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Because prior to the pandemic, I was pretty regimented with set schedules and can clea...\n",
            "Reference: Is there anything else I can help you with?...\n",
            "Generated: you're not feeling this...\n",
            "Full Response: you're not feeling this <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1429 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  72%|███████▏  | 10501/14642 [20:39<09:18,  7.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10500/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I think that's pretty good advice. I know which room I can do this, but just away from ...\n",
            "Reference: Of course! Is anything else on your mind?...\n",
            "Generated: you're quite nervous...\n",
            "Full Response: you're quite nervous <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: nervousness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  72%|███████▏  | 10601/14642 [20:51<08:55,  7.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Well the boyfriend for awhile the other thing for a day or two I got a hold of a thera...\n",
            "Reference: that's very good that you are going to talk to a therapist. you showed great strength by reaching ou...\n",
            "Generated: You didn't want him to talk to you for two days?...\n",
            "Full Response: You didn't want him to talk to you for two days? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0484 | ROUGE-1: 0.3125 | METEOR: 0.2451\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  73%|███████▎  | 10701/14642 [21:03<07:04,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10700/14642\n",
            "================================================================================\n",
            "Input: <problem>Alcohol Abuse <user>Yes, I sure hope so. Thank you have a good day! <user_emotion>shame <therapist>...\n",
            "Reference: You as well!...\n",
            "Generated: you're late....\n",
            "Full Response: you're late. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.3333 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  74%|███████▍  | 10801/14642 [21:16<07:56,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10800/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>I'm looking forward to start a own business. Yes i hope so. i'll start planning <user_emot...\n",
            "Reference: Oh that's exciting! What sort of business?...\n",
            "Generated: You're going to start a business?...\n",
            "Full Response: You're going to start a business? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0346 | ROUGE-1: 0.1333 | METEOR: 0.0725\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  74%|███████▍  | 10901/14642 [21:28<07:57,  7.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10900/14642\n",
            "================================================================================\n",
            "Input: <problem>Procrastination <user>OK, so with, well, kinf0f like baby steps....right <user_emotion>anxiety <therapist>...\n",
            "Reference: It is about making small adjustments to feed a good habit....\n",
            "Generated: You're afraid that you're going to kang...\n",
            "Full Response: You're afraid that you're going to kang  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0187 | ROUGE-1: 0.1000 | METEOR: 0.0472\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  75%|███████▌  | 11001/14642 [21:39<07:13,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11000/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>Bye <user_emotion>anxiety <therapist>...\n",
            "Reference: (please click the quit button)...\n",
            "Generated: So you're afraid she's gonna......\n",
            "Full Response: So you're afraid she's gonna... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  76%|███████▌  | 11101/14642 [21:52<06:30,  9.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11100/14642\n",
            "================================================================================\n",
            "Input: <problem>Alcohol Abuse <user>Work has been stressful, but I feel like was before things got bad. Most nights I come home...\n",
            "Reference: What do you do for work?...\n",
            "Generated: Do you drink?...\n",
            "Full Response: Do you drink? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0418 | ROUGE-1: 0.4444 | METEOR: 0.1754\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  76%|███████▋  | 11201/14642 [22:03<06:34,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11200/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>That's a good idea. I could try go out for a walk either before or after work as a startin...\n",
            "Reference: That sounds like a good plan! It also helps to make sure that it’s dark and very quiet. Surprisingly...\n",
            "Generated: Would you like to walk?...\n",
            "Full Response: Would you like to walk? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.0889 | METEOR: 0.0281\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  77%|███████▋  | 11301/14642 [22:15<05:55,  9.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11300/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>I'm looking forward to a fulls night rest. <user_emotion>anxiety <therapist>...\n",
            "Reference: That is good, lavender baths or showers will also ease and relax the troubled mind....\n",
            "Generated: What do you wanna do?...\n",
            "Full Response: What do you wanna do? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  78%|███████▊  | 11401/14642 [22:27<06:36,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11400/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>mind u i was 125 and fit for the 10 years we were together before we had kids like a d...\n",
            "Reference: I talked to a nutritionist and it really helped. They are professionals who can look into your diet ...\n",
            "Generated: You're not in our lives?...\n",
            "Full Response: You're not in our lives? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  79%|███████▊  | 11502/14642 [22:39<05:26,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11500/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>Yes. I mentioned it to them at my 6 week pp check up. I was prescribed to a med to hel...\n",
            "Reference: Antidepressants can take a couple of weeks to kick in, I am on them too; I hope you will find them h...\n",
            "Generated: Do you think you've gotten the hang of it yet?...\n",
            "Full Response: Do you think you've gotten the hang of it yet? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0038 | ROUGE-1: 0.1463 | METEOR: 0.0554\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  79%|███████▉  | 11600/14642 [22:50<05:16,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11600/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>I hate everything when I see my reflection. I just feel fat and ugly <user_emotion>dis...\n",
            "Reference: Well, I have been overweight and I know it sucks. Perhaps you could join a weight loss group?...\n",
            "Generated: You're so fat and ugly?...\n",
            "Full Response: You're so fat and ugly? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0040 | ROUGE-1: 0.1667 | METEOR: 0.0299\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  80%|███████▉  | 11701/14642 [23:03<05:37,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes that is a very good summary of what is going on. And I am glad to see you can relate. Whil...\n",
            "Reference: Are there other jobs available in your area that you could apply for that are more up your alley?...\n",
            "Generated: you're so depressed....\n",
            "Full Response: you're so depressed. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0870 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  81%|████████  | 11801/14642 [23:14<05:51,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>SOMEWHERE SCARED AND CRYING IN THE RAIN <user_emotion>fear <therapist>...\n",
            "Reference: Is it cold up there?...\n",
            "Generated: You're so scared?...\n",
            "Full Response: You're so scared? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  81%|████████▏ | 11901/14642 [23:26<04:57,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11900/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>i was having an affair and i confided in my best friend about it. i found out that ...\n",
            "Reference: Your friend violated a confidence. That sounds difficult....\n",
            "Generated: what did you find out?...\n",
            "Full Response: what did you find out? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  82%|████████▏ | 12001/14642 [23:38<05:31,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>that sounds weird not what you said I referring to what I said I think it was weird ri...\n",
            "Reference: What do you think sounds weird?...\n",
            "Generated: you're right....\n",
            "Full Response: you're right. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2222 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  83%|████████▎ | 12101/14642 [23:50<05:34,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12100/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Today those things have gone and all are fine. When we happen to think of the old e...\n",
            "Reference: So you are angry about what happen in the past...\n",
            "Generated: you're not sure you want to feel happy?...\n",
            "Full Response: you're not sure you want to feel happy? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0216 | ROUGE-1: 0.1053 | METEOR: 0.0510\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  83%|████████▎ | 12202/14642 [24:02<04:46,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>thanks for trying to understand it just seems pretty hopeless <user_emotion>anxiety <therapist...\n",
            "Reference: No problem. I am encountering a similar situation, looking for a well suited job....\n",
            "Generated: you're really struggling?...\n",
            "Full Response: you're really struggling? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  84%|████████▍ | 12301/14642 [24:14<05:38,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thank you for listening and giving good advice. You are really good at giving suppor...\n",
            "Reference: I am glad that you find it helpful. I wish I can be around to hear more about it....\n",
            "Generated: You're really good at listening to your patients?...\n",
            "Full Response: You're really good at listening to your patients? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0070 | ROUGE-1: 0.1429 | METEOR: 0.0559\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  85%|████████▍ | 12402/14642 [24:26<03:28, 10.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I just don't feel motivated to study <user_emotion>shame <therapist>...\n",
            "Reference: from today please feel yourself that you know everything about your studies , i think then you fell ...\n",
            "Generated: you. You're not motivated to study?...\n",
            "Full Response: you. You're not motivated to study? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2400 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  85%|████████▌ | 12501/14642 [24:37<04:05,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>We met on AIM, Her ex is a registered sex offender. and it makes me sad that she lef...\n",
            "Reference: Sometimes we just have to learn to let go *nods sententiously*...\n",
            "Generated: You think she was trying to get you?...\n",
            "Full Response: You think she was trying to get you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0191 | ROUGE-1: 0.1053 | METEOR: 0.0935\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  86%|████████▌ | 12600/14642 [24:49<03:48,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>We, I and my wife, also think the same way. Even if takes some time, better to wait. But we we...\n",
            "Reference: That's great! I'm glad I was able to help....\n",
            "Generated: We'd like to talk about this?...\n",
            "Full Response: We'd like to talk about this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0248 | ROUGE-1: 0.1111 | METEOR: 0.0575\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  87%|████████▋ | 12701/14642 [25:01<04:17,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12700/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>sure, you too <user_emotion>anxiety <therapist>...\n",
            "Reference: thank you...\n",
            "Generated: you're anxious. You're anxious about your sister?...\n",
            "Full Response: you're anxious. You're anxious about your sister? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1818 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  87%|████████▋ | 12801/14642 [25:13<03:07,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>its hard to plan a future when i am grieving....i don't know how to make myself happ...\n",
            "Reference: don't be sad because of past...\n",
            "Generated: you're......\n",
            "Full Response: you're... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  88%|████████▊ | 12901/14642 [25:26<03:57,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>No I haven't yet. But I was thinking about it actually. Do you think that would be weird to do...\n",
            "Reference: I think that would be a good next step. Communication is always helpful. I think your work will appr...\n",
            "Generated: I don't think it's unusual....\n",
            "Full Response: I don't think it's unusual. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0014 | ROUGE-1: 0.1290 | METEOR: 0.0452\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  89%|████████▉ | 13000/14642 [25:38<03:28,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Thanks, that will be helpful to decide on the programs I want to apply to Are you based...\n",
            "Reference: You welcome. and yes...\n",
            "Generated: I'm not sure that you want me to be your doctor....\n",
            "Full Response: I'm not sure that you want me to be your doctor. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1250 | METEOR: 0.1064\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  89%|████████▉ | 13101/14642 [25:49<02:46,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13100/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>What kind of advise should I be seeking from the counsellor? <user_emotion>anxiety <the...\n",
            "Reference: Well, perhaps they can at least alleviate your anxiety somewhat. Or maybe even get you a sick note t...\n",
            "Generated: You're anxious....\n",
            "Full Response: You're anxious. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0606 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  90%|█████████ | 13201/14642 [26:01<02:31,  9.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>You met with your friends? I've tried meeting with my friends. I feel ok when I'm with...\n",
            "Reference: yes, you have to be positive at all time and always do something that makes you happy...\n",
            "Generated: You wanna talk about yourself?...\n",
            "Full Response: You wanna talk about yourself? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0909 | METEOR: 0.0316\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  91%|█████████ | 13301/14642 [26:13<03:04,  7.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thanks! You’ve been really helpful today. I can’t thank you enough for your encourag...\n",
            "Reference: It was no problem! Thank you for sharing and talking it out!...\n",
            "Generated: You've been very kind to me....\n",
            "Full Response: You've been very kind to me. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1053 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  92%|█████████▏| 13402/14642 [26:25<02:21,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I actually do yoga every evening. She hates it. I'm living in her home without a lease...\n",
            "Reference: As long as you have property there she would have to formally evict you. That is the good news....\n",
            "Generated: You're afraid that she'll just leave you?...\n",
            "Full Response: You're afraid that she'll just leave you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2857 | METEOR: 0.0562\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  92%|█████████▏| 13501/14642 [26:37<02:21,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13500/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>should i go to my school councellor <user_emotion>anxiety <therapist>...\n",
            "Reference: Yes, that is a great idea. Have you ever joined a study group? A group of peers can also be helpful....\n",
            "Generated: who you wanna go to?...\n",
            "Full Response: who you wanna go to? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0022 | ROUGE-1: 0.0769 | METEOR: 0.0258\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  93%|█████████▎| 13601/14642 [26:49<01:58,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>At this point, I don't know. I have thought about doing art commissions and selling them onlin...\n",
            "Reference: That sounds like a fantastic idea, and even if there is competition, there are still a lot of people...\n",
            "Generated: I know you're anxious....\n",
            "Full Response: I know you're anxious. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  94%|█████████▎| 13701/14642 [27:01<01:36,  9.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yes you are correct the problems with the bank how do i solve not to sink into depress...\n",
            "Reference: So, I have also struggled with that in the past. The way that really helped me put things into persp...\n",
            "Generated: you......\n",
            "Full Response: you... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0588 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  94%|█████████▍| 13802/14642 [27:14<01:26,  9.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13800/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Kind of, but the schedule is a bit weird, like every other day I only have an afternoon...\n",
            "Reference: it sounds like your schedule is different almost everyday. I know I find schedule changes like that ...\n",
            "Generated: You've been in this situation before?...\n",
            "Full Response: You've been in this situation before? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0245\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  95%|█████████▍| 13900/14642 [27:26<01:39,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>We talked about it briefly, but havent spoke about in great detail. I'm just scared,...\n",
            "Reference: How much of this distance between you do you think is related to COVID measures?...\n",
            "Generated: What do you think we're gonna do if you do?...\n",
            "Full Response: What do you think we're gonna do if you do? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0681 | ROUGE-1: 0.3077 | METEOR: 0.1379\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  96%|█████████▌| 14001/14642 [27:37<01:09,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14000/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes. i plan on doing that this afternoon. Thank you so much. I am feeling way more at ease. I ...\n",
            "Reference: I hope your day goes great as well...\n",
            "Generated: I appreciate it....\n",
            "Full Response: I appreciate it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0215 | ROUGE-1: 0.1818 | METEOR: 0.0667\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  96%|█████████▋| 14101/14642 [27:50<00:55,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>its gone, she left me <user_emotion>sadness <therapist>...\n",
            "Reference: That's awful. I'm so sorry to hear that. How did it happen?...\n",
            "Generated: You've left her?...\n",
            "Full Response: You've left her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  97%|█████████▋| 14202/14642 [28:02<00:49,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Thank you so much for your insight. I will be praying for a good outcome. <user_emotion...\n",
            "Reference: you will get it for sure! is there anything else I can help you with?...\n",
            "Generated: I'll be praying for a good outcome....\n",
            "Full Response: I'll be praying for a good outcome. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0105 | ROUGE-1: 0.1739 | METEOR: 0.0352\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  98%|█████████▊| 14302/14642 [28:14<00:37,  9.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>That's something you would have to ask him, but I feel like I am at peace for now. ...\n",
            "Reference: Yeah that a good way to look at it. Maybe take your mind of it by occupying yourself...\n",
            "Generated: Do you feel that you're at peace for now?...\n",
            "Full Response: Do you feel that you're at peace for now? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0105 | ROUGE-1: 0.1429 | METEOR: 0.0877\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  98%|█████████▊| 14400/14642 [28:25<00:24, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I'm feeling really anxious these days. I'm finding the COVID online learning experience...\n",
            "Reference: I understand your frustration. All of us are challenged due to COVID....\n",
            "Generated: you're feeling really anxious?...\n",
            "Full Response: you're feeling really anxious? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000:  99%|█████████▉| 14501/14642 [28:37<00:18,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Yeah she was a little violent. I was honestly a little scared for my life for a seco...\n",
            "Reference: Have you talked since then?...\n",
            "Generated: Did she say she was a little scared for your life?...\n",
            "Full Response: Did she say she was a little scared for your life? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000: 100%|█████████▉| 14601/14642 [28:49<00:04, 10.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes It is frustrating. When I think about the financial issues I feel depressed <user_emotion>...\n",
            "Reference: I compleyely understand I have also lost my career due to covid. Dont give up, staying positive and ...\n",
            "Generated: You're depressed?...\n",
            "Full Response: You're depressed? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0645 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.000: 100%|██████████| 14642/14642 [28:53<00:00,  8.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ESCONV EVALUATION COMPLETED!\n",
            "============================================================\n",
            "Processed 14642 samples\n",
            "Average BLEU: 0.0042\n",
            "Average ROUGE-1: 0.1110\n",
            "Emotion Accuracy: 0.0000\n",
            "Emotion Tag Coverage: 0.9992\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ESCONV THERAPY MODEL EVALUATION RESULTS\n",
            "============================================================\n",
            "Model Type: RL\n",
            "Output Format: STANDARD\n",
            "\n",
            "Text Generation Metrics:\n",
            "  BLEU Score:     0.0042\n",
            "  ROUGE-1:        0.1110\n",
            "  ROUGE-2:        0.0092\n",
            "  ROUGE-L:        0.1002\n",
            "  METEOR:         0.0290\n",
            "\n",
            "Emotion Prediction:\n",
            "  Emotion Accuracy:    0.0000\n",
            "  Emotion Tag Coverage: 0.9992\n",
            "\n",
            "Dataset Info:\n",
            "  Total Samples:  14642\n",
            "\n",
            "Emotion Confusion Matrix:\n",
            "  anxiety:\n",
            "    -> neutral: 3907\n",
            "    -> emotional: 2\n",
            "    -> you're: 14\n",
            "    -> of: 1\n",
            "    -> anger?: 1\n",
            "    -> no_prediction: 4\n",
            "    -> parent?: 1\n",
            "    -> you: 1\n",
            "    -> if: 1\n",
            "    -> anxiety.: 1\n",
            "  anger:\n",
            "    -> neutral: 1255\n",
            "    -> you're: 1\n",
            "    -> anger?: 1\n",
            "  fear:\n",
            "    -> neutral: 1048\n",
            "    -> <therapist_emotion>: 1\n",
            "  depression:\n",
            "    -> neutral: 3816\n",
            "    -> no_prediction: 4\n",
            "    -> cause: 2\n",
            "    -> s?: 1\n",
            "    -> <therapist_emotion>: 1\n",
            "    -> anger.: 1\n",
            "    -> will: 1\n",
            "    -> you: 1\n",
            "    -> neutralscale: 1\n",
            "  sadness:\n",
            "    -> neutral: 3466\n",
            "    -> no_prediction: 3\n",
            "    -> .: 1\n",
            "    -> <therapist_emotion>: 1\n",
            "    -> ?: 1\n",
            "    -> anger.: 1\n",
            "    -> neutralscale20mentsale.: 1\n",
            "    -> anger?: 2\n",
            "  disgust:\n",
            "    -> neutral: 451\n",
            "    -> judiced?: 1\n",
            "    -> anger?: 1\n",
            "  shame:\n",
            "    -> neutral: 461\n",
            "    -> you're: 2\n",
            "    -> clearing: 1\n",
            "    -> emotional: 1\n",
            "    -> shameful?: 2\n",
            "    -> no_prediction: 1\n",
            "  nervousness:\n",
            "    -> neutral: 144\n",
            "    -> you're: 1\n",
            "  pain:\n",
            "    -> neutral: 9\n",
            "  jealousy:\n",
            "    -> neutral: 14\n",
            "  guilt:\n",
            "    -> neutral: 10\n",
            "\n",
            "Sample Outputs:\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "    Reference: Hello, what would you like to talk about?...\n",
            "    Predicted: you're nervous about what you're gonna say to me....\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.029, ROUGE-1: 0.421\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stre...\n",
            "    Reference: What makes your job stressful for you?...\n",
            "    Predicted: you're worried about what you're going to do next month. What do you think about...\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.012, ROUGE-1: 0.160\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is ups...\n",
            "    Reference: Do you help your clients to make it to a better financial situation?...\n",
            "    Predicted: you're anxious?...\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.000, ROUGE-1: 0.125\n",
            "\n",
            "Evaluation completed! Results saved to ESConv_RL_evaluation_results.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFT"
      ],
      "metadata": {
        "id": "0Hbfg0D_Z4Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from datasets import Dataset as HFDataset\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# ====================== Text Cleaning Functions ======================\n",
        "def clean_therapy_text(text):\n",
        "    \"\"\"Remove descriptive text patterns and clean text\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    # Remove newlines and extra whitespace\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# ====================== ESConv Dataset Processing ======================\n",
        "class ESConvEvaluationDataset:\n",
        "    \"\"\"Dataset class for ESConv evaluation data processing\"\"\"\n",
        "\n",
        "    def __init__(self, json_path, tokenizer_path=None):\n",
        "        with open(json_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            if isinstance(data, dict):\n",
        "                self._data = [data]\n",
        "            else:\n",
        "                self._data = data\n",
        "\n",
        "        if tokenizer_path:\n",
        "            self.tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "        else:\n",
        "            # Use default tokenizer if path not provided\n",
        "            from transformers import AutoTokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
        "\n",
        "        self.evaluation_data = []\n",
        "        self._process_esconv_data()\n",
        "\n",
        "    def _process_esconv_data(self):\n",
        "        \"\"\"Process ESConv dialog data for evaluation\"\"\"\n",
        "        print(\"Processing ESConv data...\")\n",
        "\n",
        "        for conv_idx, conv in enumerate(tqdm(self._data, desc=\"Processing conversations\")):\n",
        "            problem_type = conv.get(\"problem_type\", \"\").strip()\n",
        "            emotion_type = conv.get(\"emotion_type\", \"\").strip()\n",
        "            dialog = conv.get(\"dialog\", [])\n",
        "\n",
        "            if not dialog:\n",
        "                continue\n",
        "\n",
        "            if conv_idx < 3:\n",
        "                print(f\"\\nProcessing conversation {conv_idx + 1}:\")\n",
        "                print(f\"  Problem type: {problem_type}\")\n",
        "                print(f\"  Emotion type: {emotion_type}\")\n",
        "                print(f\"  Dialog length: {len(dialog)} turns\")\n",
        "\n",
        "            user_messages = []  # Accumulate user messages\n",
        "\n",
        "            for turn_idx, turn in enumerate(dialog):\n",
        "                speaker = turn.get(\"speaker\", \"\").strip()\n",
        "                content = clean_therapy_text(turn.get(\"content\", \"\"))\n",
        "\n",
        "                if not content:\n",
        "                    continue\n",
        "\n",
        "                if speaker == \"seeker\":\n",
        "                    # Accumulate user (seeker) messages\n",
        "                    user_messages.append(content)\n",
        "\n",
        "                elif speaker == \"supporter\":\n",
        "                    if user_messages:\n",
        "\n",
        "                        # Combine all user messages for this interaction\n",
        "                        combined_user_text = \" \".join(user_messages)\n",
        "                        therapist_response = content\n",
        "\n",
        "                        # Create structured input in the expected format\n",
        "                        input_parts = []\n",
        "                        if problem_type:\n",
        "                            input_parts.append(f\"<problem>{problem_type}\")\n",
        "\n",
        "                        input_parts.append(f\"<user>{combined_user_text}\")\n",
        "\n",
        "                        if emotion_type:\n",
        "                            input_parts.append(f\"<user_emotion>{emotion_type}\")\n",
        "\n",
        "                        input_parts.append(\"<therapist>\")\n",
        "                        input_text = \" \".join(input_parts)\n",
        "\n",
        "                        # Create evaluation sample\n",
        "                        eval_sample = {\n",
        "                            'input_text': input_text,\n",
        "                            'reference_text': therapist_response,\n",
        "                            'reference_emotion': emotion_type,  # Use conversation-level emotion\n",
        "                            'user_input': combined_user_text,\n",
        "                            'user_emotion': emotion_type,\n",
        "                            'problem_type': problem_type,\n",
        "                            'conversation_id': conv_idx,\n",
        "                            'turn_id': turn_idx\n",
        "                        }\n",
        "\n",
        "                        self.evaluation_data.append(eval_sample)\n",
        "\n",
        "                        # Show first few examples\n",
        "                        if len(self.evaluation_data) <= 3:\n",
        "                            print(f\"\\n  Sample {len(self.evaluation_data)}:\")\n",
        "                            print(f\"    Input: {input_text[:100]}...\")\n",
        "                            print(f\"    Reference: {therapist_response[:100]}...\")\n",
        "\n",
        "                        user_messages = []\n",
        "\n",
        "        print(f\"\\nProcessed {len(self.evaluation_data)} evaluation samples from {len(self._data)} conversations\")\n",
        "\n",
        "    def get_evaluation_data(self):\n",
        "        return self.evaluation_data\n",
        "\n",
        "    def print_sample_formats(self, num_samples=3):\n",
        "        \"\"\"Print sample input/output formats for verification\"\"\"\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"ESCONV SAMPLE INPUT/OUTPUT FORMATS\")\n",
        "        print('='*80)\n",
        "\n",
        "        for i, sample in enumerate(self.evaluation_data[:num_samples]):\n",
        "            print(f\"\\nSample {i+1}:\")\n",
        "            print(f\"  Problem Type: {sample['problem_type']}\")\n",
        "            print(f\"  User Emotion: {sample['user_emotion']}\")\n",
        "            print(f\"  Input Format: {sample['input_text'][:150]}...\")\n",
        "            print(f\"  Reference Response: {sample['reference_text'][:100]}...\")\n",
        "            print(f\"  User Input Only: {sample['user_input'][:100]}...\")\n",
        "\n",
        "# ====================== Model Format Detection ======================\n",
        "def detect_model_format(model, tokenizer, device='cuda', test_inputs=None):\n",
        "    \"\"\"\n",
        "    Test model output format (should be consistent since both SFT and RL use same format)\n",
        "\n",
        "    Args:\n",
        "        model: The model to test\n",
        "        tokenizer: Model tokenizer\n",
        "        device: Device to run test on\n",
        "        test_inputs: List of test input strings, uses defaults if None\n",
        "\n",
        "    Returns:\n",
        "        str: 'standard' if using <therapist_emotion> format, 'unknown' otherwise\n",
        "    \"\"\"\n",
        "    if test_inputs is None:\n",
        "        test_inputs = [\n",
        "            \"<problem>anxiety <user>I'm worried about work <user_emotion>anxiety <therapist>\",\n",
        "            \"<problem>depression <user>I feel very sad <user_emotion>sadness <therapist>\",\n",
        "            \"<problem>relationship <user>My partner doesn't understand me <user_emotion>anger <therapist>\"\n",
        "        ]\n",
        "\n",
        "    emotion_tag_count = 0\n",
        "    total_tests = len(test_inputs)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_input in test_inputs:\n",
        "            # Tokenize and generate\n",
        "            input_ids = tokenizer.encode(test_input, return_tensors='pt').to(device)\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=128,\n",
        "                do_sample=True,\n",
        "                top_p=0.6,\n",
        "                top_k=30,\n",
        "                temperature=1.0,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decode response\n",
        "            new_tokens = outputs[0][len(input_ids[0]):]\n",
        "            response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "            # Check for emotion tag\n",
        "            if '<therapist_emotion>' in response:\n",
        "                emotion_tag_count += 1\n",
        "\n",
        "    # Determine format\n",
        "    if emotion_tag_count >= total_tests * 0.5:  # At least 50% have emotion tags\n",
        "        return 'standard'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# ====================== Model Output Extraction ======================\n",
        "def extract_model_output(response):\n",
        "    \"\"\"\n",
        "    Extract therapist text and emotion from model output.\n",
        "    Both SFT and RL models use format: 'text <therapist_emotion> emotion<eos>'\n",
        "\n",
        "    Returns:\n",
        "        therapist_text (str): Text before <therapist_emotion>\n",
        "        emotion (str): Emotion word after <therapist_emotion>\n",
        "        has_emotion_tag (bool): Whether emotion tag was found\n",
        "    \"\"\"\n",
        "    response = response.strip()\n",
        "\n",
        "    # Remove <eos> if present\n",
        "    if response.endswith('<eos>'):\n",
        "        response = response[:-5].strip()\n",
        "\n",
        "    # Find <therapist_emotion> tag\n",
        "    emotion_pattern = r'<therapist_emotion>'\n",
        "    emotion_match = re.search(emotion_pattern, response)\n",
        "\n",
        "    if emotion_match:\n",
        "        # Extract text before <therapist_emotion>\n",
        "        therapist_text = response[:emotion_match.start()].strip()\n",
        "\n",
        "        # Extract emotion part after <therapist_emotion>\n",
        "        emotion_part = response[emotion_match.end():].strip()\n",
        "\n",
        "        # Get the first word as emotion\n",
        "        emotion_words = emotion_part.split()\n",
        "        emotion = emotion_words[0].lower() if emotion_words else \"\"\n",
        "\n",
        "        return therapist_text, emotion, True\n",
        "    else:\n",
        "        return response, \"\", False\n",
        "\n",
        "# ====================== Evaluation Metrics ======================\n",
        "class TherapyEvaluationMetrics:\n",
        "    \"\"\"Class to compute evaluation metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "        self.smoothing = SmoothingFunction().method1\n",
        "\n",
        "    def compute_bleu(self, reference, candidate):\n",
        "        \"\"\"Compute BLEU score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=self.smoothing)\n",
        "\n",
        "    def compute_rouge(self, reference, candidate):\n",
        "        \"\"\"Compute ROUGE scores\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
        "\n",
        "        scores = self.rouge_scorer.score(reference, candidate)\n",
        "        return {\n",
        "            'rouge1': scores['rouge1'].fmeasure,\n",
        "            'rouge2': scores['rouge2'].fmeasure,\n",
        "            'rougeL': scores['rougeL'].fmeasure\n",
        "        }\n",
        "\n",
        "    def compute_meteor(self, reference, candidate):\n",
        "        \"\"\"Compute METEOR score\"\"\"\n",
        "        if not candidate or not reference:\n",
        "            return 0.0\n",
        "\n",
        "        reference_tokens = reference.split()\n",
        "        candidate_tokens = candidate.split()\n",
        "\n",
        "        if len(candidate_tokens) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return meteor_score([reference_tokens], candidate_tokens)\n",
        "\n",
        "# ====================== Model Evaluation ======================\n",
        "def evaluate_model_esconv(model, tokenizer, evaluation_dataset, device='cuda', max_new_tokens=128,\n",
        "                         top_p=0.6, top_k=30, temperature=1.0, do_sample=True):\n",
        "    \"\"\"\n",
        "    Evaluate model on ESConv therapy dataset\n",
        "\n",
        "    Args:\n",
        "        model: Trained model (SFT or RL)\n",
        "        tokenizer: Model tokenizer\n",
        "        evaluation_dataset: ESConvEvaluationDataset instance\n",
        "        device: Device to run evaluation on\n",
        "        max_new_tokens: Maximum tokens to generate\n",
        "        top_p: Top-p sampling parameter\n",
        "        do_sample: Whether to use sampling\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation results\n",
        "    \"\"\"\n",
        "    metrics_computer = TherapyEvaluationMetrics()\n",
        "    evaluation_data = evaluation_dataset.get_evaluation_data()\n",
        "\n",
        "    results = {\n",
        "        'bleu_scores': [],\n",
        "        'rouge1_scores': [],\n",
        "        'rouge2_scores': [],\n",
        "        'rougeL_scores': [],\n",
        "        'meteor_scores': [],\n",
        "        'emotion_accuracy': [],\n",
        "        'has_emotion_tag': [],\n",
        "        'sample_outputs': []\n",
        "    }\n",
        "\n",
        "    emotion_confusion = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Detect model output format\n",
        "    detected_format = detect_model_format(model, tokenizer, device)\n",
        "    print(f\"Output format check: {detected_format.upper()}\")\n",
        "\n",
        "    print(f\"Evaluating model on {len(evaluation_data)} ESConv samples...\")\n",
        "\n",
        "    # Create progress bar with custom format\n",
        "    progress_bar = tqdm(evaluation_data, desc=\"Evaluating ESConv\",\n",
        "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
        "\n",
        "    for i, sample in enumerate(progress_bar):\n",
        "        input_text = sample['input_text']\n",
        "        reference_text = sample['reference_text']\n",
        "        reference_emotion = sample['reference_emotion']\n",
        "\n",
        "        # Tokenize input\n",
        "        input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=do_sample,\n",
        "                top_p=top_p,\n",
        "                top_k=top_k,\n",
        "                temperature=temperature,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode response\n",
        "        new_tokens = outputs[0][len(input_ids[0]):]\n",
        "        response = tokenizer.decode(new_tokens, skip_special_tokens=False).strip()\n",
        "\n",
        "        # Extract model output\n",
        "        predicted_text, predicted_emotion, has_emotion = extract_model_output(response)\n",
        "\n",
        "        # Compute text generation metrics\n",
        "        bleu = metrics_computer.compute_bleu(reference_text, predicted_text)\n",
        "        rouge = metrics_computer.compute_rouge(reference_text, predicted_text)\n",
        "        meteor = metrics_computer.compute_meteor(reference_text, predicted_text)\n",
        "\n",
        "        # Compute emotion accuracy\n",
        "        emotion_correct = (predicted_emotion.lower() == reference_emotion.lower()) if has_emotion else False\n",
        "\n",
        "        # Store results\n",
        "        results['bleu_scores'].append(bleu)\n",
        "        results['rouge1_scores'].append(rouge['rouge1'])\n",
        "        results['rouge2_scores'].append(rouge['rouge2'])\n",
        "        results['rougeL_scores'].append(rouge['rougeL'])\n",
        "        results['meteor_scores'].append(meteor)\n",
        "        results['emotion_accuracy'].append(emotion_correct)\n",
        "        results['has_emotion_tag'].append(has_emotion)\n",
        "\n",
        "        # Update confusion matrix\n",
        "        if has_emotion:\n",
        "            emotion_confusion[reference_emotion.lower()][predicted_emotion.lower()] += 1\n",
        "        else:\n",
        "            emotion_confusion[reference_emotion.lower()]['no_prediction'] += 1\n",
        "\n",
        "        # Store sample outputs for inspection\n",
        "        if i < 10:  # Store first 10 samples\n",
        "            results['sample_outputs'].append({\n",
        "                'input': input_text,\n",
        "                'reference_text': reference_text,\n",
        "                'predicted_text': predicted_text,\n",
        "                'reference_emotion': reference_emotion,\n",
        "                'predicted_emotion': predicted_emotion,\n",
        "                'full_response': response,\n",
        "                'bleu': bleu,\n",
        "                'rouge1': rouge['rouge1'],\n",
        "                'meteor': meteor\n",
        "            })\n",
        "\n",
        "        if (i + 1) % 20 == 0 or i < 5:\n",
        "            sample_info = f\"Sample {i+1}: BLEU={bleu:.3f}, Emotion={'✓' if emotion_correct else '✗'}\"\n",
        "            progress_bar.set_description(f\"Evaluating ESConv - {sample_info}\")\n",
        "\n",
        "            if (i + 1) % 50 == 0 or i < 3:\n",
        "                print(f\"\\n\" + \"=\"*80)\n",
        "                print(f\"ESCONV LIVE SAMPLE {i+1}/{len(evaluation_data)}\")\n",
        "                print(\"=\"*80)\n",
        "                print(f\"Input: {input_text[:120]}...\")\n",
        "                print(f\"Reference: {reference_text[:100]}...\")\n",
        "                print(f\"Generated: {predicted_text[:100]}...\")\n",
        "                print(f\"Full Response: {response[:150]}...\")\n",
        "                print(f\"Ref Emotion: {reference_emotion} | Pred Emotion: {predicted_emotion} | Match: {'✓' if emotion_correct else '✗'}\")\n",
        "                print(f\"BLEU: {bleu:.4f} | ROUGE-1: {rouge['rouge1']:.4f} | METEOR: {meteor:.4f}\")\n",
        "                print(\"=\"*80)\n",
        "        else:\n",
        "            # Just update progress bar with running averages\n",
        "            if i > 0:\n",
        "                avg_bleu = np.mean(results['bleu_scores'])\n",
        "                avg_emotion_acc = np.mean(results['emotion_accuracy'])\n",
        "                progress_bar.set_description(f\"Evaluating ESConv - Avg BLEU: {avg_bleu:.3f}, Emotion Acc: {avg_emotion_acc:.3f}\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Compute summary statistics\n",
        "    results['summary'] = {\n",
        "        'avg_bleu': np.mean(results['bleu_scores']),\n",
        "        'avg_rouge1': np.mean(results['rouge1_scores']),\n",
        "        'avg_rouge2': np.mean(results['rouge2_scores']),\n",
        "        'avg_rougeL': np.mean(results['rougeL_scores']),\n",
        "        'avg_meteor': np.mean(results['meteor_scores']),\n",
        "        'emotion_accuracy': np.mean(results['emotion_accuracy']),\n",
        "        'emotion_tag_coverage': np.mean(results['has_emotion_tag']),\n",
        "        'total_samples': len(evaluation_data)\n",
        "    }\n",
        "\n",
        "    results['emotion_confusion_matrix'] = dict(emotion_confusion)\n",
        "    results['detected_format'] = detected_format\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ESCONV EVALUATION COMPLETED!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Processed {len(evaluation_data)} samples\")\n",
        "    print(f\"Average BLEU: {results['summary']['avg_bleu']:.4f}\")\n",
        "    print(f\"Average ROUGE-1: {results['summary']['avg_rouge1']:.4f}\")\n",
        "    print(f\"Emotion Accuracy: {results['summary']['emotion_accuracy']:.4f}\")\n",
        "    print(f\"Emotion Tag Coverage: {results['summary']['emotion_tag_coverage']:.4f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_evaluation_results(results):\n",
        "    \"\"\"Print formatted evaluation results\"\"\"\n",
        "    summary = results['summary']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ESCONV THERAPY MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Model Type: {results.get('model_type', 'Unknown').upper()}\")\n",
        "    print(f\"Output Format: {results.get('detected_format', 'Unknown').upper()}\")\n",
        "\n",
        "    print(f\"\\nText Generation Metrics:\")\n",
        "    print(f\"  BLEU Score:     {summary['avg_bleu']:.4f}\")\n",
        "    print(f\"  ROUGE-1:        {summary['avg_rouge1']:.4f}\")\n",
        "    print(f\"  ROUGE-2:        {summary['avg_rouge2']:.4f}\")\n",
        "    print(f\"  ROUGE-L:        {summary['avg_rougeL']:.4f}\")\n",
        "    print(f\"  METEOR:         {summary['avg_meteor']:.4f}\")\n",
        "\n",
        "    print(f\"\\nEmotion Prediction:\")\n",
        "    print(f\"  Emotion Accuracy:    {summary['emotion_accuracy']:.4f}\")\n",
        "    print(f\"  Emotion Tag Coverage: {summary['emotion_tag_coverage']:.4f}\")\n",
        "\n",
        "    print(f\"\\nDataset Info:\")\n",
        "    print(f\"  Total Samples:  {summary['total_samples']}\")\n",
        "\n",
        "    # Print emotion confusion matrix\n",
        "    if 'emotion_confusion_matrix' in results:\n",
        "        print(f\"\\nEmotion Confusion Matrix:\")\n",
        "        confusion = results['emotion_confusion_matrix']\n",
        "        for ref_emotion, pred_dict in confusion.items():\n",
        "            print(f\"  {ref_emotion}:\")\n",
        "            for pred_emotion, count in pred_dict.items():\n",
        "                print(f\"    -> {pred_emotion}: {count}\")\n",
        "\n",
        "    print(f\"\\nSample Outputs:\")\n",
        "    for i, sample in enumerate(results['sample_outputs'][:3], 1):\n",
        "        print(f\"\\n  Sample {i}:\")\n",
        "        print(f\"    Input: {sample['input'][:100]}...\")\n",
        "        print(f\"    Reference: {sample['reference_text'][:80]}...\")\n",
        "        print(f\"    Predicted: {sample['predicted_text'][:80]}...\")\n",
        "        print(f\"    Ref Emotion: {sample['reference_emotion']}\")\n",
        "        print(f\"    Pred Emotion: {sample['predicted_emotion']}\")\n",
        "        print(f\"    BLEU: {sample['bleu']:.3f}, ROUGE-1: {sample['rouge1']:.3f}\")\n",
        "\n",
        "# ====================== Model Loading Functions ======================\n",
        "def load_sft_model(checkpoint_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load SFT model from checkpoint file\"\"\"\n",
        "    from transformers import GPT2LMHeadModel\n",
        "\n",
        "    print(f\"Loading SFT checkpoint: {checkpoint_path}\")\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    if 'epoch' in checkpoint:\n",
        "        print(f\"Checkpoint info: Epoch {checkpoint['epoch']}, Loss {checkpoint.get('valid_loss', 'N/A')}\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_rl_model(model_dir, tokenizer_path, device='cuda'):\n",
        "    \"\"\"Load RL model from directory\"\"\"\n",
        "    from transformers import AutoModelForCausalLM\n",
        "\n",
        "    print(f\"Loading RL model from directory: {model_dir}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load model from directory\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def load_model_auto(model_path, tokenizer_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Automatically detect and load model (SFT checkpoint or RL directory)\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        device: Device to load model on\n",
        "\n",
        "    Returns:\n",
        "        tuple: (model, tokenizer, model_type)\n",
        "    \"\"\"\n",
        "    import os\n",
        "\n",
        "    if os.path.isfile(model_path):\n",
        "        print(\"Detected SFT checkpoint file\")\n",
        "        model, tokenizer = load_sft_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'sft'\n",
        "\n",
        "    elif os.path.isdir(model_path):\n",
        "        print(\"Detected RL model directory\")\n",
        "        model, tokenizer = load_rl_model(model_path, tokenizer_path, device)\n",
        "        return model, tokenizer, 'rl'\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Model path {model_path} is neither a file nor a directory\")\n",
        "\n",
        "# ====================== Main Evaluation Function ======================\n",
        "def run_esconv_evaluation(model_path, tokenizer_path, esconv_data_path, device='cuda'):\n",
        "    \"\"\"\n",
        "    Run complete evaluation pipeline on ESConv data\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to trained model (file for SFT, directory for RL)\n",
        "        tokenizer_path: Path to tokenizer\n",
        "        esconv_data_path: Path to ESConv JSON data\n",
        "        device: Device to run evaluation on\n",
        "    \"\"\"\n",
        "\n",
        "    # Load model and tokenizer (auto-detect type)\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model, tokenizer, model_type = load_model_auto(model_path, tokenizer_path, device)\n",
        "    print(f\"Loaded {model_type.upper()} model successfully\")\n",
        "\n",
        "    # Load ESConv evaluation dataset\n",
        "    print(f\"Loading ESConv evaluation data from {esconv_data_path}...\")\n",
        "    eval_dataset = ESConvEvaluationDataset(esconv_data_path, tokenizer_path)\n",
        "\n",
        "    eval_dataset.print_sample_formats(3)\n",
        "\n",
        "    results = evaluate_model_esconv(model, tokenizer, eval_dataset, device=device)\n",
        "    results['model_type'] = model_type\n",
        "    results['dataset_type'] = 'esconv'\n",
        "\n",
        "    print_evaluation_results(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ====================== Usage Example ======================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    MODEL_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\"\n",
        "    TOKENIZER_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/train_processed_4thFIXED_tokenizer\"\n",
        "    ESCONV_DATA_PATH = \"/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/PESConv.json\"  # Update this path to your ESConv data\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    results = run_esconv_evaluation(MODEL_PATH, TOKENIZER_PATH, ESCONV_DATA_PATH, DEVICE)\n",
        "\n",
        "    import pickle\n",
        "    with open('/content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/Evaluation2/ESConv_SFT_evaluation_results.pkl', 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "    print(\"\\nEvaluation completed! Results saved to ESConv_RL_evaluation_results.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDQOdRJXt5tc",
        "outputId": "afa439e6-e174-48d5-85dd-8935deb4ebc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt...\n",
            "Detected SFT checkpoint file\n",
            "Loading SFT checkpoint: /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/therapy_model_4thFIXED_epoch_7_loss_2.2373.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint info: Epoch 7, Loss 2.237253785133362\n",
            "Loaded SFT model successfully\n",
            "Loading ESConv evaluation data from /content/drive/MyDrive/RL-SFT-GPT2 MentalHealth/RL<token>8 6/PESConv.json...\n",
            "Processing ESConv data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing conversations:  28%|██▊       | 370/1300 [00:00<00:00, 3696.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing conversation 1:\n",
            "  Problem type: job crisis\n",
            "  Emotion type: anxiety\n",
            "  Dialog length: 27 turns\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "    Reference: Hello, what would you like to talk about?...\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stre...\n",
            "    Reference: What makes your job stressful for you?...\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is ups...\n",
            "    Reference: Do you help your clients to make it to a better financial situation?...\n",
            "\n",
            "Processing conversation 2:\n",
            "  Problem type: problems with friends\n",
            "  Emotion type: anger\n",
            "  Dialog length: 69 turns\n",
            "\n",
            "Processing conversation 3:\n",
            "  Problem type: job crisis\n",
            "  Emotion type: fear\n",
            "  Dialog length: 37 turns\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing conversations: 100%|██████████| 1300/1300 [00:00<00:00, 3745.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processed 14642 evaluation samples from 1300 conversations\n",
            "\n",
            "================================================================================\n",
            "ESCONV SAMPLE INPUT/OUTPUT FORMATS\n",
            "================================================================================\n",
            "\n",
            "Sample 1:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "  Reference Response: Hello, what would you like to talk about?...\n",
            "  User Input Only: Hello...\n",
            "\n",
            "Sample 2:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stressful but pays well <user_emotion>anxiety <therapi...\n",
            "  Reference Response: What makes your job stressful for you?...\n",
            "  User Input Only: I am having a lot of anxiety about quitting my current job. It is too stressful but pays well...\n",
            "\n",
            "Sample 3:\n",
            "  Problem Type: job crisis\n",
            "  User Emotion: anxiety\n",
            "  Input Format: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is upsetting <user_emotion>anxiety <therapist>...\n",
            "  Reference Response: Do you help your clients to make it to a better financial situation?...\n",
            "  User Input Only: I have to deal with many people in hard financial situations and it is upsetting...\n",
            "Output format check: STANDARD\n",
            "Evaluating model on 14642 ESConv samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 2: BLEU=0.000, Emotion=✗:   0%|          | 2/14642 [00:00<35:58,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "Reference: Hello, what would you like to talk about?...\n",
            "Generated: I'm sorry. I just wanted to let you know that you're not worried....\n",
            "Full Response: I'm sorry. I just wanted to let you know that you're not worried. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0185 | ROUGE-1: 0.1739 | METEOR: 0.1176\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stressful but pays well ...\n",
            "Reference: What makes your job stressful for you?...\n",
            "Generated: You have to live with it....\n",
            "Full Response: You have to live with it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1538 | METEOR: 0.0725\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 4: BLEU=0.000, Emotion=✗:   0%|          | 3/14642 [00:00<46:31,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is upsetting <user_emotion...\n",
            "Reference: Do you help your clients to make it to a better financial situation?...\n",
            "Generated: you can't control your emotions, you can control your emotions...\n",
            "Full Response: you can't control your emotions, you can control your emotions  <therapist_emotion> but it's not your fault. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: but | Match: ✗\n",
            "BLEU: 0.0186 | ROUGE-1: 0.1667 | METEOR: 0.0787\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 100: BLEU=0.000, Emotion=✗:   1%|          | 100/14642 [00:13<32:33,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>sorry about that, but that's good, people help each other Absolutely! Volunteering is a great ...\n",
            "Reference: Do you feel you will be getting the vaccine when it is rolled out where you are?...\n",
            "Generated: but......\n",
            "Full Response: but...  <therapist_emotion> what do you mean, what do you mean? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: what | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.025:   1%|▏         | 200/14642 [00:26<23:48, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes, I really think you are correct! thank you so very much for your help today! <user_emotion...\n",
            "Reference: The survivor rate from COVID-19 infections is around 99%, so your chances of dying from the virus ar...\n",
            "Generated: Thank you....\n",
            "Full Response: Thank you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.023:   2%|▏         | 301/14642 [00:39<25:38,  9.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 300/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No I think I'm good <user_emotion>depression <therapist>...\n",
            "Reference: Please click \"Finish and Quit\" to close the chat.. thank you....\n",
            "Generated: So what does that mean?...\n",
            "Full Response: So what does that mean? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.017:   3%|▎         | 400/14642 [00:50<20:42, 11.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>i will have to find somewhere i can properly exercise my awful vocals lol <user_emot...\n",
            "Reference: Ah! I like pop songs from the 60's :-)...\n",
            "Generated: What?...\n",
            "Full Response: What? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.016:   3%|▎         | 500/14642 [01:03<32:02,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 500/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>yes , you prediction was so good <user_emotion>sadness <therapist>...\n",
            "Reference: That's lovely to hear. Have you tried discussing your doubts with your supervisor? There are times w...\n",
            "Generated: I'm not sure you can do it again....\n",
            "Full Response: I'm not sure you can do it again. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0007 | ROUGE-1: 0.0833 | METEOR: 0.0147\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.004, Emotion Acc: 0.013:   4%|▍         | 601/14642 [01:16<25:40,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Merry Chirstmas. <user_emotion>anxiety <therapist>...\n",
            "Reference: I'm doing good!...\n",
            "Generated: I think you're having trouble sleeping....\n",
            "Full Response: I think you're having trouble sleeping. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1818 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:   5%|▍         | 702/14642 [01:28<23:08, 10.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>We are looking at other options via business visa but we don't know how that will go <...\n",
            "Reference: if you are an American, you can just go to Indonesia, get married to your beautiful fiancée and come...\n",
            "Generated: So what do you think is the best route to go?...\n",
            "Full Response: So what do you think is the best route to go? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0075 | ROUGE-1: 0.1714 | METEOR: 0.0917\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.019:   5%|▌         | 801/14642 [01:41<33:54,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Bye Have a Good Day Some Report preparation <user_emotion>anger <therapist>...\n",
            "Reference: Have an amazing Christmas!...\n",
            "Generated: I'm sorry. I just... I don't know....\n",
            "Full Response: I'm sorry. I just... I don't know. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.018:   6%|▌         | 901/14642 [01:53<28:41,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That actually sounds like a good idea. I hope the shelter near me will take volunteers...\n",
            "Reference: If you are not comfortable going out due to COVID, you could involve some activities online promotin...\n",
            "Generated: And how would you like them to go about packing up?...\n",
            "Full Response: And how would you like them to go about packing up? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0052 | ROUGE-1: 0.2105 | METEOR: 0.0984\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 1000: BLEU=0.000, Emotion=✗:   7%|▋         | 999/14642 [02:06<25:03,  9.08it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I'll keep that in mind as I move forward. I really appreciate your help. <user_emotion>...\n",
            "Reference: I commend you for doing the thesis and I also know it can get weary as time passes, but with some go...\n",
            "Generated: I appreciate your help....\n",
            "Full Response: I appreciate your help. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0465 | METEOR: 0.0141\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.015:   8%|▊         | 1101/14642 [02:18<32:58,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>With him... he was perfect (or at least I thought), but also, I'm lonely, and it's h...\n",
            "Reference: Have you tried making other connections online? A lot of people are home during this pandemic, you m...\n",
            "Generated: It's hard to process that you're in such a state?...\n",
            "Full Response: It's hard to process that you're in such a state? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1176 | METEOR: 0.0240\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 1200: BLEU=0.000, Emotion=✗:   8%|▊         | 1200/14642 [02:29<28:43,  7.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i usually try to follow the tutorials and do revisions <user_emotion>anxiety <therapist...\n",
            "Reference: Can you think of anything you can do, to help make your studying be more successful?...\n",
            "Generated: but you've been doing that for a while now....\n",
            "Full Response: but you've been doing that for a while now. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1538 | METEOR: 0.0654\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.015:   9%|▉         | 1300/14642 [02:43<24:38,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>And to you You doing alright? <user_emotion>anxiety <therapist>...\n",
            "Reference: How are you today? I am buried in cookie dough, lol, but happy and wwell....\n",
            "Generated: I think that's true....\n",
            "Full Response: I think that's true. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0051 | ROUGE-1: 0.1000 | METEOR: 0.0360\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.014:  10%|▉         | 1401/14642 [02:56<25:06,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Well, counselors are hard to get ahold of so close to the Holidays. The so-called teach...\n",
            "Reference: Are you confident in your abilities to succeed in those classes or you think you might lack the mate...\n",
            "Generated: I know....\n",
            "Full Response: I know. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.015:  10%|█         | 1501/14642 [03:10<29:42,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1500/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I am having a hard time.... Ok, I will look some of them online. I need some financial planner...\n",
            "Reference: If you want other suggestions, meditation is something that is extremely overlooked and will help yo...\n",
            "Generated: So you think that you are struggling,...\n",
            "Full Response: So you think that you are struggling, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.1053 | METEOR: 0.0328\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.014:  11%|█         | 1601/14642 [03:23<25:29,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1600/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>no other questions, you have been most helpful, thank you! <user_emotion>anxiety <t...\n",
            "Reference: I have done volunteer work; people want to be friends with those who care and know how to use a nail...\n",
            "Generated: I appreciate it....\n",
            "Full Response: I appreciate it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.0769 | METEOR: 0.0228\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.014:  12%|█▏        | 1701/14642 [03:35<31:32,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I feel like a replaceable cog in a giant machine that doesn't give two shits whether I show up...\n",
            "Reference: you are doing your best and are working really hard...\n",
            "Generated: So I think you're not really retired,...\n",
            "Full Response: So I think you're not really retired, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0215 | ROUGE-1: 0.2222 | METEOR: 0.0515\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.014:  12%|█▏        | 1801/14642 [03:48<24:23,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Do you smoke and drink alcohol? <user_emotion>depression <therapist>...\n",
            "Reference: No, I don't find that to be healthy, and I don't enjoy them....\n",
            "Generated: No, I don't....\n",
            "Full Response: No, I don't. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0086 | ROUGE-1: 0.4211 | METEOR: 0.0833\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.013:  13%|█▎        | 1901/14642 [04:00<30:33,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 1900/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I think so? I think it is just the way the material is taught now. We have these \"Zoom\"...\n",
            "Reference: What happened when you reached out to the teacher?...\n",
            "Generated: I'm sure that you feel that you're losing your passion....\n",
            "Full Response: I'm sure that you feel that you're losing your passion. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0211 | ROUGE-1: 0.0952 | METEOR: 0.0549\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.013:  14%|█▎        | 2001/14642 [04:12<21:15,  9.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Well thank you im okay <user_emotion>depression <therapist>...\n",
            "Reference: Hmm all the best...\n",
            "Generated: I'm fine....\n",
            "Full Response: I'm fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.013:  14%|█▍        | 2102/14642 [04:26<24:36,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hmm, I didn't know that. I'm on a waiting list for a therapist through my medical insu...\n",
            "Reference: That is a good idea, especially at this time when it's probably not a good idea to see too many new ...\n",
            "Generated: I think it's possible that you might be able to get a therapist who is......\n",
            "Full Response: I think it's possible that you might be able to get a therapist who is... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0060 | ROUGE-1: 0.2857 | METEOR: 0.0825\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  15%|█▌        | 2200/14642 [04:38<21:04,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2200/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>hi <user_emotion>anxiety <therapist>...\n",
            "Reference: Hello....\n",
            "Generated: you know,...\n",
            "Full Response: you know, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  16%|█▌        | 2301/14642 [04:51<25:45,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>did she start off doing that or was she employed by another company <user_emotion>fear <therap...\n",
            "Reference: She has over 100 companies that are hiring...\n",
            "Generated: you said that she was not employed by another company?...\n",
            "Full Response: you said that she was not employed by another company? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0211 | ROUGE-1: 0.3333 | METEOR: 0.1829\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  16%|█▋        | 2400/14642 [05:04<20:41,  9.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I try to find a job but there is not many <user_emotion>anxiety <therapist>...\n",
            "Reference: I am sorry to hear that. How long have you been looking?...\n",
            "Generated: no one is here to help you....\n",
            "Full Response: no one is here to help you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0162 | ROUGE-1: 0.2105 | METEOR: 0.0870\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  17%|█▋        | 2502/14642 [05:15<20:35,  9.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>my dog was 13 years old. she was very close to me. i had her when she was a puppy <u...\n",
            "Reference: The dog then lived a very happy and fulfilling life from what I can tell. Dogs are among the best co...\n",
            "Generated: So you had a very close relationship with her when she was a puppy....\n",
            "Full Response: So you had a very close relationship with her when she was a puppy. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0148 | ROUGE-1: 0.1053 | METEOR: 0.0652\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 2600: BLEU=0.000, Emotion=✗:  18%|█▊        | 2600/14642 [05:27<23:19,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2600/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Friends not being there for me when I need emotional support. They also do not pay ...\n",
            "Reference: So just to make sure I understand, you are having issues with your friends not being there for you e...\n",
            "Generated: So why don't you ask them?...\n",
            "Full Response: So why don't you ask them? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0005 | ROUGE-1: 0.1463 | METEOR: 0.0481\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  18%|█▊        | 2701/14642 [05:40<24:17,  8.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That's a very optimistic view... <user_emotion>sadness <therapist>...\n",
            "Reference: Like I said, I used to be sad too and not optimistic. But now I am optimistic because I know what it...\n",
            "Generated: It's not....\n",
            "Full Response: It's not. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0889 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  19%|█▉        | 2802/14642 [05:53<21:51,  9.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I just lost interest. I'm losing interest in everything, man I think it's time for my ...\n",
            "Reference: I certainly hope you don't do that!...\n",
            "Generated: That's not what I'm saying....\n",
            "Full Response: That's not what I'm saying. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2667 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  20%|█▉        | 2901/14642 [06:06<36:07,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 2900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>yes, thanks a lot for your time <user_emotion>anger <therapist>...\n",
            "Reference: You are welcome. I hope you don't give up, and stay optimistic! It sounds like you have a great star...\n",
            "Generated: I'm just wondering if you're aware of what's going on with your family...\n",
            "Full Response: I'm just wondering if you're aware of what's going on with your family  <therapist_emotion> anger <therapist_emotion> Well, I've spoken to your mother...\n",
            "Ref Emotion: anger | Pred Emotion: anger | Match: ✓\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1081 | METEOR: 0.0259\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  21%|██        | 3002/14642 [06:20<20:49,  9.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3000/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>that will be hard because i am soo used to her being around <user_emotion>sadness <t...\n",
            "Reference: I can understand that but the only way you can work it out with her if both of you two just talk...\n",
            "Generated: And what do you think she's going to do with that?...\n",
            "Full Response: And what do you think she's going to do with that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0082 | ROUGE-1: 0.1765 | METEOR: 0.0718\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  21%|██        | 3101/14642 [06:32<16:49, 11.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hi, I am doing ok, how are you? <user_emotion>fear <therapist>...\n",
            "Reference: Good thank you. Why only ok? What is bothering you?...\n",
            "Generated: Good....\n",
            "Full Response: Good.  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1818 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.012:  22%|██▏       | 3201/14642 [06:44<28:23,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>ohh 1 wow, I will definitely try that. It sounds like you're a doctor!\" Whenever I get tense o...\n",
            "Reference: Thank you that is very kind of you to say. I have just had alot of practice in dealing with anxiety....\n",
            "Generated: You're just... I'm not sure I know what you mean....\n",
            "Full Response: You're just... I'm not sure I know what you mean. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0005 | ROUGE-1: 0.1639 | METEOR: 0.0222\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  23%|██▎       | 3301/14642 [06:57<29:29,  6.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i was mad, but now i am just upset. My professor put in grades for my class earlier thi...\n",
            "Reference: Just to make sure I understand, you got a bad grade in one of your classes and your grade dropped be...\n",
            "Generated: Why did you drop out?...\n",
            "Full Response: Why did you drop out? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0004 | ROUGE-1: 0.1176 | METEOR: 0.0564\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  23%|██▎       | 3402/14642 [07:11<22:25,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3400/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Hello. <user_emotion>sadness <therapist>...\n",
            "Reference: Hello...\n",
            "Generated: So what's your reaction when I ask you about this?...\n",
            "Full Response: So what's your reaction when I ask you about this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.011:  24%|██▍       | 3501/14642 [07:23<27:09,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hi <user_emotion>shame <therapist>...\n",
            "Reference: Hello...\n",
            "Generated: I'm sorry. I just... I'm not sure I understand what you're trying to say....\n",
            "Full Response: I'm sorry. I just... I'm not sure I understand what you're trying to say. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  25%|██▍       | 3601/14642 [07:37<21:42,  8.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>you are so nice. i lost my job and having trouble finding a new on one <user_emotion>anxiety <...\n",
            "Reference: Oh, I'm so sorry. I can empathize a bit. I lost mine earlier this year due to covid, but they did br...\n",
            "Generated: what?...\n",
            "Full Response: what? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  25%|██▌       | 3701/14642 [07:49<22:02,  8.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I have sold wreaths for awhile but I did not have time to be as serious so I did not sell a to...\n",
            "Reference: That sounds like an excellent idea to me! I think that you are definitely doing the right thing....\n",
            "Generated: You seem to have a lot of energy....\n",
            "Full Response: You seem to have a lot of energy. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0080 | ROUGE-1: 0.1538 | METEOR: 0.0588\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  26%|██▌       | 3801/14642 [08:01<19:20,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3800/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>We have gotten him tutors in the past and it helps. I am not sure I could do a tutor wi...\n",
            "Reference: you are right. Have you tried helping him with his work?...\n",
            "Generated: What is anxiety?...\n",
            "Full Response: What is anxiety? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  27%|██▋       | 3901/14642 [08:14<20:25,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 3900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>oh, i dont use it much <user_emotion>depression <therapist>...\n",
            "Reference: There is also proofreading that can help establish yourself...\n",
            "Generated: I think you have to stop using it....\n",
            "Full Response: I think you have to stop using it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  27%|██▋       | 4002/14642 [08:26<18:37,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Garbo hates small animals also. Especially skunks <user_emotion>anxiety <therapist>...\n",
            "Reference: Oh Garbo! Hahahaha! She sounds wonderful!...\n",
            "Generated: Why don't you tell me what...\n",
            "Full Response: Why don't you tell me what  <therapist_emotion> <therapist_emotion> anger <therapist_emotion> <therapist_emotion> <therapist_emotion> <therapist_emoti...\n",
            "Ref Emotion: anxiety | Pred Emotion: <therapist_emotion> | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  28%|██▊       | 4101/14642 [08:38<20:34,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>so sorry i had stepped away <user_emotion>sadness <therapist>...\n",
            "Reference: I have been having a bit of a bad time in life lately so I can understand and empathise if you are t...\n",
            "Generated: You didn't have a choice....\n",
            "Full Response: You didn't have a choice. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0017 | ROUGE-1: 0.2069 | METEOR: 0.0708\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  29%|██▊       | 4202/14642 [08:51<21:40,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4200/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>haha YES! see it is a stupid thing. like dood we hook your ass up all the tome time...\n",
            "Reference: People suck....\n",
            "Generated: So what do you think...\n",
            "Full Response: So what do you think  <therapist_emotion> <therapist_emotion> <therapist_emotion> I think it is  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: <therapist_emotion> | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  29%|██▉       | 4301/14642 [09:02<22:12,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yes, I am feeling very anxious about my school work lately. <user_emotion>anxiety <ther...\n",
            "Reference: I see, so your main worry is about academic pressure?...\n",
            "Generated: It's not like I'm anxious about anything....\n",
            "Full Response: It's not like I'm anxious about anything. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0215 | ROUGE-1: 0.2105 | METEOR: 0.0515\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  30%|███       | 4401/14642 [09:15<21:15,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>It was a political game where she isolated the president and made him no longer support her. I...\n",
            "Reference: ok so your director played a game she was not allowed to play and she got caught playing it and quit...\n",
            "Generated: You think that's why you left?...\n",
            "Full Response: You think that's why you left? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0606 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  31%|███       | 4501/14642 [09:27<20:02,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>What are those? I heard of them, but never used them. Most of my old friends are no ...\n",
            "Reference: Social networks online, you can connect with family or old coworkers. And post pictures and see what...\n",
            "Generated: What do you mean?...\n",
            "Full Response: What do you mean? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0005 | ROUGE-1: 0.2143 | METEOR: 0.0682\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  31%|███▏      | 4601/14642 [09:40<16:22, 10.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No, since too much time has passed <user_emotion>sadness <therapist>...\n",
            "Reference: Have you tried any local churches or agencies? findhelp.org is also a great resource....\n",
            "Generated: we haven't been sleeping....\n",
            "Full Response: we haven't been sleeping. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  32%|███▏      | 4702/14642 [09:52<17:18,  9.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4700/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>That makes sense but I just wish I knew why she said it. Did I do something to her,...\n",
            "Reference: maybe you should let her know that you love her and say that you would never want to hurt her, so if...\n",
            "Generated: I don't think so....\n",
            "Full Response: I don't think so. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0408 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  33%|███▎      | 4801/14642 [10:05<19:59,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>well, it was weird that he got so dressed up to go hang out with friends it makes se...\n",
            "Reference: Ok, so this is a HUGE red flag to you. You can ignore it, or not. Women KNOW when a man is cheating,...\n",
            "Generated: He was dressed up for a photoshoot?...\n",
            "Full Response: He was dressed up for a photoshoot? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0002 | ROUGE-1: 0.0784 | METEOR: 0.0248\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  33%|███▎      | 4901/14642 [10:19<26:46,  6.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 4900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>i'm withdrawing from the work and that's bad. i still care about the work, but the toxic envir...\n",
            "Reference: maybe seek out someone more senior in a different department who can help...\n",
            "Generated: anger?...\n",
            "Full Response: anger?  <therapist_emotion> Well, that's true. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: well, | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  34%|███▍      | 5001/14642 [10:32<17:49,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>How are you doing today? <user_emotion>anxiety <therapist>...\n",
            "Reference: I am doing well and how are you feeling today?...\n",
            "Generated: Well, I'm fine....\n",
            "Full Response: Well, I'm fine. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2857 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  35%|███▍      | 5101/14642 [10:45<18:11,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes. <user_emotion>fear <therapist>...\n",
            "Reference: I can understand how that feels. Have you tried to talk to them about it?...\n",
            "Generated: But you're a musician....\n",
            "Full Response: But you're a musician. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  36%|███▌      | 5201/14642 [10:58<19:14,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Hello! Life is treating me fair, what about you? <user_emotion>anxiety <therapist>...\n",
            "Reference: Well, I've been a bit worried this year due to Covid and everything. Have you been worrying about an...\n",
            "Generated: You're not angry, I'm just......\n",
            "Full Response: You're not angry, I'm just... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1481 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  36%|███▌      | 5301/14642 [11:11<19:40,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I agree. She can't see past her own issues to see the whole situation. <user_emotio...\n",
            "Reference: If you think its a more serious problem maybe ask her to seek professional help....\n",
            "Generated: So you're trying to justify yourself...\n",
            "Full Response: So you're trying to justify yourself  <therapist_emotion> anger<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: anger | Match: ✓\n",
            "BLEU: 0.0091 | ROUGE-1: 0.1818 | METEOR: 0.0355\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  37%|███▋      | 5401/14642 [11:24<20:58,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Things have been pretty rough for the last few years. I found out she was hanging ou...\n",
            "Reference: So from what I am hearing, you ended things with your girlfriend because she was talking to her ex a...\n",
            "Generated: You know what else?...\n",
            "Full Response: You know what else?  <therapist_emotion> <therapist_emotion> She's upset about it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: <therapist_emotion> | Match: ✗\n",
            "BLEU: 0.0001 | ROUGE-1: 0.1111 | METEOR: 0.0342\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  38%|███▊      | 5502/14642 [11:38<16:39,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>His latest obsession has been 3d printing. I have found weird sites with ' funny'' d...\n",
            "Reference: goodness...\n",
            "Generated: You're not suggesting that he's attracted to women....\n",
            "Full Response: You're not suggesting that he's attracted to women. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  38%|███▊      | 5600/14642 [11:51<20:59,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5600/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I enjoy snowboarding as a hobby. I might try to get back on my board depending on wh...\n",
            "Reference: Yes. when you are depressed it is hard to become motivated to do anything. However, it is extremely ...\n",
            "Generated: I don't think that's necessarily a problem....\n",
            "Full Response: I don't think that's necessarily a problem. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0471 | METEOR: 0.0072\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  39%|███▉      | 5701/14642 [12:03<17:07,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>i am depressed <user_emotion>depression <therapist>...\n",
            "Reference: I'm sorry to hear that! When did you begin feeling this way?...\n",
            "Generated: You've been depressed?...\n",
            "Full Response: You've been depressed? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1176 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  40%|███▉      | 5802/14642 [12:16<14:11, 10.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I will follow your suggestion. Thanks a lot. <user_emotion>sadness <therapist>...\n",
            "Reference: You are so welcome! I hope you start to feel better soon....\n",
            "Generated: I'm glad you're here....\n",
            "Full Response: I'm glad you're here. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2222 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  40%|████      | 5901/14642 [12:29<23:02,  6.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 5900/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I appreciate your help! I'll try to have a productive conversation with her soon. <...\n",
            "Reference: Great, the sooner the better. I have a feeling you'll both be relieved when you do....\n",
            "Generated: I'm sorry, Mia, I didn't mean to offend you....\n",
            "Full Response: I'm sorry, Mia, I didn't mean to offend you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0110 | ROUGE-1: 0.1429 | METEOR: 0.0327\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  41%|████      | 6001/14642 [12:42<16:34,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I've been felling quite deppressed recently, just wanted to ask for some mental suppor...\n",
            "Reference: why are you feeling in that way? tell me what it's happening?...\n",
            "Generated: Do you know how long ago you started falling?...\n",
            "Full Response: Do you know how long ago you started falling? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0172 | ROUGE-1: 0.0909 | METEOR: 0.0427\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 6100: BLEU=0.000, Emotion=✗:  42%|████▏     | 6100/14642 [12:53<16:33,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>It's just me and my small family. I was at college but moved home a few weeks ago. At ...\n",
            "Reference: I have heard that is the norm among colleges. That has to be really tough. So much of college is in ...\n",
            "Generated: So it's not that you don't like it....\n",
            "Full Response: So it's not that you don't like it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0002 | ROUGE-1: 0.1695 | METEOR: 0.0445\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  42%|████▏     | 6201/14642 [13:06<21:04,  6.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6200/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>yes i have faith in people very fast seriously its like your seeing my mind <user_em...\n",
            "Reference: Maybe this could be a learning experience? I always try to see the best in people, but have learned ...\n",
            "Generated: What do you mean, what do i see my mind?...\n",
            "Full Response: What do you mean, what do i see my mind? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0031 | ROUGE-1: 0.1463 | METEOR: 0.0519\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 6300: BLEU=0.000, Emotion=✗:  43%|████▎     | 6300/14642 [13:19<16:21,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6300/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yes, that is true. I just can't quite seem to quiet my mind. (8) <user_emotion>anxiety ...\n",
            "Reference: Well, I've tried meditating a few times before which doesn;t take it all away, it just takes the edg...\n",
            "Generated: You said that you felt you were in a state of limbo,...\n",
            "Full Response: You said that you felt you were in a state of limbo, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0002 | ROUGE-1: 0.0732 | METEOR: 0.0248\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 6400: BLEU=0.020, Emotion=✗:  44%|████▎     | 6400/14642 [13:32<16:26,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>It might, I am not sure but I don't think my boss will like the idea <user_emotion>anxiety <th...\n",
            "Reference: Sometimes it's important to remember that part of your bosses job is having this kinds of conversati...\n",
            "Generated: I think he might like the idea of you being angry with him....\n",
            "Full Response: I think he might like the idea of you being angry with him. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0195 | ROUGE-1: 0.3077 | METEOR: 0.1874\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  44%|████▍     | 6502/14642 [13:46<12:34, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>but he thinks he is always right and blah blah blah yes My real concern is for the boy...\n",
            "Reference: I can tell this situation stresses you out and probably consumes a lot of your day to day energy. I ...\n",
            "Generated: I'm not angry at you....\n",
            "Full Response: I'm not angry at you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0952 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  45%|████▌     | 6602/14642 [13:58<14:00,  9.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>True That's a good idea. Thank you for your help I just have this as my mai n income r...\n",
            "Reference: Okay, then one of you will have income and then he can find a job later....\n",
            "Generated: ...\n",
            "Full Response: <therapist_emotion> I'm sure that you appreciate it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: i'm | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  46%|████▌     | 6701/14642 [14:12<14:44,  8.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6700/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>i know thats why im so stress. stressed bye <user_emotion>depression <therapist>...\n",
            "Reference: Perhaps \"teacher\" is the right path, buth \"math\" is not. good Luck to you...\n",
            "Generated: It's a little bit of a shock to hear that....\n",
            "Full Response: It's a little bit of a shock to hear that. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0141 | ROUGE-1: 0.0800 | METEOR: 0.0368\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 6800: BLEU=0.000, Emotion=✗:  46%|████▋     | 6800/14642 [14:24<12:47, 10.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6800/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Hi, I need to vent about an ongoing situation. Can I talk to you? <user_emotion>ang...\n",
            "Reference: Of course you can talk to me, What would you like to vent about?...\n",
            "Generated: Of course....\n",
            "Full Response: Of course. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0004 | ROUGE-1: 0.2500 | METEOR: 0.0391\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  47%|████▋     | 6901/14642 [14:36<13:53,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 6900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I do. My other sister is always a big help. Maybe I should text her more often? <user_...\n",
            "Reference: yes! that would always be a good idea. its always comforting to hear from a loved one....\n",
            "Generated: Sure....\n",
            "Full Response: Sure. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  48%|████▊     | 7001/14642 [14:49<15:45,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7000/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>My breakup was a few months ago too. I'm in the Poconos. :) <user_emotion>depression...\n",
            "Reference: I've always wanted to go to Las Vegas. My brother and his girlfriend just took a trip out there not ...\n",
            "Generated: You mean,...\n",
            "Full Response: You mean, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.010:  48%|████▊     | 7101/14642 [15:00<18:03,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7100/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Yeah, it can be very stressful when I don't understand though. I'm normally a very good...\n",
            "Reference: Yes, I had a 100% average almost in high school and still struggled with the class. I kind of wish t...\n",
            "Generated: cause it's not uncommon for you to have a hard time coping with the stress....\n",
            "Full Response: cause it's not uncommon for you to have a hard time coping with the stress. <therapist_emotion> How do you feel about that? <therapist_emotion> neutra...\n",
            "Ref Emotion: anxiety | Pred Emotion: how | Match: ✗\n",
            "BLEU: 0.0007 | ROUGE-1: 0.1111 | METEOR: 0.0367\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  49%|████▉     | 7201/14642 [15:14<17:32,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>To be honest I have been a little afraid to approach them about the subject because the...\n",
            "Reference: Just from chatting to you, I can sense that you are anxious, however, as many students feel this way...\n",
            "Generated: You're right....\n",
            "Full Response: You're right. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0606 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  50%|████▉     | 7302/14642 [15:30<15:59,  7.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I m not sure. why would my friend let it happen, and why would my boyfriend choose t...\n",
            "Reference: you've had some time to sit with this, i understand completely that you are disgusted, but how have ...\n",
            "Generated: ?...\n",
            "Full Response: ? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  51%|█████     | 7400/14642 [15:43<14:48,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>That must have been difficult to deal with. Mental health affects so many people in so...\n",
            "Reference: It was. Luckily I had my doctor to help me. Family members meant well but chalked it up to \"that's w...\n",
            "Generated: I think that's a good thing....\n",
            "Full Response: I think that's a good thing. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0005 | ROUGE-1: 0.1951 | METEOR: 0.0495\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 7500: BLEU=0.000, Emotion=✗:  51%|█████     | 7499/14642 [15:56<16:38,  7.15it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7500/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>feeling very shame <user_emotion>shame <therapist>...\n",
            "Reference: Oh my god ! What happened?...\n",
            "Generated: how did you feel?...\n",
            "Full Response: how did you feel? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 7600: BLEU=0.000, Emotion=✗:  52%|█████▏    | 7600/14642 [16:10<15:12,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yes I do hope so. <user_emotion>depression <therapist>...\n",
            "Reference: I love AMC/Holiday movies as well!...\n",
            "Generated: What I'm asking you is if there is something...\n",
            "Full Response: What I'm asking you is if there is something  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1176 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  53%|█████▎    | 7702/14642 [16:24<12:33,  9.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I've been better. Just stressed really bad. but I think everybody just about is at thi...\n",
            "Reference: it is a stressful time. what's bothering you the most?...\n",
            "Generated: Well, what's the point?...\n",
            "Full Response: Well, what's the point? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0213 | ROUGE-1: 0.3750 | METEOR: 0.1064\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  53%|█████▎    | 7801/14642 [16:36<12:13,  9.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yeah maybe. I suppose nobody really understands but I could at least speak to them abo...\n",
            "Reference: everyone has problems and it is good to talk about them because a problem shared is a problem halved...\n",
            "Generated: I think you should talk to your parents....\n",
            "Full Response: I think you should talk to your parents. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0005 | ROUGE-1: 0.1154 | METEOR: 0.0506\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  54%|█████▍    | 7901/14642 [16:49<14:15,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 7900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>yes <user_emotion>anxiety <therapist>...\n",
            "Reference: You are definitely not the only person to feel this way!...\n",
            "Generated: What's your mood?...\n",
            "Full Response: What's your mood? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  55%|█████▍    | 8002/14642 [17:02<11:10,  9.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>yea, thats what my family is telling me to not rush into thigns <user_emotion>depressi...\n",
            "Reference: You have to do what's right for you...\n",
            "Generated: I don't think that's what your mother told you....\n",
            "Full Response: I don't think that's what your mother told you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.3000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  55%|█████▌    | 8100/14642 [17:16<11:57,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8100/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>but anyhow, I have been conferring with my friend pretty much daily on the phone and t...\n",
            "Reference: that's great. having a supportive friend/family is so much a blessing during this pandemic...\n",
            "Generated: if you can do that....\n",
            "Full Response: if you can do that. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0952 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  56%|█████▌    | 8202/14642 [17:30<12:46,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Hi <user_emotion>depression <therapist>...\n",
            "Reference: What can I help you with today?...\n",
            "Generated: And you were just talking about the birth control pill,...\n",
            "Full Response: And you were just talking about the birth control pill, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0211 | ROUGE-1: 0.1176 | METEOR: 0.0685\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  57%|█████▋    | 8301/14642 [17:43<10:50,  9.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I'm just having a hard time dealing with hurtful things people have said to me. I f...\n",
            "Reference: that is really hard. Are you able to tell these people how their words are making you feel?...\n",
            "Generated: What?...\n",
            "Full Response: What? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  57%|█████▋    | 8401/14642 [17:57<17:19,  6.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8400/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I don't want to. If there is a vaccine in the first quarter of 2021 then the company I worked ...\n",
            "Reference: you have determination! There is fire within! Tell me, what brings you joy?...\n",
            "Generated: I'm not sure that's the right word....\n",
            "Full Response: I'm not sure that's the right word. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  58%|█████▊    | 8501/14642 [18:13<13:51,  7.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>My oldest is sad my youngest 7 couldnt care less. He loves that he can just play roblo...\n",
            "Reference: To be fair Roblox is pretty fun. Have you seen those videos on Facebook where family members visit t...\n",
            "Generated: Maybe he can......\n",
            "Full Response: Maybe he can... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  59%|█████▊    | 8601/14642 [18:26<13:36,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I have practiced breathing techniques and meditation before and think that is a great ...\n",
            "Reference: Absolutely, and it's completely understandable, but it's very hard to wait. I hope that you are able...\n",
            "Generated: What would make you feel better?...\n",
            "Full Response: What would make you feel better? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0339 | METEOR: 0.0219\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  59%|█████▉    | 8701/14642 [18:40<10:39,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8700/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>I am not good . What about you? <user_emotion>depression <therapist>...\n",
            "Reference: i am so sorry to hear that. what seems to be worrying you today?...\n",
            "Generated: You're not good....\n",
            "Full Response: You're not good. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1111 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  60%|██████    | 8801/14642 [18:53<11:19,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yeah, the anxiety of being trapped in my apartment has kind of gotten to me but I am d...\n",
            "Reference: Yeah, socially distancing is quite the isolating experience so I can relate to how you are feeling....\n",
            "Generated: Maybe you could talk to me....\n",
            "Full Response: Maybe you could talk to me. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0078 | ROUGE-1: 0.1739 | METEOR: 0.0629\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  61%|██████    | 8901/14642 [19:05<12:35,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 8900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>It's good that you have had a similar experience and understand what I'm going throu...\n",
            "Reference: Oh I see. That's a huge step to make in a relationship. So you are hesitant to break up with her bec...\n",
            "Generated: You know, she's not a good mother....\n",
            "Full Response: You know, she's not a good mother. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0014 | ROUGE-1: 0.2105 | METEOR: 0.0560\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  61%|██████▏   | 9001/14642 [19:18<09:16, 10.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>No! I keep hearing the negative cruel remarks being repeated in my head over and over ...\n",
            "Reference: WHAT DO YOU HEAR?...\n",
            "Generated: ,...\n",
            "Full Response: , <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  62%|██████▏   | 9101/14642 [19:30<12:15,  7.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9100/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes, sure. I work in an industry heavily impacted by COVID-19, and my company has announced pa...\n",
            "Reference: Woah. Blessings to you for existing in what sounds like a stressful situation. How is self care goin...\n",
            "Generated: I think that's true....\n",
            "Full Response: I think that's true. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  63%|██████▎   | 9201/14642 [19:43<09:28,  9.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Hi <user_emotion>sadness <therapist>...\n",
            "Reference: Hi there, how are you today?...\n",
            "Generated: What are you waiting for?...\n",
            "Full Response: What are you waiting for? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0930 | ROUGE-1: 0.3636 | METEOR: 0.3178\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  64%|██████▎   | 9301/14642 [19:56<12:07,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9300/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>I thought I had everything set up for one of my resident's at a new placement and I called tod...\n",
            "Reference: I see. It seems as though you've done your best, but I understand your feelings. Is it possible you ...\n",
            "Generated: Do you feel you have to be there for her?...\n",
            "Full Response: Do you feel you have to be there for her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0035 | ROUGE-1: 0.1538 | METEOR: 0.0191\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  64%|██████▍   | 9401/14642 [20:09<07:53, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9400/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I don't know if it was good. Maybe he was just being mean. It's nice of you to liste...\n",
            "Reference: I know it's useless to tell you to not be sad. Go ahead and let it all out by crying or screaming bu...\n",
            "Generated: I'm sorry?...\n",
            "Full Response: I'm sorry? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0571 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  65%|██████▍   | 9501/14642 [20:21<08:18, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9500/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>thanks. I hope you best of luck then with all your endeavours. I know we can all get t...\n",
            "Reference: Right on, same to you. It's okay to feel anxious right now. It's okay to feel unproductive right now...\n",
            "Generated: April,...\n",
            "Full Response: April, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  66%|██████▌   | 9601/14642 [20:33<07:52, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>She did but not so great anymore. I sure hope so. It's been hard on everybody. especia...\n",
            "Reference: Maybe she just needs some time to decompress. Being a teenager is a stressful time, especially this ...\n",
            "Generated: And how did she feel about this?...\n",
            "Full Response: And how did she feel about this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0009 | ROUGE-1: 0.1000 | METEOR: 0.0508\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  66%|██████▋   | 9701/14642 [20:47<09:53,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9700/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I am not feeling very positive tonight but I think you are right. I think I reached ...\n",
            "Reference: Would you feel comfortable giving me a little more detail as far as you problem with self abuse? wha...\n",
            "Generated: I think you are right....\n",
            "Full Response: I think you are right. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0010 | ROUGE-1: 0.0667 | METEOR: 0.0217\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  67%|██████▋   | 9801/14642 [21:00<09:56,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9800/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>It's fine, no need to apologize <user_emotion>anxiety <therapist>...\n",
            "Reference: Have you had any chance for ME Time where husband friend or family could watch your kids and give mo...\n",
            "Generated: I just wanted to......\n",
            "Full Response: I just wanted to... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0488 | METEOR: 0.0305\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  68%|██████▊   | 9901/14642 [21:13<09:08,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 9900/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>But when i see social media and News every day it increasing my stress level <user_emo...\n",
            "Reference: I live alone as well and also need to take care of myself. It can be so hard at times....\n",
            "Generated: you think that's because i'm......\n",
            "Full Response: you think that's because i'm... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0741 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  68%|██████▊   | 10002/14642 [21:25<07:07, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I feel somewhat better just thin I feel a little better now. I look forward to talking...\n",
            "Reference: Be creative! Get silly! most important have fun! this is a hard year but its still a chance to make ...\n",
            "Generated: You mean the movie?...\n",
            "Full Response: You mean the movie? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  69%|██████▉   | 10101/14642 [21:38<08:50,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>I just need to schedule an appointment with someone and go in and meet them face to ...\n",
            "Reference: It is great that you can identify what needs to be done in this situation. It sounds like you are re...\n",
            "Generated: And what are you going to do with her?...\n",
            "Full Response: And what are you going to do with her? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0010 | ROUGE-1: 0.2400 | METEOR: 0.0926\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  70%|██████▉   | 10201/14642 [21:52<11:27,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I'm so sorry that it's a situation that you can relate to, its such a hard situation w...\n",
            "Reference: Wow, that really is a lot to deal with. It seems as though you have a good understanding of what you...\n",
            "Generated: And yet, you feel that you've been given a choice,...\n",
            "Full Response: And yet, you feel that you've been given a choice, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1573 | METEOR: 0.0498\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  70%|███████   | 10302/14642 [22:05<08:15,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thanks' so much , you lifted my mood , you being really helpful <user_emotion>depres...\n",
            "Reference: No problem at all! Sending positive vibes your way!! You can get through this!!...\n",
            "Generated: I'm glad you liked it....\n",
            "Full Response: I'm glad you liked it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1000 | METEOR: 0.0382\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  71%|███████   | 10402/14642 [22:17<07:30,  9.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Because prior to the pandemic, I was pretty regimented with set schedules and can clea...\n",
            "Reference: Is there anything else I can help you with?...\n",
            "Generated: You seem like you've been struggling with anxiety....\n",
            "Full Response: You seem like you've been struggling with anxiety. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.2222 | METEOR: 0.0562\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  72%|███████▏  | 10501/14642 [22:29<08:27,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10500/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I think that's pretty good advice. I know which room I can do this, but just away from ...\n",
            "Reference: Of course! Is anything else on your mind?...\n",
            "Generated: So what do you think about this?...\n",
            "Full Response: So what do you think about this? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: nervousness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  72%|███████▏  | 10601/14642 [22:43<09:45,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10600/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Well the boyfriend for awhile the other thing for a day or two I got a hold of a thera...\n",
            "Reference: that's very good that you are going to talk to a therapist. you showed great strength by reaching ou...\n",
            "Generated: And they don't talk to you for two weeks?...\n",
            "Full Response: And they don't talk to you for two weeks? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0185 | ROUGE-1: 0.2000 | METEOR: 0.1420\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  73%|███████▎  | 10701/14642 [22:56<06:49,  9.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10700/14642\n",
            "================================================================================\n",
            "Input: <problem>Alcohol Abuse <user>Yes, I sure hope so. Thank you have a good day! <user_emotion>shame <therapist>...\n",
            "Reference: You as well!...\n",
            "Generated: I'm sorry....\n",
            "Full Response: I'm sorry. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  74%|███████▍  | 10800/14642 [23:09<07:38,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10800/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>I'm looking forward to start a own business. Yes i hope so. i'll start planning <user_emot...\n",
            "Reference: Oh that's exciting! What sort of business?...\n",
            "Generated: So you want to start a company?...\n",
            "Full Response: So you want to start a company? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 10900: BLEU=0.016, Emotion=✗:  74%|███████▍  | 10900/14642 [23:21<07:36,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 10900/14642\n",
            "================================================================================\n",
            "Input: <problem>Procrastination <user>OK, so with, well, kinf0f like baby steps....right <user_emotion>anxiety <therapist>...\n",
            "Reference: It is about making small adjustments to feed a good habit....\n",
            "Generated: we don't talk about kinf0f......\n",
            "Full Response: we don't talk about kinf0f... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0162 | ROUGE-1: 0.1176 | METEOR: 0.0481\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  75%|███████▌  | 11002/14642 [23:34<07:26,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11000/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>Bye <user_emotion>anxiety <therapist>...\n",
            "Reference: (please click the quit button)...\n",
            "Generated: It's not like you're afraid of what you might find....\n",
            "Full Response: It's not like you're afraid of what you might find. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  76%|███████▌  | 11101/14642 [23:46<08:48,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11100/14642\n",
            "================================================================================\n",
            "Input: <problem>Alcohol Abuse <user>Work has been stressful, but I feel like was before things got bad. Most nights I come home...\n",
            "Reference: What do you do for work?...\n",
            "Generated: It's hard for you to imagine that you and your family would be feeling this way...\n",
            "Full Response: It's hard for you to imagine that you and your family would be feeling this way <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0146 | ROUGE-1: 0.1739 | METEOR: 0.1429\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  76%|███████▋  | 11201/14642 [23:58<06:51,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11200/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>That's a good idea. I could try go out for a walk either before or after work as a startin...\n",
            "Reference: That sounds like a good plan! It also helps to make sure that it’s dark and very quiet. Surprisingly...\n",
            "Generated: Would you mind telling me what it would do to your body?...\n",
            "Full Response: Would you mind telling me what it would do to your body? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0018 | ROUGE-1: 0.0769 | METEOR: 0.0413\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  77%|███████▋  | 11301/14642 [24:11<06:05,  9.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11300/14642\n",
            "================================================================================\n",
            "Input: <problem>Sleep Problems <user>I'm looking forward to a fulls night rest. <user_emotion>anxiety <therapist>...\n",
            "Reference: That is good, lavender baths or showers will also ease and relax the troubled mind....\n",
            "Generated: You're feeling good....\n",
            "Full Response: You're feeling good. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1053 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  78%|███████▊  | 11401/14642 [24:25<06:52,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11400/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>mind u i was 125 and fit for the 10 years we were together before we had kids like a d...\n",
            "Reference: I talked to a nutritionist and it really helped. They are professionals who can look into your diet ...\n",
            "Generated: What do you mean?...\n",
            "Full Response: What do you mean? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  79%|███████▊  | 11501/14642 [24:38<06:01,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11500/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>Yes. I mentioned it to them at my 6 week pp check up. I was prescribed to a med to hel...\n",
            "Reference: Antidepressants can take a couple of weeks to kick in, I am on them too; I hope you will find them h...\n",
            "Generated: You seem very anxious,...\n",
            "Full Response: You seem very anxious, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0588 | METEOR: 0.0189\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  79%|███████▉  | 11601/14642 [24:50<06:01,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11600/14642\n",
            "================================================================================\n",
            "Input: <problem>Appearance Anxiety <user>I hate everything when I see my reflection. I just feel fat and ugly <user_emotion>dis...\n",
            "Reference: Well, I have been overweight and I know it sucks. Perhaps you could join a weight loss group?...\n",
            "Generated: Maybe it's time for you to get over your...\n",
            "Full Response: Maybe it's time for you to get over your  <therapist_emotion> ... <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: disgust | Pred Emotion: ... | Match: ✗\n",
            "BLEU: 0.0088 | ROUGE-1: 0.1429 | METEOR: 0.0585\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  80%|███████▉  | 11701/14642 [25:04<05:15,  9.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11700/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes that is a very good summary of what is going on. And I am glad to see you can relate. Whil...\n",
            "Reference: Are there other jobs available in your area that you could apply for that are more up your alley?...\n",
            "Generated: I'm sorry....\n",
            "Full Response: I'm sorry. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: shame | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  81%|████████  | 11801/14642 [25:17<06:33,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11800/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>SOMEWHERE SCARED AND CRYING IN THE RAIN <user_emotion>fear <therapist>...\n",
            "Reference: Is it cold up there?...\n",
            "Generated: What?...\n",
            "Full Response: What? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  81%|████████▏ | 11901/14642 [25:30<05:33,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 11900/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>i was having an affair and i confided in my best friend about it. i found out that ...\n",
            "Reference: Your friend violated a confidence. That sounds difficult....\n",
            "Generated: you're a therapist?...\n",
            "Full Response: you're a therapist? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0215 | ROUGE-1: 0.1667 | METEOR: 0.0667\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  82%|████████▏ | 12001/14642 [25:42<04:51,  9.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12000/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>that sounds weird not what you said I referring to what I said I think it was weird ri...\n",
            "Reference: What do you think sounds weird?...\n",
            "Generated: I think that's a little extreme,...\n",
            "Full Response: I think that's a little extreme, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0408 | ROUGE-1: 0.1538 | METEOR: 0.0833\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  83%|████████▎ | 12101/14642 [25:56<07:35,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12100/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>Today those things have gone and all are fine. When we happen to think of the old e...\n",
            "Reference: So you are angry about what happen in the past...\n",
            "Generated: And what is it that you feel is anger?...\n",
            "Full Response: And what is it that you feel is anger? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anger | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0255 | ROUGE-1: 0.2105 | METEOR: 0.1010\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 12200: BLEU=0.009, Emotion=✗:  83%|████████▎ | 12200/14642 [26:10<10:04,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12200/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>thanks for trying to understand it just seems pretty hopeless <user_emotion>anxiety <therapist...\n",
            "Reference: No problem. I am encountering a similar situation, looking for a well suited job....\n",
            "Generated: I don't think it's hopeless. I think it's just that I think it's just a lot easier to ignore the thi...\n",
            "Full Response: I don't think it's hopeless. I think it's just that I think it's just a lot easier to ignore the things that really matter  <therapist_emotion> What r...\n",
            "Ref Emotion: anxiety | Pred Emotion: what | Match: ✗\n",
            "BLEU: 0.0094 | ROUGE-1: 0.0952 | METEOR: 0.0667\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  84%|████████▍ | 12301/14642 [26:23<05:58,  6.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thank you for listening and giving good advice. You are really good at giving suppor...\n",
            "Reference: I am glad that you find it helpful. I wish I can be around to hear more about it....\n",
            "Generated: You know, sometimes it's not so easy to talk about your problems,...\n",
            "Full Response: You know, sometimes it's not so easy to talk about your problems, <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0113 | ROUGE-1: 0.2500 | METEOR: 0.0820\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  85%|████████▍ | 12401/14642 [26:37<07:01,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I just don't feel motivated to study <user_emotion>shame <therapist>...\n",
            "Reference: from today please feel yourself that you know everything about your studies , i think then you fell ...\n",
            "Generated: I don't think that's true. I think it's true. I think it's true that you have...\n",
            "Full Response: I don't think that's true. I think it's true. I think it's true that you have  <therapist_emotion> anger <therapist_emotion> anger <therapist_emotion>...\n",
            "Ref Emotion: shame | Pred Emotion: anger | Match: ✗\n",
            "BLEU: 0.0239 | ROUGE-1: 0.2105 | METEOR: 0.1688\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  85%|████████▌ | 12502/14642 [26:49<03:51,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>We met on AIM, Her ex is a registered sex offender. and it makes me sad that she lef...\n",
            "Reference: Sometimes we just have to learn to let go *nods sententiously*...\n",
            "Generated: You know, you're a lawyer....\n",
            "Full Response: You know, you're a lawyer. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  86%|████████▌ | 12601/14642 [27:02<03:49,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>We, I and my wife, also think the same way. Even if takes some time, better to wait. But we we...\n",
            "Reference: That's great! I'm glad I was able to help....\n",
            "Generated: So you feel...\n",
            "Full Response: So you feel <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  87%|████████▋ | 12700/14642 [27:15<06:09,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12700/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>sure, you too <user_emotion>anxiety <therapist>...\n",
            "Reference: thank you...\n",
            "Generated: but you can't help but feel...\n",
            "Full Response: but you can't help but feel  <therapist_emotion> joy  <therapist_emotion> joy  <therapist_emotion> joy,  <therapist_emotion> joy.  <therapist_emotion>...\n",
            "Ref Emotion: anxiety | Pred Emotion: joy | Match: ✗\n",
            "BLEU: 0.0408 | ROUGE-1: 0.2222 | METEOR: 0.2083\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  87%|████████▋ | 12800/14642 [27:29<04:35,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12800/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>its hard to plan a future when i am grieving....i don't know how to make myself happ...\n",
            "Reference: don't be sad because of past...\n",
            "Generated: You're very much a part of...\n",
            "Full Response: You're very much a part of  <therapist_emotion> <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: <therapist_emotion> | Match: ✗\n",
            "BLEU: 0.0408 | ROUGE-1: 0.1429 | METEOR: 0.0833\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  88%|████████▊ | 12901/14642 [27:42<02:54,  9.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 12900/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>No I haven't yet. But I was thinking about it actually. Do you think that would be weird to do...\n",
            "Reference: I think that would be a good next step. Communication is always helpful. I think your work will appr...\n",
            "Generated: Maybe....\n",
            "Full Response: Maybe. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.009:  89%|████████▉ | 13001/14642 [27:57<04:21,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13000/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Thanks, that will be helpful to decide on the programs I want to apply to Are you based...\n",
            "Reference: You welcome. and yes...\n",
            "Generated: I'm sure you're aware that there are a lot of people who would rather live in the US than in Canada....\n",
            "Full Response: I'm sure you're aware that there are a lot of people who would rather live in the US than in Canada. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0741 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  89%|████████▉ | 13101/14642 [28:09<04:14,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13100/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>What kind of advise should I be seeking from the counsellor? <user_emotion>anxiety <the...\n",
            "Reference: Well, perhaps they can at least alleviate your anxiety somewhat. Or maybe even get you a sick note t...\n",
            "Generated: You know, I've had the best of luck in therapy. I'm sure you can work through whatever it is that yo...\n",
            "Full Response: You know, I've had the best of luck in therapy. I'm sure you can work through whatever it is that you feel I have to offer. <therapist_emotion> neutra...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0092 | ROUGE-1: 0.1379 | METEOR: 0.1045\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  90%|█████████ | 13201/14642 [28:21<03:33,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13200/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>You met with your friends? I've tried meeting with my friends. I feel ok when I'm with...\n",
            "Reference: yes, you have to be positive at all time and always do something that makes you happy...\n",
            "Generated: You think that you're not happy when you're alone?...\n",
            "Full Response: You think that you're not happy when you're alone? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0117 | ROUGE-1: 0.2857 | METEOR: 0.0926\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  91%|█████████ | 13301/14642 [28:36<02:33,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13300/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Thanks! You’ve been really helpful today. I can’t thank you enough for your encourag...\n",
            "Reference: It was no problem! Thank you for sharing and talking it out!...\n",
            "Generated: I'm sorry, Paul....\n",
            "Full Response: I'm sorry, Paul. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  92%|█████████▏| 13402/14642 [28:50<02:36,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13400/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>I actually do yoga every evening. She hates it. I'm living in her home without a lease...\n",
            "Reference: As long as you have property there she would have to formally evict you. That is the good news....\n",
            "Generated: You know, sometimes you feel guilty about something....\n",
            "Full Response: You know, sometimes you feel guilty about something. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0070 | ROUGE-1: 0.1481 | METEOR: 0.0279\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  92%|█████████▏| 13501/14642 [29:02<02:53,  6.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13500/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>should i go to my school councellor <user_emotion>anxiety <therapist>...\n",
            "Reference: Yes, that is a great idea. Have you ever joined a study group? A group of peers can also be helpful....\n",
            "Generated: you don't know how much pressure it's gonna put on you....\n",
            "Full Response: you don't know how much pressure it's gonna put on you. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0076 | ROUGE-1: 0.0588 | METEOR: 0.0250\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  93%|█████████▎| 13601/14642 [29:14<01:56,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>At this point, I don't know. I have thought about doing art commissions and selling them onlin...\n",
            "Reference: That sounds like a fantastic idea, and even if there is competition, there are still a lot of people...\n",
            "Generated: What's that?...\n",
            "Full Response: What's that? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0645 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  94%|█████████▎| 13701/14642 [29:28<01:34,  9.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13700/14642\n",
            "================================================================================\n",
            "Input: <problem>ongoing depression <user>Yes you are correct the problems with the bank how do i solve not to sink into depress...\n",
            "Reference: So, I have also struggled with that in the past. The way that really helped me put things into persp...\n",
            "Generated: ?...\n",
            "Full Response: ? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  94%|█████████▍| 13801/14642 [29:41<01:50,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13800/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Kind of, but the schedule is a bit weird, like every other day I only have an afternoon...\n",
            "Reference: it sounds like your schedule is different almost everyday. I know I find schedule changes like that ...\n",
            "Generated: I'm not sure how you mean it is....\n",
            "Full Response: I'm not sure how you mean it is. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0048 | ROUGE-1: 0.1935 | METEOR: 0.0243\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 13900: BLEU=0.013, Emotion=✗:  95%|█████████▍| 13900/14642 [29:53<01:29,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 13900/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>We talked about it briefly, but havent spoke about in great detail. I'm just scared,...\n",
            "Reference: How much of this distance between you do you think is related to COVID measures?...\n",
            "Generated: I don't think it is worth it....\n",
            "Full Response: I don't think it is worth it. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0125 | ROUGE-1: 0.1739 | METEOR: 0.0704\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  96%|█████████▌| 14001/14642 [30:07<01:25,  7.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14000/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes. i plan on doing that this afternoon. Thank you so much. I am feeling way more at ease. I ...\n",
            "Reference: I hope your day goes great as well...\n",
            "Generated: I'm honored to be here today....\n",
            "Full Response: I'm honored to be here today. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: fear | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.1333 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  96%|█████████▋| 14101/14642 [30:19<00:55,  9.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14100/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>its gone, she left me <user_emotion>sadness <therapist>...\n",
            "Reference: That's awful. I'm so sorry to hear that. How did it happen?...\n",
            "Generated: what do you mean?...\n",
            "Full Response: what do you mean? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0000 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  97%|█████████▋| 14201/14642 [30:32<00:57,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14200/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>Thank you so much for your insight. I will be praying for a good outcome. <user_emotion...\n",
            "Reference: you will get it for sure! is there anything else I can help you with?...\n",
            "Generated: So what do you think is the most important outcome?...\n",
            "Full Response: So what do you think is the most important outcome? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0152 | ROUGE-1: 0.1600 | METEOR: 0.0690\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  98%|█████████▊| 14301/14642 [30:43<00:39,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14300/14642\n",
            "================================================================================\n",
            "Input: <problem>problems with friends <user>That's something you would have to ask him, but I feel like I am at peace for now. ...\n",
            "Reference: Yeah that a good way to look at it. Maybe take your mind of it by occupying yourself...\n",
            "Generated: I don't think that's what I'm doing....\n",
            "Full Response: I don't think that's what I'm doing. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0000 | ROUGE-1: 0.0714 | METEOR: 0.0000\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 14400: BLEU=0.011, Emotion=✗:  98%|█████████▊| 14399/14642 [30:56<00:27,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14400/14642\n",
            "================================================================================\n",
            "Input: <problem>academic pressure <user>I'm feeling really anxious these days. I'm finding the COVID online learning experience...\n",
            "Reference: I understand your frustration. All of us are challenged due to COVID....\n",
            "Generated: I think that's true....\n",
            "Full Response: I think that's true. <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: anxiety | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0109 | ROUGE-1: 0.1176 | METEOR: 0.0446\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008:  99%|█████████▉| 14500/14642 [31:10<00:18,  7.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14500/14642\n",
            "================================================================================\n",
            "Input: <problem>breakup with partner <user>Yeah she was a little violent. I was honestly a little scared for my life for a seco...\n",
            "Reference: Have you talked since then?...\n",
            "Generated: And how did you react when she did threaten to kill you?...\n",
            "Full Response: And how did you react when she did threaten to kill you? <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: sadness | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0170 | ROUGE-1: 0.1176 | METEOR: 0.0877\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Sample 14600: BLEU=0.001, Emotion=✗: 100%|█████████▉| 14600/14642 [31:24<00:04,  9.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ESCONV LIVE SAMPLE 14600/14642\n",
            "================================================================================\n",
            "Input: <problem>job crisis <user>Yes It is frustrating. When I think about the financial issues I feel depressed <user_emotion>...\n",
            "Reference: I compleyely understand I have also lost my career due to covid. Dont give up, staying positive and ...\n",
            "Generated: I can imagine that you feel...\n",
            "Full Response: I can imagine that you feel  <therapist_emotion> neutral<eos>...\n",
            "Ref Emotion: depression | Pred Emotion: neutral | Match: ✗\n",
            "BLEU: 0.0012 | ROUGE-1: 0.1176 | METEOR: 0.0991\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ESConv - Avg BLEU: 0.005, Emotion Acc: 0.008: 100%|██████████| 14642/14642 [31:29<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ESCONV EVALUATION COMPLETED!\n",
            "============================================================\n",
            "Processed 14642 samples\n",
            "Average BLEU: 0.0050\n",
            "Average ROUGE-1: 0.1046\n",
            "Emotion Accuracy: 0.0080\n",
            "Emotion Tag Coverage: 0.9979\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "ESCONV THERAPY MODEL EVALUATION RESULTS\n",
            "============================================================\n",
            "Model Type: SFT\n",
            "Output Format: STANDARD\n",
            "\n",
            "Text Generation Metrics:\n",
            "  BLEU Score:     0.0050\n",
            "  ROUGE-1:        0.1046\n",
            "  ROUGE-2:        0.0089\n",
            "  ROUGE-L:        0.0925\n",
            "  METEOR:         0.0354\n",
            "\n",
            "Emotion Prediction:\n",
            "  Emotion Accuracy:    0.0080\n",
            "  Emotion Tag Coverage: 0.9979\n",
            "\n",
            "Dataset Info:\n",
            "  Total Samples:  14642\n",
            "\n",
            "Emotion Confusion Matrix:\n",
            "  anxiety:\n",
            "    -> neutral: 3359\n",
            "    -> but: 24\n",
            "    -> <therapist_emotion>: 70\n",
            "    -> i: 66\n",
            "    -> tell: 1\n",
            "    -> i'm: 49\n",
            "    -> what: 23\n",
            "    -> i'm...: 2\n",
            "    -> who: 11\n",
            "    -> well,: 10\n",
            "    -> that: 4\n",
            "    -> i'll: 2\n",
            "    -> anger?: 11\n",
            "    -> and: 13\n",
            "    -> unwell.: 1\n",
            "    -> okay,: 2\n",
            "    -> get: 2\n",
            "    -> you: 29\n",
            "    -> cause: 10\n",
            "    -> unrelated?: 1\n",
            "    -> you're: 18\n",
            "    -> you've: 6\n",
            "    -> ?: 7\n",
            "    -> anger.: 11\n",
            "    -> so: 14\n",
            "    -> but...: 2\n",
            "    -> .: 6\n",
            "    -> appropriate: 1\n",
            "    -> but,: 1\n",
            "    -> we: 11\n",
            "    -> northern: 1\n",
            "    -> right: 2\n",
            "    -> again: 1\n",
            "    -> anger: 23\n",
            "    -> cause?: 1\n",
            "    -> the: 2\n",
            "    -> do: 7\n",
            "    -> if: 17\n",
            "    -> is: 2\n",
            "    -> who'd: 1\n",
            "    -> no_prediction: 8\n",
            "    -> emotional: 11\n",
            "    -> thank: 4\n",
            "    -> others.: 1\n",
            "    -> you're...: 2\n",
            "    -> okay.: 1\n",
            "    -> you.: 1\n",
            "    -> a: 4\n",
            "    -> 17-20?: 1\n",
            "    -> alex.: 1\n",
            "    -> of: 1\n",
            "    -> so,: 4\n",
            "    -> anxiety: 1\n",
            "    -> unrelated: 1\n",
            "    -> angry: 1\n",
            "    -> because: 3\n",
            "    -> good: 1\n",
            "    -> it's: 4\n",
            "    -> for: 1\n",
            "    -> vitamin: 1\n",
            "    -> ful.: 1\n",
            "    -> you'll: 1\n",
            "    -> i've: 4\n",
            "    -> hope: 2\n",
            "    -> who's: 1\n",
            "    -> your: 1\n",
            "    -> how: 2\n",
            "    -> we've: 2\n",
            "    -> knowledge: 1\n",
            "    -> before: 4\n",
            "    -> maybe: 1\n",
            "    -> we'll: 1\n",
            "    -> empower: 1\n",
            "    -> related: 3\n",
            "    -> sessions: 1\n",
            "    -> ...: 2\n",
            "    -> : 1\n",
            "    -> why: 1\n",
            "    -> ,: 1\n",
            "    -> before.: 1\n",
            "    -> telling: 1\n",
            "    -> joy.: 1\n",
            "    -> no,: 1\n",
            "    -> am: 1\n",
            "    -> stayed: 1\n",
            "    -> problem.: 1\n",
            "    -> angerously: 1\n",
            "    -> so...: 1\n",
            "    -> uh,: 1\n",
            "    -> knowledge.: 1\n",
            "    -> unpleasant: 1\n",
            "    -> laura,: 1\n",
            "    -> emotionally: 1\n",
            "    -> we're: 1\n",
            "    -> joy: 3\n",
            "    -> em,: 1\n",
            "    -> happen.: 1\n",
            "    -> joys: 1\n",
            "    -> weird: 1\n",
            "    -> anger,: 1\n",
            "    -> no.: 1\n",
            "    -> aren't: 1\n",
            "    -> talked: 1\n",
            "  anger:\n",
            "    -> neutral: 1102\n",
            "    -> anger: 116\n",
            "    -> and: 1\n",
            "    -> anger.: 5\n",
            "    -> i'm: 3\n",
            "    -> anger?: 6\n",
            "    -> you: 1\n",
            "    -> <therapist_emotion>: 10\n",
            "    -> i: 1\n",
            "    -> cause: 1\n",
            "    -> so,: 1\n",
            "    -> no_prediction: 1\n",
            "    -> .: 1\n",
            "    -> cut: 1\n",
            "    -> 8: 1\n",
            "    -> so: 1\n",
            "    -> you're: 1\n",
            "    -> because: 1\n",
            "    -> joyjoy: 1\n",
            "    -> bye: 1\n",
            "    -> well,: 1\n",
            "  fear:\n",
            "    -> neutral: 998\n",
            "    -> <therapist_emotion>: 31\n",
            "    -> i: 2\n",
            "    -> ful: 1\n",
            "    -> i'm: 2\n",
            "    -> anger.: 1\n",
            "    -> you're: 1\n",
            "    -> what: 1\n",
            "    -> : 2\n",
            "    -> it's: 1\n",
            "    -> how: 1\n",
            "    -> ?: 1\n",
            "    -> and: 3\n",
            "    -> do: 1\n",
            "    -> joy: 1\n",
            "    -> we: 1\n",
            "    -> offer: 1\n",
            "  depression:\n",
            "    -> neutral: 3626\n",
            "    -> <therapist_emotion>: 118\n",
            "    -> : 4\n",
            "    -> anger?: 1\n",
            "    -> thank: 2\n",
            "    -> what: 3\n",
            "    -> and: 3\n",
            "    -> your: 2\n",
            "    -> we: 4\n",
            "    -> angerously: 1\n",
            "    -> i'm: 5\n",
            "    -> ultimately: 1\n",
            "    -> i: 3\n",
            "    -> ?: 4\n",
            "    -> because: 1\n",
            "    -> you're: 2\n",
            "    -> anger: 2\n",
            "    -> no_prediction: 7\n",
            "    -> why: 2\n",
            "    -> you've: 1\n",
            "    -> but: 4\n",
            "    -> break: 1\n",
            "    -> so: 3\n",
            "    -> therapy: 1\n",
            "    -> we're: 1\n",
            "    -> that: 1\n",
            "    -> anger.: 3\n",
            "    -> what?: 2\n",
            "    -> em: 1\n",
            "    -> you: 2\n",
            "    -> emotional: 1\n",
            "    -> do: 1\n",
            "    -> it's: 1\n",
            "    -> have: 1\n",
            "    -> what's: 1\n",
            "    -> ...: 1\n",
            "    -> drink: 1\n",
            "    -> boat.: 1\n",
            "    -> so,: 1\n",
            "    -> who: 1\n",
            "    -> from: 1\n",
            "    -> we've: 1\n",
            "    -> depressed.: 1\n",
            "    -> if: 1\n",
            "    -> cause: 1\n",
            "    -> good: 1\n",
            "    -> issues: 1\n",
            "  sadness:\n",
            "    -> neutral: 3274\n",
            "    -> no_prediction: 7\n",
            "    -> <therapist_emotion>: 136\n",
            "    -> i'm: 5\n",
            "    -> and: 5\n",
            "    -> so: 3\n",
            "    -> i: 4\n",
            "    -> what: 2\n",
            "    -> .: 2\n",
            "    -> anger: 7\n",
            "    -> been: 1\n",
            "    -> ?: 4\n",
            "    -> why: 1\n",
            "    -> nosedived: 1\n",
            "    -> so,: 1\n",
            "    -> joy: 1\n",
            "    -> you: 3\n",
            "    -> of: 1\n",
            "    -> anger,: 1\n",
            "    -> because: 1\n",
            "    -> you're: 1\n",
            "    -> we: 1\n",
            "    -> do: 2\n",
            "    -> anger.: 3\n",
            "    -> anger?: 2\n",
            "    -> joys: 1\n",
            "    -> maybe: 2\n",
            "    -> ripped: 1\n",
            "    -> cause: 1\n",
            "    -> problems: 1\n",
            "    -> joy.: 1\n",
            "  disgust:\n",
            "    -> neutral: 422\n",
            "    -> <therapist_emotion>: 20\n",
            "    -> no_prediction: 3\n",
            "    -> joy: 1\n",
            "    -> we're: 1\n",
            "    -> ...: 1\n",
            "    -> i: 1\n",
            "    -> anger?: 1\n",
            "    -> so: 1\n",
            "    -> but: 1\n",
            "    -> i'm: 1\n",
            "  shame:\n",
            "    -> why: 3\n",
            "    -> neutral: 366\n",
            "    -> i...: 1\n",
            "    -> what: 2\n",
            "    -> before: 2\n",
            "    -> maybe: 1\n",
            "    -> embrace: 1\n",
            "    -> if: 7\n",
            "    -> i'm: 13\n",
            "    -> i: 17\n",
            "    -> you're: 6\n",
            "    -> no_prediction: 4\n",
            "    -> shamala,: 1\n",
            "    -> cause: 1\n",
            "    -> so: 3\n",
            "    -> but: 4\n",
            "    -> <therapist_emotion>: 7\n",
            "    -> anger: 7\n",
            "    -> honestly: 1\n",
            "    -> you: 6\n",
            "    -> and: 1\n",
            "    -> you've: 1\n",
            "    -> we: 1\n",
            "    -> sorry,: 1\n",
            "    -> .: 1\n",
            "    -> right: 1\n",
            "    -> that: 1\n",
            "    -> anger.: 1\n",
            "    -> emotional,: 1\n",
            "    -> i've: 1\n",
            "    -> get: 1\n",
            "    -> that's: 1\n",
            "    -> haha.: 1\n",
            "    -> joyful: 1\n",
            "    -> joy: 1\n",
            "  nervousness:\n",
            "    -> neutral: 121\n",
            "    -> <therapist_emotion>: 9\n",
            "    -> what: 1\n",
            "    -> anger: 1\n",
            "    -> who: 2\n",
            "    -> so: 1\n",
            "    -> nervousness?: 1\n",
            "    -> so,: 1\n",
            "    -> empowered: 1\n",
            "    -> : 1\n",
            "    -> i: 1\n",
            "    -> unable: 1\n",
            "    -> thank: 1\n",
            "    -> we: 1\n",
            "    -> anger?: 1\n",
            "    -> no_prediction: 1\n",
            "  pain:\n",
            "    -> neutral: 8\n",
            "    -> you're: 1\n",
            "  jealousy:\n",
            "    -> neutral: 14\n",
            "  guilt:\n",
            "    -> neutral: 10\n",
            "\n",
            "Sample Outputs:\n",
            "\n",
            "  Sample 1:\n",
            "    Input: <problem>job crisis <user>Hello <user_emotion>anxiety <therapist>...\n",
            "    Reference: Hello, what would you like to talk about?...\n",
            "    Predicted: I'm sorry. I just wanted to let you know that you're not worried....\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.018, ROUGE-1: 0.174\n",
            "\n",
            "  Sample 2:\n",
            "    Input: <problem>job crisis <user>I am having a lot of anxiety about quitting my current job. It is too stre...\n",
            "    Reference: What makes your job stressful for you?...\n",
            "    Predicted: You have to live with it....\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: neutral\n",
            "    BLEU: 0.000, ROUGE-1: 0.154\n",
            "\n",
            "  Sample 3:\n",
            "    Input: <problem>job crisis <user>I have to deal with many people in hard financial situations and it is ups...\n",
            "    Reference: Do you help your clients to make it to a better financial situation?...\n",
            "    Predicted: you can't control your emotions, you can control your emotions...\n",
            "    Ref Emotion: anxiety\n",
            "    Pred Emotion: but\n",
            "    BLEU: 0.019, ROUGE-1: 0.167\n",
            "\n",
            "Evaluation completed! Results saved to ESConv_RL_evaluation_results.pkl\n"
          ]
        }
      ]
    }
  ]
}